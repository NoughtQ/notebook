<!DOCTYPE html>
<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="NoughtQ的笔记本，主要记录一些 CS 相关的笔记" name="description"/>
<meta content="NoughtQ" name="author"/>
<link href="https://notebook.noughtq.top/system/ca/5.html" rel="canonical"/>
<link href="4.html" rel="prev"/>
<link href="../db/index.html" rel="next"/>
<link href="../../feed_rss_created.xml" rel="alternate" title="RSS 订阅" type="application/rss+xml"/>
<link href="../../feed_rss_updated.xml" rel="alternate" title="已更新内容的 RSS 订阅" type="application/rss+xml"/>
<link href="../../assets/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.14" name="generator"/>
<title>Chap 5: Thread-Level Parallelism - NoughtQ的笔记本</title>
<link href="../../assets/stylesheets/main.342714a4.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=JetBrains+Mono,+LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono,+Consolas:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"JetBrains Mono, LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono, Consolas"}</style>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="../../css/toc_extra.css" rel="stylesheet"/>
<link href="../../css/timeline.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/extra_changelog.css" rel="stylesheet"/>
<link href="https://unpkg.com/katex@0/dist/katex.min.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&amp;display=swap" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-43NH8CVRCJ"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-43NH8CVRCJ",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-43NH8CVRCJ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#chap-5-thread-level-parallelism">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="NoughtQ的笔记本" class="md-header__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            NoughtQ的笔记本
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Chap 5: Thread-Level Parallelism
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Dark Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Dark Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
<input aria-label="Light Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Light Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 320 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<a aria-label="分享" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="分享">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../index.html">
          
  
  
    
  
  🏫主页

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../lang/index.html">
          
  
  
    
  
  🔡语言

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../math/index.html">
          
  
  
    
  
  📊数学相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../algorithms/index.html">
          
  
  
    
  
  🧮算法相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../software/index.html">
          
  
  
    
  
  💾软件相关

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../index.html">
          
  
  
    
  
  💻系统相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../web/index.html">
          
  
  
    
  
  🌏Web相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../sec/ctf-101/index.html">
          
  
  
    
  
  🛡️信息安全

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../ai/index.html">
          
  
  
    
  
  🤖人工智能

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../misc/index.html">
          
  
  
    
  
  🗃️杂项

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tools/index.html">
          
  
  
    
  
  🛠️工具

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../papers/index.html">
          
  
  
    
  
  📑论文阅读

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="NoughtQ的笔记本" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
    NoughtQ的笔记本
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../index.html">
<span class="md-ellipsis">
    🏫主页
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../lang/index.html">
<span class="md-ellipsis">
    🔡语言
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../math/index.html">
<span class="md-ellipsis">
    📊数学相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../algorithms/index.html">
<span class="md-ellipsis">
    🧮算法相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../software/index.html">
<span class="md-ellipsis">
    💾软件相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../index.html">
<span class="md-ellipsis">
    💻系统相关
    
  </span>
</a>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            💻系统相关
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../csapp/index.html">
<span class="md-ellipsis">
    CSAPP
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../dld/index.html">
<span class="md-ellipsis">
    数字逻辑设计
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../co/index.html">
<span class="md-ellipsis">
    计算机组成
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_6_5" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="index.html">
<span class="md-ellipsis">
    计算机体系结构
    
  </span>
</a>
<label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_6_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_6_5">
<span class="md-nav__icon md-icon"></span>
            计算机体系结构
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1.html">
<span class="md-ellipsis">
    Chap 1: Fundamentals of Quantitative Design and Analysis
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2.html">
<span class="md-ellipsis">
    Chap 2: Memory Hierarchy Design
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="3.html">
<span class="md-ellipsis">
    Chap 3: Instruction-Level Parallelism and Its Exploitation
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4.html">
<span class="md-ellipsis">
    Chap 4: Data-Level Parallelism in Vector, SIMD, and GPU Architectures
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Chap 5: Thread-Level Parallelism
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="5.html">
<span class="md-ellipsis">
    Chap 5: Thread-Level Parallelism
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#introduction">
<span class="md-ellipsis">
      Introduction
    </span>
</a>
<nav aria-label="Introduction" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprocessor-architecture">
<span class="md-ellipsis">
      Multiprocessor Architecture
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#challenges-of-parallel-processing">
<span class="md-ellipsis">
      Challenges of Parallel Processing
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#centralized-shared-memory-architectures">
<span class="md-ellipsis">
      Centralized Shared-Memory Architectures
    </span>
</a>
<nav aria-label="Centralized Shared-Memory Architectures" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprocessor-cache-coherence">
<span class="md-ellipsis">
      Multiprocessor Cache Coherence
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-schemes-for-enforcing-coherence">
<span class="md-ellipsis">
      Basic Schemes for Enforcing Coherence
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#snooping-coherence-protocols">
<span class="md-ellipsis">
      Snooping Coherence Protocols
    </span>
</a>
<nav aria-label="Snooping Coherence Protocols" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-implementation-techniques">
<span class="md-ellipsis">
      Basic Implementation Techniques
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#a-simple-protocol">
<span class="md-ellipsis">
      A Simple Protocol
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extensions-to-the-basic-coherence-protols">
<span class="md-ellipsis">
      Extensions to the Basic Coherence Protols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#limitations-in-smps-and-snooping-protocols">
<span class="md-ellipsis">
      Limitations in SMPs and Snooping Protocols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#implementing-snooping-cache-coherence">
<span class="md-ellipsis">
      Implementing Snooping Cache Coherence
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#performance-of-symmetric-shared-memory-multiprocessors">
<span class="md-ellipsis">
      Performance of Symmetric Shared-Memory Multiprocessors
    </span>
</a>
<nav aria-label="Performance of Symmetric Shared-Memory Multiprocessors" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#commercial-workload">
<span class="md-ellipsis">
      Commercial Workload
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprogramming-and-os-workload">
<span class="md-ellipsis">
      Multiprogramming and OS Workload
    </span>
</a>
<nav aria-label="Multiprogramming and OS Workload" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#performance">
<span class="md-ellipsis">
      Performance
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#distributed-shared-memory-and-directory-based-coherence">
<span class="md-ellipsis">
      Distributed Shared-Memory and Directory-Based Coherence
    </span>
</a>
<nav aria-label="Distributed Shared-Memory and Directory-Based Coherence" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#directory-based-cache-coherence-protocols">
<span class="md-ellipsis">
      Directory-Based Cache Coherence Protocols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#an-example-directory-protocol">
<span class="md-ellipsis">
      An Example Directory Protocol
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#synchronization">
<span class="md-ellipsis">
      Synchronization
    </span>
</a>
<nav aria-label="Synchronization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-hardware-primitives">
<span class="md-ellipsis">
      Basic Hardware Primitives
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#implementing-locks-using-coherence">
<span class="md-ellipsis">
      Implementing Locks Using Coherence
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models-of-memory-consistency">
<span class="md-ellipsis">
      Models of Memory Consistency
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cross-cutting-issues">
<span class="md-ellipsis">
      Cross-Cutting Issues
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#fallacies-and-pitfalls">
<span class="md-ellipsis">
      Fallacies and Pitfalls
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../db/index.html">
<span class="md-ellipsis">
    数据库系统
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../web/index.html">
<span class="md-ellipsis">
    🌏Web相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../sec/ctf-101/index.html">
<span class="md-ellipsis">
    🛡️信息安全
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../ai/index.html">
<span class="md-ellipsis">
    🤖人工智能
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../misc/index.html">
<span class="md-ellipsis">
    🗃️杂项
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tools/index.html">
<span class="md-ellipsis">
    🛠️工具
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../papers/index.html">
<span class="md-ellipsis">
    📑论文阅读
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#introduction">
<span class="md-ellipsis">
      Introduction
    </span>
</a>
<nav aria-label="Introduction" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprocessor-architecture">
<span class="md-ellipsis">
      Multiprocessor Architecture
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#challenges-of-parallel-processing">
<span class="md-ellipsis">
      Challenges of Parallel Processing
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#centralized-shared-memory-architectures">
<span class="md-ellipsis">
      Centralized Shared-Memory Architectures
    </span>
</a>
<nav aria-label="Centralized Shared-Memory Architectures" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprocessor-cache-coherence">
<span class="md-ellipsis">
      Multiprocessor Cache Coherence
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-schemes-for-enforcing-coherence">
<span class="md-ellipsis">
      Basic Schemes for Enforcing Coherence
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#snooping-coherence-protocols">
<span class="md-ellipsis">
      Snooping Coherence Protocols
    </span>
</a>
<nav aria-label="Snooping Coherence Protocols" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-implementation-techniques">
<span class="md-ellipsis">
      Basic Implementation Techniques
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#a-simple-protocol">
<span class="md-ellipsis">
      A Simple Protocol
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extensions-to-the-basic-coherence-protols">
<span class="md-ellipsis">
      Extensions to the Basic Coherence Protols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#limitations-in-smps-and-snooping-protocols">
<span class="md-ellipsis">
      Limitations in SMPs and Snooping Protocols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#implementing-snooping-cache-coherence">
<span class="md-ellipsis">
      Implementing Snooping Cache Coherence
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#performance-of-symmetric-shared-memory-multiprocessors">
<span class="md-ellipsis">
      Performance of Symmetric Shared-Memory Multiprocessors
    </span>
</a>
<nav aria-label="Performance of Symmetric Shared-Memory Multiprocessors" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#commercial-workload">
<span class="md-ellipsis">
      Commercial Workload
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#multiprogramming-and-os-workload">
<span class="md-ellipsis">
      Multiprogramming and OS Workload
    </span>
</a>
<nav aria-label="Multiprogramming and OS Workload" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#performance">
<span class="md-ellipsis">
      Performance
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#distributed-shared-memory-and-directory-based-coherence">
<span class="md-ellipsis">
      Distributed Shared-Memory and Directory-Based Coherence
    </span>
</a>
<nav aria-label="Distributed Shared-Memory and Directory-Based Coherence" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#directory-based-cache-coherence-protocols">
<span class="md-ellipsis">
      Directory-Based Cache Coherence Protocols
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#an-example-directory-protocol">
<span class="md-ellipsis">
      An Example Directory Protocol
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#synchronization">
<span class="md-ellipsis">
      Synchronization
    </span>
</a>
<nav aria-label="Synchronization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-hardware-primitives">
<span class="md-ellipsis">
      Basic Hardware Primitives
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#implementing-locks-using-coherence">
<span class="md-ellipsis">
      Implementing Locks Using Coherence
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models-of-memory-consistency">
<span class="md-ellipsis">
      Models of Memory Consistency
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cross-cutting-issues">
<span class="md-ellipsis">
      Cross-Cutting Issues
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#fallacies-and-pitfalls">
<span class="md-ellipsis">
      Fallacies and Pitfalls
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/edit/master/docs/system/ca/5.md" title="编辑此页">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/raw/master/docs/system/ca/5.md" title="查看本页的源代码">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
</a>
<h1 id="chap-5-thread-level-parallelism">Chap 5: Thread-Level Parallelism<a class="headerlink" href="#chap-5-thread-level-parallelism" title="Permanent link">⚓︎</a></h1>
<div style="margin-top: -30px; font-size: 0.9em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>16412<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6m80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3l89.3 89.4-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3"></path></svg></span> <span>18<span class="heti-spacing"> </span></span>行代码 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>82<span class="heti-spacing"> </span></span>分钟</p>
</div>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">⚓︎</a></h2>
<p>前面提到过，由于<span class="heti-skip"><span class="heti-spacing"> </span>ILP<span class="heti-spacing"> </span></span>工艺进步的放缓，单处理器<span class="heti-skip"><span class="heti-spacing"> </span>(uniprocessor)<span class="heti-spacing"> </span></span>的发展逐渐走向尾声。因此多处理器的重要性日渐提升，这主要体现在以下几方面：</p>
<ul>
<li><span>ILP<span class="heti-spacing"> </span></span>的低效——功率和硅成本的增长要高于性能的提升</li>
<li>高端服务器在云计算和<span class="heti-skip"><span class="heti-spacing"> </span>SaaS<span class="heti-spacing"> </span></span>的重要性提升</li>
<li>得益于互联网上的大量数据，数据密集型应用不断增长</li>
<li>多处理器的并行能力为大数据集（数据并行<heti-adjacent class="heti-adjacent-half">）</heti-adjacent><heti-adjacent class="heti-adjacent-quarter">、</heti-adjacent>“自然世界”并行（科学和工程代码）以及在大量并行的独立请求带来很大帮助</li>
<li>...</li>
</ul>
<p>在本章，我们主要探索的是<strong>线程级并行</strong>(thread-level parallelism, <strong>TLP</strong>)；而<span class="heti-skip"><span class="heti-spacing"> </span>TLP<span class="heti-spacing"> </span></span>利用到了 <strong>MIMD</strong>(multiple instructions, multiple data)。</p>
<p><strong>多处理器</strong><span>(multiprocessor)<span class="heti-spacing"> </span></span>由一组紧密耦合的处理器构成，这些处理器受操作系统控制，并通过一个共享的地址空间来共享内存（不一定只有一块物理内存<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。多处理器通过以下两个不同的软件模型来利用<span><span class="heti-spacing"> </span>TLP</span>：</p>
<ul>
<li><strong>并行处理</strong>(parallel processing)：一组在单任务上协作的紧密耦合的线程的执行</li>
<li><strong>请求级并行</strong>(request-level parallelism)：来自一名或多名用户的多个相对独立的进程的执行<ul>
<li>运行在多个处理器上的单一应用程序会利用请求级并行，例如数据库响应查询，或者通过多个独立运行的应用程序（后者通常被称为<strong>多道程序设计</strong>(multiprogramming)）</li>
</ul>
</li>
</ul>
<p>多处理器既包含具有多个核心的单芯片系统，即所谓的<strong>多核</strong>(multicore)，也涵盖由多个芯片组成的计算机，其中每个芯片通常也是一个多核单元。</p>
<p>之后我们还会探讨<strong>多线程</strong><span>(multithreading)<span class="heti-spacing"> </span></span>技术——这是一种支持在单个多发射处理器上以交错方式执行多个线程的技术。许多多核处理器同样包含对多线程的支持。</p>
<h3 id="multiprocessor-architecture">Multiprocessor Architecture<a class="headerlink" href="#multiprocessor-architecture" title="Permanent link">⚓︎</a></h3>
<p>要充分利用具有<span class="heti-skip"><span class="heti-spacing"> </span>n<span class="heti-spacing"> </span></span>个处理器的<span class="heti-skip"><span class="heti-spacing"> </span>MIMD<span class="heti-spacing"> </span></span>多处理器，通常需要至少<span class="heti-skip"><span class="heti-spacing"> </span>n<span class="heti-spacing"> </span></span>个线程或进程来执行；而当今大多数多核芯片都支持多线程技术，这一数量会增至<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>到<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>倍。单个进程内的独立线程通常由<strong>程序员</strong>显式指定，或由<strong>操作系统</strong>根据多个独立请求动态创建。另一种极端情况是，一个线程可能仅包含循环的数十次迭代——这是<strong>并行编译器</strong>循环中的数据并行性而自动生成的。尽管分配给线程的计算量（称为<strong>粒度大小</strong>(grain size)）对于高效利用<span class="heti-skip"><span class="heti-spacing"> </span>TLP<span class="heti-spacing"> </span></span>至关重要，但与<span class="heti-skip"><span class="heti-spacing"> </span>ILP<span class="heti-spacing"> </span></span>的本质区别在于：<span>TLP<span class="heti-spacing"> </span></span>是由<strong>软件系统</strong>或<strong>程序员</strong>在高层抽象中识别出的、由数百至数百万条可并行执行的指令构成的代码段。</p>
<p>线程也可为<span class="heti-skip"><span class="heti-spacing"> </span>DLP<span class="heti-spacing"> </span></span>所利用，但其开销通常高于<span class="heti-skip"><span class="heti-spacing"> </span>SIMD<span class="heti-spacing"> </span></span>处理器或<span><span class="heti-spacing"> </span>GPU</span>。必须确保粒度足够大，才能高效利用其并行性。</p>
<p>现有的共享内存的多处理器，根据其内存组织的不同划分为以下两大类：</p>
<ul>
<li>
<p><strong>对称（共享内存）多处理器</strong>(symmetric (shared-memory) multiprocessors, <strong>SMP</strong>)（或<strong>集中式</strong>(centralized)<strong>共享内存多处理器</strong>）</p>
<ul>
<li>具有小到中等数量的核心，通常为<span class="heti-skip"><span class="heti-spacing"> </span>32<span class="heti-spacing"> </span></span>个或更少</li>
<li>对于这种核心数量较少的多处理器，里面的这些处理器可以共享一个所有处理器都有平等访问权的单一集中式内存，因此称为“对称”</li>
<li>大多数现有的多核都属于<span><span class="heti-spacing"> </span>SMP</span></li>
<li><span>SMP<span class="heti-spacing"> </span></span>有时也被称为<strong>统一内存访问</strong><span>(uniform memory access, UMA)<span class="heti-spacing"> </span></span>多处理器，这是因为所有处理器对内存的访问延迟是均等的，即便内存被划分为多个分区亦是如此</li>
<li>某些多核处理器对最外层高速缓存的访问是非均匀的，这种结构被称为<strong>非均匀高速缓存访问</strong>(nonuniform cache access, NUCA)，因此即便它们拥有单一主内存，也并非真正的<span><span class="heti-spacing"> </span>SMP</span></li>
<li>
<p>下图展示了集中式共享内存多处理器的基本结构：</p>
<p></p><div style="text-align: center">
<img src="images/C5/1.png" width="70%"/>
</div>
</li>
</ul>
</li>
<li>
<p><strong>分布式共享内存</strong>(distributed shared memory, <strong>DSM</strong>)</p>
<ul>
<li>在由<strong>多个多核芯片</strong>构成的多处理器系统中，每个多核芯片通常配备<strong>独立的内存单元</strong>，因此这类系统的内存采用<strong>分布式</strong>组织而非集中式组织</li>
<li>许多分布式内存设计能实现对<strong>本地</strong>内存的快速访问，而<strong>远程</strong>内存访问速度则显著下降</li>
<li>在此类架构中，程序员和软件系统需明确区分本地与远程内存访问操作，但通常无需关注各远程存储节点间的具体分布情况</li>
<li>为支持更多的处理器数量，内存必须是分布组织而非集中组织；否则内存系统将以增大访问延迟的代价来满足更多处理器的带宽需求</li>
<li>由于上述问题，<span>SMP<span class="heti-spacing"> </span></span>随处理器数量的增加会逐渐丧失优势，因此绝大多数超大规模多处理器系统都采用了分布式内存组织</li>
<li>
<p>下图展示了分布式共享内存多处理器的基本结构：</p>
<p></p><div style="text-align: center">
<img src="images/C5/2.png" width="80%"/>
</div>
</li>
<li>
<p><span>DSM<span class="heti-spacing"> </span></span>多处理器也被称为<strong>非均匀内存访问架构</strong>(nonuniform memeory access, NUMA)，因为数据访问时间取决于数据字在内存中的物理位置</p>
</li>
<li><span>DSM<span class="heti-spacing"> </span></span>的主要缺点是处理器间的数据通信机制变得更为复杂，且需要软件层面付出更多努力才能充分利用所增加的内存带宽优势</li>
</ul>
</li>
</ul>
<p>无论是<span class="heti-skip"><span class="heti-spacing"> </span>SMP<span class="heti-spacing"> </span></span>还是<span class="heti-skip"><span class="heti-spacing"> </span>DSM<span class="heti-spacing"> </span></span>架构，线程间的通信均通过一个共享的地址空间来实现。这意味着只要具备相应的访问权限，任何处理器均可对任意内存位置进行寻址操作。<span>SMP<span class="heti-spacing"> </span></span>与<span class="heti-skip"><span class="heti-spacing"> </span>DSM<span class="heti-spacing"> </span></span>的<strong>共享内存</strong><span>(shared memory)<span class="heti-spacing"> </span></span>本质上指代的是<strong>地址空间</strong><span>(address space)<span class="heti-spacing"> </span></span>的共享性。</p>
<h3 id="challenges-of-parallel-processing">Challenges of Parallel Processing<a class="headerlink" href="#challenges-of-parallel-processing" title="Permanent link">⚓︎</a></h3>
<p>多处理器的应用范围广泛，包括：运行几乎无需通信的独立任务，或者执行需要线程间协作才能完成的并行程序。要应对这些任务带来的挑战，通常需要采取以下综合方案：</p>
<ul>
<li>精心选择算法并优化实现</li>
<li>适配底层编程语言与系统</li>
<li>协调操作系统及其支持功能</li>
<li>调整体系结构与硬件实施方案</li>
</ul>
<p>尽管很多时候其中某一个环节可能会成为主要瓶颈，但当处理器规模变得很大的时候，我们需要同步优化软件和硬件的所有层面。具体来说，我们主要会遇到以下两种挑战：</p>
<ul>
<li>程序中有限的并行能力</li>
<li>相对高昂的通信开销，或者说并行处理器中远程访问的高延迟问题<ul>
<li>在现有的共享内存的多处理器中，不同核心间的数据传输可能耗费<span class="heti-skip"><span class="heti-spacing"> </span>35<span class="heti-spacing"> </span></span>至<span class="heti-skip"><span class="heti-spacing"> </span>50<span class="heti-spacing"> </span></span>个时钟周期</li>
<li>而跨芯片的核心间通信则需<span class="heti-skip"><span class="heti-spacing"> </span>100<span class="heti-spacing"> </span></span>到<span class="heti-skip"><span class="heti-spacing"> </span>300<span class="heti-spacing"> </span></span>甚至更多时钟周期（针对大规模多处理器<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>（这些数据均来自教材）</li>
<li>具体时长取决于通信机制、互连网络类型以及多处理器的规模</li>
</ul>
</li>
</ul>
<p>它们对应的具体解决方法为：</p>
<ul>
<li>
<p>对于应用程序并行能力不足的问题，主要需从软件层面着手：</p>
<ul>
<li>一方面采用能提供更优并行性能的新算法</li>
<li>另一方面依靠软件系统，最大化处理器完整配置下的有效执行时间</li>
</ul>
</li>
<li>
<p>对于降低远距离延迟的影响，则需要架构师与程序员的共同努力：</p>
<ul>
<li>例如通过硬件机制（如缓存共享数据）或软件手段（如重构数据结构使访问本地化）来减少远程访问次数</li>
<li>也可以借助<strong>多线程</strong>技术或<a href="2.html#hardware-prefetching-of-instructions-and-data"><strong>预取</strong></a>策略来尝试掩盖延迟</li>
</ul>
</li>
</ul>
<p>本章后续内容着重研究如何应对第二个挑战。</p>
<h2 id="centralized-shared-memory-architectures">Centralized Shared-Memory Architectures<a class="headerlink" href="#centralized-shared-memory-architectures" title="Permanent link">⚓︎</a></h2>
<p>使用大型的多级高速缓存能显著降低处理器对内存带宽的需求，这一发现推动了<strong>集中式内存多处理器</strong>的发展。</p>
<ul>
<li>最初的处理器均为单核设计，通常会占据整个主板；内存则位于共享总线上</li>
<li>随着高性能处理器的出现，处理器的内存需求已超出了常规总线的承载能力，因此现代的微处理器直接将内存连接至单一芯片（有时称为<strong>后端</strong><span>(backside)<span class="heti-spacing"> </span></span>或<strong>内存总线</strong>(memory bus)，以区别于连接<span class="heti-skip"><span class="heti-spacing"> </span>I/O<span class="heti-spacing"> </span></span>的总线）<ul>
<li>无论是执行<span class="heti-skip"><span class="heti-spacing"> </span>I/O<span class="heti-spacing"> </span></span>操作还是来自其他芯片的访问，访问芯片本地存储器时都必须经过“拥有”该内存的芯片处理</li>
<li>因此这种内存访问具有不对称性：本地内存访问速度较快，而远程内存较慢</li>
<li>在多核架构中，单个芯片上的所有核心共享该存储器，但不同的核之间通过各自内存进行的不对称访问模式通常存在</li>
</ul>
</li>
</ul>
<p><strong>对称的共享内存机器</strong>通常支持对共享数据和私有数据的<strong>缓存</strong>，其中：</p>
<ul>
<li><strong>私有数据</strong><span>(private data)<span class="heti-spacing"> </span></span>仅被一个处理器使用<ul>
<li>当私有数据被缓存时，其存储位置会迁移至高速缓存中，从而降低平均访问时间以及所需的内存带宽</li>
</ul>
</li>
<li><strong>共享数据</strong><span>(shared data)<span class="heti-spacing"> </span></span>则能被多个处理器共同访问<ul>
<li>对于共享数据的缓存处理，其值可能被复制到多个高速缓存中。除了缩短访问延迟和减少内存带宽需求外，这种复制还能缓解多处理器同时读取同一共享数据项时可能产生的竞争问题</li>
<li>然而，共享数据的缓存也带来了新的挑战——高速缓存的<strong>一致性</strong><span>(coherence)<span class="heti-spacing"> </span></span>问题，下面马上介绍！</li>
</ul>
</li>
</ul>
<h3 id="multiprocessor-cache-coherence">Multiprocessor Cache Coherence<a class="headerlink" href="#multiprocessor-cache-coherence" title="Permanent link">⚓︎</a></h3>
<p><strong>高速缓存一致性问题</strong>(cache coherence problem)：由于两个不同的处理器对内存的视图是通过各自的高速缓存建立的，因此这些处理器最终可能看到同一内存位置下的不同值。这一问题来源于我们同时拥有由主存定义的<strong>全局状态</strong>和由各处理器核心私有的独立缓存所定义的<strong>局部状态</strong>。</p>
<p>一种不太正式的说法是：如果一个内存系统对任何数据项的读取都能返回该数据项最近被写入的值，我们就可以说这个内存系统是<strong>一致的</strong>。这个定义虽然直观易懂，却显得模糊且过于简单——实际情况要比这复杂得多；而且这一简单的定义实际包括了内存系统行为的两个方面：</p>
<ul>
<li><strong>一致性</strong>(coherence)：规定了读操作可以返回哪些值</li>
<li><strong>连贯性</strong>(consistency)：决定了写操作的值何时能被读操作返回</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">注意</p>
<p>实际上，中文翻译没能很好地将<span class="heti-skip"><span class="heti-spacing"> </span>coherence<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>consistency<span class="heti-spacing"> </span></span>区分开来，所以你可能会在网上看到把<span class="heti-skip"><span class="heti-spacing"> </span>consistency<span class="heti-spacing"> </span></span>翻译成“一致性”的情况。不过在自己的笔记中，我还是选择将其翻译成“连贯性”。</p>
</div>
<p>对一致性的严格定义为：当满足以下条件时，我们称内存系统具有一致性：</p>
<ul>
<li>处理器<span class="heti-skip"><span class="heti-spacing"> </span>P<span class="heti-spacing"> </span></span>对位置<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的写入操作后紧跟着<span class="heti-skip"><span class="heti-spacing"> </span>P<span class="heti-spacing"> </span></span>对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的读取操作，且在该写入与读取之间没有其他处理器对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>进行写入时，该读取总是返回由<span class="heti-skip"><span class="heti-spacing"> </span>P<span class="heti-spacing"> </span></span>所写入的值。<ul>
<li>该性质保留了程序顺序，而且该性质即使在单处理器中也依然成立。</li>
</ul>
</li>
<li>当一个处理器对位置<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的读取操作发生在另一个处理器对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的写入操作之后，只要读写之间有足够的时间间隔<span class="heti-skip"><span class="heti-spacing"> </span>,<span class="heti-spacing"> </span></span>且在两次访问之间没有其他对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的写入发生，该读取将返回被写入的值。<ul>
<li>该性质定义了内存一致性的核心含义：若某个处理器能持续读取到过时的数据值，那么显然可以判定该内存处在不一致的状态。</li>
</ul>
</li>
<li><strong>写串行化</strong>(write serialization)：针对同一位置的写操作是<strong>可串行的</strong>(serialized)。也就是说，任何两个处理器对该位置的两次写操作，在所有处理器看来，都遵循相同的顺序。例如，若先后向某位置写入值<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>2</span>，所有处理器都不可能先读到<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>再读到<span><span class="heti-spacing"> </span>1</span>。</li>
</ul>
<p>尽管上述三个性质已足以确保一致性，但连贯性同样至关重要，比如：我们无法要求对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>的读取操作能立即获取其他处理器对<span class="heti-skip"><span class="heti-spacing"> </span>X<span class="heti-spacing"> </span></span>所写入的（最新）值，因为此时写入的数据甚至可能尚未离开原来的处理器。连贯性是由<strong>内存连贯性模型</strong><span>(memory consistency model)<span class="heti-spacing"> </span></span>定义的，其具体内容在<a href="#models-of-memory-consistency">后面</a>会介绍。</p>
<p>一致性与连贯性互为补充：</p>
<ul>
<li><strong>一致性</strong>规定了针对<strong>同一内存</strong>地址读写操作的行为</li>
<li>而<strong>连贯性</strong>则定义了涉及<strong>不同内存</strong>地址访问时的读写行为</li>
</ul>
<p>目前，我们作出以下两点基本假设：</p>
<ul>
<li>必须等到所有处理器都知道到写操作的结果后，该写操作才被视为完成任务（并允许后续写操作执行）</li>
<li>处理器不得调整任何写操作相对于其他内存访问的执行顺序<ul>
<li>这意味着若某处理器先后写入地址<span class="heti-skip"><span class="heti-spacing"> </span>A<span class="heti-spacing"> </span></span>和地址<span><span class="heti-spacing"> </span>B</span> ，任何观测到<span class="heti-skip"><span class="heti-spacing"> </span>B<span class="heti-spacing"> </span></span>新值的处理器必然也已获取<span class="heti-skip"><span class="heti-spacing"> </span>A<span class="heti-spacing"> </span></span>的新值</li>
</ul>
</li>
</ul>
<p>这些假设允许处理器重排读操作顺序，但强制其按照程序顺序来完成写操作。并且这些假设将一直沿用至介绍<a href="#models-of-memory-consistency">内存连贯性模型</a>时为止。</p>
<h3 id="basic-schemes-for-enforcing-coherence">Basic Schemes for Enforcing Coherence<a class="headerlink" href="#basic-schemes-for-enforcing-coherence" title="Permanent link">⚓︎</a></h3>
<p>在多处理器内运行的程序中，同一数据的多份拷贝通常会同时存在于各级高速缓存中。在一致性的多处理器中，高速缓存提供了共享数据的<strong>迁移</strong><span>(migration)<span class="heti-spacing"> </span></span>与<strong>复制</strong><span>(replication)<span class="heti-spacing"> </span></span>的双重功能。</p>
<ul>
<li><strong>迁移</strong>：数据项可透明地转移至本地高速缓存并被使用。这既降低了访问远程分配的共享数据的延迟，又缓解了共享内存的带宽压力。</li>
<li><strong>复制</strong>：有效减少了读取共享数据时的访问延迟和资源争用。</li>
</ul>
<p>由此可见，实现高效的迁移与复制对提升共享数据访问的性能而言至关重要。因此，多处理器引入硬件级协议来维护高速缓存的一致性。这个协议被称为<strong>高速缓存一致性协议</strong>(cache coherence protocols)，其实现核心在于追踪数据块的共享状态。每个缓存块的状态通过与之关联的<strong>状态位</strong>来维护（类似于单处理器高速缓存中的有效位和脏位<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。根据具体实现技术的不同，可以将协议分为以下两类：</p>
<ul>
<li><strong>基于目录</strong>(directory based)：<ul>
<li>特定物理内存块的共享状态被保存在一个称为<strong>目录</strong><span>(memory)<span class="heti-spacing"> </span></span>的位置。</li>
<li>存在两种截然不同的基于目录的缓存一致性方案：<ul>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>SMP<span class="heti-spacing"> </span></span>中，可采用与内存或其他单一串行化点（如多核芯片的最外层高速缓存）关联的<strong>集中式目录</strong></li>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>DSM<span class="heti-spacing"> </span></span>中，由于单个目录会阻碍性能，且难以满足多核架构的内存扩展需求，因此需采用<strong>分布式目录</strong>，但实现起来相对更复杂</li>
</ul>
</li>
</ul>
</li>
<li><strong>监听</strong>(snooping)：<ul>
<li>每个持有物理内存块数据拷贝的高速缓存均可追踪该块的共享状态</li>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>SMP<span class="heti-spacing"> </span></span>中，各个核的高速缓存通常通过广播介质（如核自己的高速缓存与共享高速缓存<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>内存之间的总线）实现互通，并且所有的高速缓存控制器通过持续监控或<strong>监听</strong><span>(snoop)<span class="heti-spacing"> </span></span>介质，以确认自身是否拥有在总线上，或交换访问中请求的目标数据块拷贝</li>
<li>侦听技术同样适用于多芯片多处理器的一致性协议</li>
</ul>
</li>
</ul>
<p><strong>监听协议</strong>在采用微处理器（单核<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，并通过总线连接至单一共享内存的多处理器系统中广受欢迎。其中，<strong>总线</strong>为实现监听协议提供了便捷的广播媒介。但多核架构改变了这一局面，因为所有多核芯片上的核都共享了一定级别的高速缓存。因此，部分设计转而采用<strong>目录协议</strong>，因其开销较小。</p>
<p>我们接下来先重点探讨监听协议，等到讨论<span class="heti-skip"><span class="heti-spacing"> </span>DSM<span class="heti-spacing"> </span></span>架构时再详细介绍目录协议。</p>
<h3 id="snooping-coherence-protocols">Snooping Coherence Protocols<a class="headerlink" href="#snooping-coherence-protocols" title="Permanent link">⚓︎</a></h3>
<p>要维持高速缓存一致性要求，有以下两种方法：</p>
<ul>
<li>
<p><strong>写无效协议</strong>(write invalidate protocol)：确保处理器在写入数据项前拥有对该项的<strong>独占访问权</strong></p>
<ul>
<li>独占访问能保证执行写入操作时不存在任何其他可读或可写的副本：该项数据的所有其他高速缓存的拷贝均会被置为<strong>无效</strong>状态</li>
<li>当<strong>读取</strong>操作发生时，高速缓存未命中，这迫使系统必须获取数据的新副本</li>
<li>对于<strong>写入</strong>操作，我们要求执行写入的处理器拥有独占访问权限，防止其他任何处理器同时进行写入<ul>
<li>若存在两个处理器试图同时写入同一数据的情况，其中一方将获胜，导致另一方的数据拷贝失效；另一方若要完成其写入操作，就必须获取包含最新更新值的数据新拷贝</li>
<li>由此可见，此协议确保了<strong>写串行化</strong></li>
</ul>
</li>
<li>这是目前最主流的协议</li>
</ul>
<details class="example">
<summary>例子</summary>
<p></p><div style="text-align: center">
<img src="images/C5/3.png" width="80%"/>
</div>
</details>
</li>
<li>
<p><strong>写更新</strong>(write update)/<strong>写广播</strong><span>(write broadcast)<span class="heti-spacing"> </span></span>协议：在写入数据项时更新该数据项的所有缓存拷贝</p>
<ul>
<li>由于写更新协议必须向所有共享缓存行广播写入操作，因而会消耗更多的带宽</li>
</ul>
</li>
</ul>
<p>所以，几乎所有现在的多处理器系统都选择实现<strong>写无效协议</strong>，后面我们也只关注这个协议。</p>
<h4 id="basic-implementation-techniques">Basic Implementation Techniques<a class="headerlink" href="#basic-implementation-techniques" title="Permanent link">⚓︎</a></h4>
<ul>
<li>在多核处理器中，实现无效协议的关键在于利用<strong>总线或其他广播媒介</strong>来执行无效操作。</li>
<li>在早期的多芯片多处理器系统中，用于一致性的总线就是共享内存访问总线；而在单芯片多核架构里，该总线可以是私有高速缓存与共享外部高速缓存之间的连接通道。</li>
<li>执行无效指令时，处理器只需获取总线控制权，并将待失效的地址通过总线广播出去。</li>
<li>所有处理器持续监听总线上的地址信号：若发现总线上出现的地址出现在自己的高速缓存中，则立即将对应的高速缓存数据标记为无效。</li>
<li>当对共享块进行写入操作时，执行写入的处理器必须获取总线访问权限，以广播其无效化请求。</li>
<li>若两个处理器同时尝试写入共享块，它们广播无效化操作的请求将在总线仲裁过程中被<strong>串行化</strong>处理；首先获得总线访问权的处理器将使其正在写入的块的所有其他拷贝失效。<ul>
<li>该机制的一个重要含义是：在获得总线访问权之前，对共享数据项的写操作实际上无法完成。</li>
</ul>
</li>
<li>所有一致性方案都需要某种方法来<strong>串行化</strong>对同一缓存块的访问，无论是通过串行化通信介质的访问途径，还是通过对另一个共享结构的控制来实现。</li>
<li>我们还需在发生高速缓存失效时定位数据项。<ul>
<li>在<strong>写穿式</strong><span>(write-through)<span class="heti-spacing"> </span></span>高速缓存中，查找数据项的当前值较为简单，因为所有已写入的数据都会立即发送至内存，从中总能获取到数据项的最新值。</li>
<li>对于<strong>写回式</strong><span>(write-back)<span class="heti-spacing"> </span></span>高速缓存而言，确定最新数据值的难度更大，因为数据项的最新值可能存在于私有高速缓存而非共享高速缓存或主存中。<ul>
<li>不过我们可以对高速缓存失效和写入操作采用相同的<strong>监听</strong>机制：<ul>
<li>每个处理器都会监听共享总线上传输的所有地址。</li>
<li>当某处理器发现自己持有目标缓存块的脏拷贝时，会将该缓存块作为读请求的响应内容返回，并终止对主存（或三级高速缓存）的访问。</li>
<li>该方法的复杂性在于需要从其他处理器的私有高速缓存（<span>L1<span class="heti-spacing"> </span></span>或<span><span class="heti-spacing"> </span>L2</span>）中获取目标块，这通常比访问三级高级缓存耗时更长。</li>
</ul>
</li>
<li>由于写回式缓存的<strong>内存带宽需求较低</strong>，因此能支持更多高速处理器的协同工作。正因如此，所有多核处理器都在最外层缓存采用写回策略。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>接下来我们将探讨基于写回式缓存的一致性实现方案。</p>
<ul>
<li>常规高速缓存的<strong>标签位</strong><span>(tags)<span class="heti-spacing"> </span></span>可用于实现监听机制，每个块的<strong>有效位</strong><span>(valid bit)<span class="heti-spacing"> </span></span>使得失效操作易于实施。</li>
<li>对于由失效或者其他事件触发的<strong>读失效</strong>问题，处理起来同样直接，因为它们仅依赖于监听功能。</li>
<li>对于<strong>写操作</strong>，我们需要知道该块是否存在其他缓存拷贝。如果没有的话，在写回式高速缓存中便无需将此次写操作置于总线上。不发送写请求既能缩短写入时间，又可节省所需带宽。</li>
<li>为了追踪一个高速缓存块是否被共享，我们可以为每个缓存块额外添加一个<strong>状态位</strong>(state bit)，从而能够判断写入操作是否需要产生无效化信号。</li>
<li>当对处于共享状态的块执行写操作时，该缓存会在总线上生成无效化命令并将该块标记为<strong>独占</strong><span>(exclusive)<span class="heti-spacing"> </span></span>状态，此后该核不再针对此块发送任何无效化请求。</li>
<li>拥有缓存块唯一拷贝的核通常被称为该缓存块的<strong>所有者</strong>(owner)。</li>
<li>当发送一条无效化指令时，所有者的高速缓存块状态会从共享状态转变为非共享（或独占）状态。若后续有其他处理器请求该缓存块，则必须将其状态重新置为共享。</li>
<li>由于我们的监听式高速缓存也能发现任何失效情况，因此它能知道独占高速缓存块何时被其他处理器请求，并且将状态恢复为共享。</li>
<li>每个总线事务都必须检查高速缓存地址的标签，这可能会干扰处理器的高速缓存访问。为了减少这种干扰，我们有以下措施：<ul>
<li><strong>复制</strong>标签，并将监听访问定向到标签拷贝上。</li>
<li>在共享的<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存处使用<strong>目录</strong>。该目录能够反映给定块是否被共享，以及可能哪些核拥有拷贝。有了目录信息，无效操作可以仅针对那些拥有该缓存块拷贝的高速缓存进行。这就要求<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>必须始终保留<span class="heti-skip"><span class="heti-spacing"> </span>L1<span class="heti-spacing"> </span></span>或<span class="heti-skip"><span class="heti-spacing"> </span>L2<span class="heti-spacing"> </span></span>中任何数据项的拷贝，这一特性称为<strong>包含性</strong>(inclusion)。</li>
</ul>
</li>
</ul>
<h4 id="a-simple-protocol">A Simple Protocol<a class="headerlink" href="#a-simple-protocol" title="Permanent link">⚓︎</a></h4>
<p>我们一般通过为每个核中集成一个<strong>有限状态控制器</strong>来实现监听式一致性协议。该控制器响应来自核内处理器及总线（或其他广播媒介）的请求，改变选定高速缓存块的状态，同时利用总线访问数据或使其失效。从逻辑上看，可以认为每个高速缓存块都关联着一个独立的控制器；这意味着针对不同缓存块的监听操作或缓存请求能够独立处理。实际实现中，单个控制器允许多个针对不同缓存块的操作以交错方式执行。</p>
<p>我们规定协议包含三种状态：</p>
<ul>
<li><strong>无效</strong>(invalid)</li>
<li><strong>共享</strong>(shared)：表示私有高速缓存中的块可能被多个核共享</li>
<li><strong>修改</strong>(modified)：表明某个块已在私有高速缓存中被更新；并且该状态意味着该块具有独占性。</li>
</ul>
<p>下表展示了由核产生的请求（上半部分）以及来自总线的请求（下半部分）与高速缓存一致性的关系：</p>
<div style="text-align: center">
<img src="images/C5/4.png" width="90%"/>
</div>
<p>当总线上出现无效请求或写失效时，所有私有高速缓存中存有该缓存块拷贝的核都会将其置为无效。对于写回式高速缓存的写失效情况，若该块仅存在于一个<strong>私有高速缓存</strong>，且处于独占状态，那么该缓存还需执行<strong>写回</strong>操作；否则可直接从共享高速缓存或主存读取数据。</p>
<p>下图展示了采用写无效协议和写回式高速缓存的单个私有高速缓存块的有限状态转换图（左图是<span class="heti-skip"><span class="heti-spacing"> </span>CPU<span class="heti-spacing"> </span></span>请求，右图是总线请求<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<img src="images/C5/5.png" width="90%"/>
</div>
<p>将两个状态转换图合并在一起，可以得到以下状态图：</p>
<div style="text-align: center">
<img src="images/C5/6.png" width="60%"/>
</div>
<ul>
<li>任何有效的高速缓存块要么处于一个或多个私有高速缓存的共享状态，要么严格位于单一高速缓存的独占状态。</li>
<li>任何向独占状态的转换（这是处理器写入块的必要条件）都要求在总线上发出无效或写失效信号，这将导致所有本地高速缓存将该块置为无效状态。</li>
<li>此外，若其他本地高速缓存曾以独占状态持有该块（变脏了<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，则该高速缓存会执行写回操作，从而提供包含目标地址的数据块。</li>
<li>最后，当总线出现针对独占状态块的读失效时，持有该独占拷贝的本地高速缓存会将其状态变更为共享状态。</li>
</ul>
<p>本协议的另一特性是：处于共享状态的内存块在外部共享高速缓存（<span>L2<span class="heti-spacing"> </span></span>或<span><span class="heti-spacing"> </span>L3</span>，若无共享高速缓存则为内存）中始终保持最新状态。这一特性显著简化了实现方案。</p>
<p>尽管这个简单的缓存协议能正确执行，但是它忽略了许多复杂情况。其中最重要的是该协议假设所有操作都是<strong>原子性的</strong>，即任一操作能够以不受其他操作干扰的方式完成，然而现实中并非如此。非原子性操作会引入协议<strong>死锁</strong><span>(deadlock)<span class="heti-spacing"> </span></span>的可能性，即进入无法继续执行的状态。在后面我们会讨论这些情况。</p>
<h3 id="extensions-to-the-basic-coherence-protols">Extensions to the Basic Coherence Protols<a class="headerlink" href="#extensions-to-the-basic-coherence-protols" title="Permanent link">⚓︎</a></h3>
<p>先前描述的一致性协议是一种简单的三状态协议，通常以其状态的首字母来指代，因此被称为 <strong>MSI</strong>（Modified（修改<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，Shared（共享<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，Invalid（无效<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>）协议。我们可以基于这一基础协议进行扩展，通过增加额外状态和事务来优化特定行为，从而（可能会）提升性能表现。其中，最常见的两种扩展是：</p>
<ul>
<li><strong>MESI</strong> 协议：增加了<strong>独占</strong><span>(exclusive)<span class="heti-spacing"> </span></span>状态，形成四种状态：修改<span><span class="heti-spacing"> </span>(modified)</span>、独占<span><span class="heti-spacing"> </span>(exclusive)</span>、共享<span class="heti-skip"><span class="heti-spacing"> </span>(shared)<span class="heti-spacing"> </span></span>和无效<span><span class="heti-spacing"> </span>(invalid)</span>。<ul>
<li>独占状态表示缓存块仅存在于单一高速缓存中，且未被修改。</li>
<li>若某个块处于独占状态，对其进行写入时无需产生失效信号，从而优化了同一高速缓存先读取后写入该数据块的场景。</li>
<li>当然，当对处于独占状态的块的读失效发生时，必须将该块转为共享状态以维持一致性。</li>
<li>添加独占状态的好处在于：当同一个核再次写入处于独占状态的数据块时，既不需要获取总线访问权，也不需生成失效信号，因为系统明确知晓该数据块仅存在于本地的这个高速缓存中；处理器只需将其状态改为已修改即可实现更新。</li>
<li>通过将一致性状态位编码为独占状态位、并用脏位标识修改情况即可轻松实现该状态的扩展应用。</li>
</ul>
</li>
<li><strong>MOESI</strong>协议：在<span class="heti-skip"><span class="heti-spacing"> </span>MESI<span class="heti-spacing"> </span></span>协议的基础上增加了<strong>拥有</strong><span>(owned)<span class="heti-spacing"> </span></span>状态，用于表示相关缓存块由该高速缓存持有，且主存中的拷贝已过时。<ul>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>MSI<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>MESI<span class="heti-spacing"> </span></span>协议中，当尝试共享处于修改状态的缓存块时，在原高速缓存和新的共享高速缓存中，该块的状态都会转变为共享状态，且必须将其写回主存。</li>
<li>而在<span class="heti-skip"><span class="heti-spacing"> </span>MOESI<span class="heti-spacing"> </span></span>协议中，原高速缓存的修改状态可以直接转换为拥有状态而无需立即写入内存。其他新的共享该块的高速缓存则保持共享状态；而仅由原高速缓存持有的拥有状态表明主存拷贝已失效，且指定高速缓存是所有者。</li>
<li>当发生失效时，所有者必须提供该数据块（因为主存未更新<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>；若被替换，则需将其写回主存。</li>
</ul>
</li>
</ul>
<h3 id="limitations-in-smps-and-snooping-protocols">Limitations in SMPs and Snooping Protocols<a class="headerlink" href="#limitations-in-smps-and-snooping-protocols" title="Permanent link">⚓︎</a></h3>
<p>随着多处理器中处理器数量的增加，或每个处理器的内存需求增长，系统中任何<strong>集中式资源</strong><span>(centralized resource)<span class="heti-spacing"> </span></span>都可能成为瓶颈。对于多核处理器而言，仅需少量核心，就能使单个共享总线形成性能瓶颈。因此，多核设计转向了更高带宽的互连方案，以及采用多个独立内存以支持更多核心数量。</p>
<p>监听式高速缓存的带宽也可能是一个限制，因为每个高速缓存都必须检查每一次的失效情况，而增加互连带宽只会将问题转嫁给高速缓存。下面给出一些增加监听带宽的技术：</p>
<ul>
<li><strong>复制标签位</strong>(tags)，实现带宽倍增</li>
<li>如果多核处理器共享最外层的高速缓存，那么可采用<strong>分布式</strong>的高速缓存——每个处理器分管部分内存区域，并处理对应地址空间的监听请求。<ul>
<li>鉴于<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>承担着过滤监听请求的功能，<span>L3<span class="heti-spacing"> </span></span>必须具备包容性<span><span class="heti-spacing"> </span>(inclusive)</span></li>
</ul>
</li>
<li>可在最外层的共享高速缓存层（如<span><span class="heti-spacing"> </span>L3</span>）设置一个<strong>目录</strong>。<ul>
<li>同样地，<span>L3<span class="heti-spacing"> </span></span>必须保持包容性。</li>
<li>引入目录结构后，无需广播至所有<span class="heti-skip"><span class="heti-spacing"> </span>L2<span class="heti-spacing"> </span></span>缓存，仅需查询目录指向的可能持有数据块拷贝的特定<span class="heti-skip"><span class="heti-spacing"> </span>L2<span class="heti-spacing"> </span></span>即可。</li>
<li>与前一种方法类似，其关联的目录条目亦可以分布式存储。</li>
</ul>
</li>
</ul>
<p>下图展示的就是一个采用分布式高速缓存系统的多核处理器：</p>
<div style="text-align: center">
<img src="images/C5/7.png" width="70%"/>
</div>
<h3 id="implementing-snooping-cache-coherence">Implementing Snooping Cache Coherence<a class="headerlink" href="#implementing-snooping-cache-coherence" title="Permanent link">⚓︎</a></h3>
<p>在单总线的多核处理器中，通过以下方式可使这些步骤具备实质原子性：</p>
<ul>
<li>首先（在更改缓存状态前<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，对通往共享高速缓存或内存的总线进行仲裁，并在所有操作完成前不释放总线。</li>
<li>使用单条线路来表示所有必要的无效化请求都已接收并正在处理。</li>
<li>收到该信号后，生成失效信号的处理器便可释放总线，因为它知道处理和下一个失效相关的任何活动之前，所有必需的操作都将完成。</li>
</ul>
<p>而在一个没有单一集中总线的系统中，则用其他方法来实现高速缓存失效操作的原子性。具体而言，必须确保两个处理器同时尝试写入同一数据块（这种情况称为<strong>竞争</strong>(race)）时遵循严格顺序：一个写操作被完整处理并先行完成后，另一个写操作才能开始执行。竞争中两个写操作的胜负并不重要，关键在于只存在唯一胜出者，其一致性操作能率先完成。</p>
<p>在多核架构中采用多总线设计时，只要确保每个内存块仅关联一条独立总线，就能通过该共享总线对同一数据块的访问请求进行串行化处理，从而消除竞争现象。这一特性与重启竞争失败方的高速缓存失效处理的能力相结合，构成了无需总线也能实现的监听式高速缓存一致性的关键要素。</p>
<p>实际设计中可混合使用侦听协议和目录协议。</p>
<h2 id="performance-of-symmetric-shared-memory-multiprocessors">Performance of Symmetric Shared-Memory Multiprocessors<a class="headerlink" href="#performance-of-symmetric-shared-memory-multiprocessors" title="Permanent link">⚓︎</a></h2>
<p>在使用监听一致性协议的多核处理器中，多种不同的现象共同影响着性能表现。具体而言，整体的高速缓存性能由单处理器的<strong>缓存失效流量</strong>和<strong>通信流量</strong>（导致无效化以及后续缓存失效）共同决定。改变处理器的数量、高速缓存的容量和块的大小都会影响带这两类关于失效率的要素。</p>
<p>而之前在计组课程中，我们知道<strong>单处理器</strong>的失效率可以被分解为三个<span><span class="heti-spacing"> </span>C</span>：<strong>容量</strong>(capacity)、<strong>强制</strong><span>(compulsory)<span class="heti-spacing"> </span></span>和<strong>冲突</strong>(conflict)。它们既揭示了应用程序行为特征，也为高速缓存的设计优化提供了方向。同理，由<strong>处理器间通信</strong>引发的失效（通常称为<strong>一致性失效</strong>(coherence misses)）也可归因于两个因素：</p>
<ul>
<li><strong>真共享失效</strong>(true sharing misses)：<ul>
<li>在基于无效的协议中，处理器首次写入共享缓存块时会触发无效操作，以确立对该块的所有权</li>
<li>此外，当其他处理器尝试读取该缓存块中被修改的数据字时，会发生失效并导致相应块的传输</li>
<li>上述两类失效均被归类为真共享缺失，因为它们直接源于处理器间的数据共享行为</li>
</ul>
</li>
<li><strong>伪共享失效</strong>(false sharing misses)：<ul>
<li>在基于无效的一致性算法中，每个缓存块仅有一个有效位；当某个块因其中某些数据字被写入而被无效化（随后使用便引发失效）时，便会出现了伪共享</li>
<li>若接收无效化的处理器实际使用了被写入的字，则该引用属于<strong>真共享引用</strong>，此时无论块有多大都会引发失效</li>
<li>然而，若被写入字与读取字不同，且无效化并未传递新值，仅造成额外缓存失效时，即为<strong>伪共享失效</strong>。</li>
<li>此时虽然块是被共享的，但高速缓存中并无实际共享的数据字；若块大小为单个字数据，则此失效不会发生。</li>
</ul>
</li>
</ul>
<details class="example">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"/><input id="__tabbed_1_2" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="__tabbed_1_1">题目</label><label for="__tabbed_1_2">答案</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/C5/8.png" width="80%"/>
</div>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/C5/9.png" width="80%"/>
</div>
</div>
</div>
</div>
</details>
<h3 id="commercial-workload">Commercial Workload<a class="headerlink" href="#commercial-workload" title="Permanent link">⚓︎</a></h3>
<p>本节将探究一台四处理器共享内存多处理机上运行在线事务处理<span class="heti-skip"><span class="heti-spacing"> </span>(<span class="heti-spacing"> </span></span><a href="https://en.wikipedia.org/wiki/Online_transaction_processing"><span class="heti-skip"><span class="heti-spacing"> </span>OLTP<span class="heti-spacing"> </span></span></a><span class="heti-skip"><span class="heti-spacing"> </span>)<span class="heti-spacing"> </span></span>工作负载时的内存系统行为，并重点分析其中高速缓存的活动，尤其是<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存的行为（其中存在大量与一致性机制相关的流量<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p>在研究的商业应用中，<span>OLTP<span class="heti-spacing"> </span></span>应用对内存系统的压力最大，即使在评估时使用更大的<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存，也表现出很大的挑战。</p>
<p>首先来探究 <strong><span>L3<span class="heti-spacing"> </span></span>高速缓存容量</strong>变化的影响：每个处理器的<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存容量从<span class="heti-skip"><span class="heti-spacing"> </span>1MiB<span class="heti-spacing"> </span></span>到<span class="heti-skip"><span class="heti-spacing"> </span>8MiB<span class="heti-spacing"> </span></span>不等。下图展示了采用两路组相联高速缓存时增大容量的收益效果：</p>
<div style="text-align: center">
<img src="images/C5/10.png" width="50%"/>
</div>
<p>可以看到，随着容量增加，失效率降低，因而程序执行时间也不断减小。值得注意的是，性能提升几乎全部集中在<span class="heti-skip"><span class="heti-spacing"> </span>1MiB -&gt; 2MiB<span class="heti-spacing"> </span></span>的阶段，继续扩容下去的话却收效甚微。为了搞清楚背后的原因，我们需要明确哪些因素会影响<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存的失效率，以及这些因素如何随着<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存的增大而变化。下图呈现了来自五个来源的每条指令所贡献的内存访问周期数：</p>
<div style="text-align: center">
<img src="images/C5/11.png" width="50%"/>
</div>
<ul>
<li>在<span class="heti-skip"><span class="heti-spacing"> </span>1MiB<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存下，影响内存访问周期的两大主要因素是指令失效和容量<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>冲突失效；而当缓存容量增大时，这两个因素的影响会变得微不足道</li>
<li>而强制失效、伪共享失效及真共享失效几乎不受缓存容量的影响。因此当容量较大时，<strong>真共享失效</strong>构成了高速缓存失效的主要部分；由于真共享失效数量保持不变，所以当<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存容量的提升超过<span class="heti-skip"><span class="heti-spacing"> </span>2MiB<span class="heti-spacing"> </span></span>后，整体失效率的降低幅度有限。</li>
</ul>
<p>综上，虽然增大高速缓存容量可消除大部分单处理器的失效，但是对多处理器的失效则没有太大影响。</p>
<p>接下来展示的是<strong>增加处理器数量</strong>对不同类型失效的影响：</p>
<div style="text-align: center">
<img src="images/C5/12.png" width="50%"/>
</div>
<p>不难发现，真共享失效率的上升并未因单处理器失效率下降而得到抵消，所以导致每条指令的内存访问周期整体增加。</p>
<p>最后要探讨的是<strong>增加块大小</strong>是否有助于改善此类工作负载的性能。这一做法理应能降低指令失效率和冷启动失效率，并在一定范围内减少容量<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>冲突失效率，甚至可能降低真实共享失效率。下图展示了当块大小从<span class="heti-skip"><span class="heti-spacing"> </span>32B<span class="heti-spacing"> </span></span>增至<span class="heti-skip"><span class="heti-spacing"> </span>256B<span class="heti-spacing"> </span></span>时，每千条指令的失效次数变化情况：</p>
<div style="text-align: center">
<img src="images/C5/13.png" width="50%"/>
</div>
<ul>
<li>真共享失效率降低至原来的<span class="heti-skip"><span class="heti-spacing"> </span>1/2<span class="heti-spacing"> </span></span>以下，表明真共享失效能够利用局部性原则得到缓解</li>
<li>强制失效率也显著下降，符合我们的预期</li>
<li>冲突<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>容量失效呈现小幅下降，这表明在这种情况下，空间局部性的程度并不高</li>
<li>伪共享失效率的占比虽然较小，但几乎翻了一倍</li>
<li>但指令失效率未受到显著影响，这一结果超出我们的预期。<ul>
<li>若是在指令缓存中有如此表现，我们可以得出空间局部性程度很低的结论</li>
<li>但在<span class="heti-skip"><span class="heti-spacing"> </span>L2<span class="heti-spacing"> </span></span>与<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>混合高速缓存的场景下，诸如指令<span class="heti-skip"><span class="heti-spacing"> </span>-<span class="heti-spacing"> </span></span>数据冲突等其他因素也可能导致大容量块时指令缓存的高失效率</li>
<li>已有研究证实，大型数据库和<span class="heti-skip"><span class="heti-spacing"> </span>OLTP<span class="heti-spacing"> </span></span>负载的指令流中存在较低的空间局部性特征——这类工作负载包含大量短基本块和专用代码序列</li>
<li>
<p>根据这些数据，要使更大块大小的<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>的性能与<span class="heti-skip"><span class="heti-spacing"> </span>32B<span class="heti-spacing"> </span></span>大小的块相当，其失效损失可表示为<span class="heti-skip"><span class="heti-spacing"> </span>32B<span class="heti-spacing"> </span></span>块大小失效值的倍数</p>
<p></p><div style="text-align: center">
<img src="images/C5/14.png" width="50%"/>
</div>
</li>
</ul>
</li>
</ul>
<h3 id="multiprogramming-and-os-workload">Multiprogramming and OS Workload<a class="headerlink" href="#multiprogramming-and-os-workload" title="Permanent link">⚓︎</a></h3>
<p>接下来研究的是一个<strong>多程序化的</strong>工作负载<span><span class="heti-spacing"> </span>(multiprogrammed workload)</span>，包含了用户活动与操作系统活动。这类工作负载呈现出三个特征鲜明的阶段：首先是基准程序的编译（涉及大量计算操作<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，接着是将目标文件安装到库中，最后是删除目标文件。最终阶段完全由<span class="heti-skip"><span class="heti-spacing"> </span>I/O<span class="heti-spacing"> </span></span>操作主导，仅有两个进程保持活跃状态（每个运行实例各一个<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。中间阶段同样以<span class="heti-skip"><span class="heti-spacing"> </span>I/O<span class="heti-spacing"> </span></span>为主导，处理器基本处于空闲状态。整体而言，该工作负载相比<span class="heti-skip"><span class="heti-spacing"> </span>OLTP<span class="heti-spacing"> </span></span>具有更显著的<strong>系统</strong>密集型和 <strong>I/O</strong> 密集型特性。</p>
<p>后续工作负载的测量中，我们假设采用以下内存与<span class="heti-skip"><span class="heti-spacing"> </span>I/O<span class="heti-spacing"> </span></span>系统的配置：</p>
<ul>
<li><span>L1<span class="heti-spacing"> </span></span>指令高速缓存：<span>32KB<span class="heti-spacing"> </span></span>容量，<span>64B<span class="heti-spacing"> </span></span>块大小的二路组相联结构，命中周期为<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个时钟周期。</li>
<li><span>L1<span class="heti-spacing"> </span></span>数据高速缓存：<span>32KB<span class="heti-spacing"> </span></span>容量，<span>32B<span class="heti-spacing"> </span></span>块大小的二路组相联结构，命中周期为<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个时钟周期。</li>
</ul>
<blockquote>
<p>注：与侧重<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存的<span class="heti-skip"><span class="heti-spacing"> </span>OLTP<span class="heti-spacing"> </span></span>负载不同，本次重点考察<span class="heti-skip"><span class="heti-spacing"> </span>L1<span class="heti-spacing"> </span></span>数据高速缓存的行为特征。</p>
</blockquote>
<ul>
<li><span>L2<span class="heti-spacing"> </span></span>高速缓存：<span>1MB<span class="heti-spacing"> </span></span>统一式设计，<span>128B<span class="heti-spacing"> </span></span>块大小的二路组相联结构，命中需<span class="heti-skip"><span class="heti-spacing"> </span>10<span class="heti-spacing"> </span></span>个时钟周期。</li>
<li>主存系统：单通道总线架构的存储器，访问时延为<span class="heti-skip"><span class="heti-spacing"> </span>100<span class="heti-spacing"> </span></span>个时钟周期。</li>
<li>硬盘系统：固定访问延迟<span><span class="heti-spacing"> </span>3ms</span>（低于常规值，以减少空闲等待时间<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
</ul>
<p>下表展示了八个处理器在上述参数配置下的执行时间分布情况。</p>
<div style="text-align: center">
<img src="images/C5/15.png" width="70%"/>
</div>
<p>执行时间被分解为以下部分：</p>
<ul>
<li><strong>空闲</strong>(idle)：在内核模式下空闲循环中执行的时长</li>
<li><strong>用户</strong>(user)：执行用户代码的时长</li>
<li><strong>同步</strong>(synchronization)：用于同步变量操作或等待的时长</li>
<li><strong>内核</strong>(kernel)：在<span class="heti-skip"><span class="heti-spacing"> </span>OS<span class="heti-spacing"> </span></span>内既非空闲也非同步访问的执行时长</li>
</ul>
<h4 id="performance">Performance<a class="headerlink" href="#performance" title="Permanent link">⚓︎</a></h4>
<p>接下来我们考察多道程序的工作负载在高速缓存大小和块大小变化时的性能表现。由于内核行为与用户进程存在差异，所以将这两部分分开来分析。尽管用户代码执行更多的指令，但操作系统的行为可能产生更多的高速缓存失效，除了代码体量更大以及局部性缺乏外，还有两个原因：</p>
<ul>
<li>内核在向用户分配内存页前会初始化所有的页，这显著增加了其强制性失效的比例。</li>
<li>内核实际存在数据共享的现象，因而会产生可观的一致性失效；相比之下，用户进程仅在被调度到不同处理器时才会引发一致性失效问题，且比例极低。</li>
</ul>
<p>下面两张图分别展示了内核与用户的数据失效率随数据高速缓存容量及块大小的变化关系：</p>
<div style="text-align: center">
<img src="images/C5/16.png" width="80%"/>
</div>
<ul>
<li>可以看到，增大数据高速缓存容量对用户失效率的影响显著高于对内核失效率的影响</li>
<li>而增加块大小则能同时改善两者的失效问题</li>
<li>这是因为较大比例的失效源自强制性失效和容量性失效——这两类问题均可通过采用更大的块来缓解</li>
<li>由于一致性失效相对罕见，增大块尺寸带来的负面影响较小。</li>
</ul>
<p>为了理解内核进程与用户进程表现差异的原因，我们需要进一步分析内核失效的行为特征。下图展示了内核失效率随高速缓存容量和块大小增加的变化情况：</p>
<div style="text-align: center">
<img src="images/C5/17.png" width="70%"/>
</div>
<ul>
<li>
<p>图表将失效问题划分成三类：</p>
<ul>
<li>强制性失效</li>
<li>一致性失效：包括真共享与伪共享</li>
<li>容量<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>冲突性失效：含操作系统与用户进程间、多用户进程间干扰引发的失效</li>
</ul>
</li>
<li>
<p>增大高速缓存容量仅能降低单处理器环境下的容量<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>冲突性失效率</p>
</li>
<li>而增大块尺寸则有效减少了强制性失效率</li>
<li>随着块尺寸的增加，一致性缺失率并未出现显著上升，这表明伪共享的影响可能微乎其微</li>
</ul>
<hr/>
<ul>
<li>对于多道程序的工作负载而言，<strong>操作系统</strong>对内存系统的需求更为严苛。</li>
<li>若工作负载中包含更多操作系统或类操作系统的活动，且其行为特征与本研究所测的情形相似，那么构建性能足够强大的内存系统将变得异常困难。</li>
<li>提升性能的潜在途径之一是通过改进<strong>编程环境</strong>或借助<strong>程序员</strong>辅助手段，使操作系统更具高速缓存感知能力。<ul>
<li>例如，操作系统会为不同系统调用产生的请求复用相同的内存区域。尽管这些被复用的内存将被完全覆写，但硬件因无法识别这一特性仍会维持缓存一致性机制运行，甚至可能尝试读取已失效的高速缓存块数据段。</li>
</ul>
</li>
</ul>
<h2 id="distributed-shared-memory-and-directory-based-coherence">Distributed Shared-Memory and Directory-Based Coherence<a class="headerlink" href="#distributed-shared-memory-and-directory-based-coherence" title="Permanent link">⚓︎</a></h2>
<p>前面介绍的监听协议要求每次高速缓存失效时，要和其他所有的高速缓存进行通信。这种不用集中式的数据结构来追踪高速缓存状态的特性，既是监听方案的优势（实现成本低廉<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，也是它的致命弱点，因为这使得它的可扩展性<span class="heti-skip"><span class="heti-spacing"> </span>(scalability)<span class="heti-spacing"> </span></span>很差。</p>
<p>近年来，多核处理器的发展迫使所有设计者转向<strong>分布式内存</strong>(distributed memory)，以满足各处理器对带宽的需求。这种内存组织能够提升内存带宽和互连带宽，因为它能立即将本地内存流量与远程内存流量分离，从而降低了对内存系统和互连网络的带宽需求。然而，若无法消除高速缓存失效时执行一致性协议的广播操作，那么分布式内存所带来的收益将极为有限。</p>
<p>另外，我们还提到过监听协议的替代方案——<strong>目录协议</strong>(directory protocol)。</p>
<ul>
<li>目录会记录每个可能被缓存的块的状态信息，包括哪些高速缓存（或高速缓存组）拥有该块的副本、数据是否是脏的（已被修改）等</li>
<li>在共享最外层缓存（L3）的多核处理器中，实现目录机制非常简单：只需为每个<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存块维护一个与核心数量等长的位向量即可<ul>
<li>该位向量能标识出哪些私有<span class="heti-skip"><span class="heti-spacing"> </span>L2<span class="heti-spacing"> </span></span>高速缓存可能持有<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存中的对应块副本，这样失效请求仅需发送至这些特定的高速缓存即可</li>
<li>当<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>采用包容性设计时，这种机制在单个多核芯片上能完美运作</li>
</ul>
</li>
<li>
<p>多核系统中，采用单个目录的解决方案不具备可扩展性，即便这避免了广播操作。所以我们必须设置<strong>分布式的目录</strong>，但分布方式需确保一致性协议能定位到任意缓存内存块的目录信息。</p>
<ul>
<li>容易想到的一种解决方法是让目录随内存单元分布——正如不同内存请求指向不同内存那样，不同的一致性请求也能访问到不同的分布式目录。</li>
<li>若将信息维护在<span class="heti-skip"><span class="heti-spacing"> </span>L3<span class="heti-spacing"> </span></span>高速缓存等多分区的外层高速缓存中，则可将目录信息分散到各个高速缓存分区间，从而有效提升带宽利用率。</li>
</ul>
</li>
<li>
<p>分布式目录具有以下特性：一个块的共享状态始终位于单个的已知位置。这一性质结合了维护节点缓存块的信息，使得一致性协议能够避免广播操作。</p>
</li>
<li>
<p>下图展示了添加目录至每个<strong>节点</strong>（单个多核处理器，或在内部实现一致性的小型处理器集合）后，分布式内存多处理器结构的示意图：</p>
<p></p><div style="text-align: center">
<img src="images/C5/18.png" width="80%"/>
</div>
</li>
<li>
<p>最简单的目录实现方式是：为每个内存块在目录中关联一个条目。</p>
<ul>
<li>此时信息总量与“内存块的数量<span class="heti-skip"><span class="heti-spacing"> </span>*<span class="heti-spacing"> </span></span>节点数量”的结果成正比</li>
<li>对于不超过数百个处理器（每个可能是多核）的多处理器而言，这种开销在合理块大小设置下是可接受的</li>
<li>而对于更大规模的多处理器系统，则需要采用能高效扩展目录结构的方法，不过我们无需考虑这种情况</li>
</ul>
</li>
</ul>
<h3 id="directory-based-cache-coherence-protocols">Directory-Based Cache Coherence Protocols<a class="headerlink" href="#directory-based-cache-coherence-protocols" title="Permanent link">⚓︎</a></h3>
<p>目录协议必须实现两个核心操作：处理<strong>读失效</strong>和处理对共享且干净的高速缓存块的<strong>写入</strong>。</p>
<p>为实现这些功能，目录需要追踪每个高速缓存块的状态。具体有以下几类状态：</p>
<ul>
<li><strong>共享</strong>：一个或多个节点缓存了该数据块，且内存中的数值与所有缓存副本保持同步更新</li>
<li><strong>未缓存</strong>(uncached)：没有任何节点持有该缓存块的副本</li>
<li><strong>已修改</strong>(modified)：只有一个节点持有该数据块副本，且已执行过写操作，因此内存中的对应副本失效；此时该处理器被称为此数据块的<strong>所有者</strong>(owner)</li>
</ul>
<p>除了跟踪状态外，还需要记录哪些节点拥有<strong>内存块的副本</strong>，因为在写入时需要使这些副本失效。实现这一功能的最简单方法是为每个内存块维护一个<strong>位向量</strong>。当内存块处于共享状态时，向量的每一位表示对应的处理器芯片是否持有该块的副本。当内存块处于独占状态时，我们同样可以利用这个位向量来追踪其所有者。</p>
<p>出于效率考虑，还会在各级高速缓存中单独记录每个高速缓存块的状态。</p>
<p>尽管状态转换时的具体操作略有差异，但各高速缓存中<strong>状态机</strong>的状态与转换机制与之前采用的监听式高速缓存方案完全一致。</p>
<p>而数据项的<strong>无效化</strong>处理及<strong>独占副本的定位</strong>操作则存在显著区别：这两种操作都需要请求节点与目录之间、目录与一个或多个远程节点之间进行通信；而在监听协议中，这两个步骤是通过向所有节点广播一起完成的。</p>
<p>下图展示了节点间传递的各类消息：</p>
<div style="text-align: center">
<img src="images/C5/19.png" width="90%"/>
</div>
<ul>
<li><strong>本地节点</strong><span>(local node)<span class="heti-spacing"> </span></span>是发起请求的节点，<strong>家节点</strong><span>(home node)<span class="heti-spacing"> </span></span>则是存储着目标地址对应内存位置及目录条目的节点。</li>
<li>物理地址空间采用静态分布方式，因此总能确定哪个节点存有特定的物理地址的内存和目录信息（例如高位比特可表示节点编号，低位比特则表示该节点内存中的偏移量<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
<li>当家节点同时作为本地节点时仍需访问目录，因为数据副本可能存在于被称为<strong>远程节点</strong><span>(remote node)<span class="heti-spacing"> </span></span>的第三方节点中。<ul>
<li><strong>远程节点</strong>是拥有高速缓存块副本的节点（无论该副本处在独占状态还是共享状态<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</li>
<li>远程节点可能与本地节点或家节点相同，此时处理器间消息可替换为处理器内消息，其他机制保持不变</li>
</ul>
</li>
</ul>
<h3 id="an-example-directory-protocol">An Example Directory Protocol<a class="headerlink" href="#an-example-directory-protocol" title="Permanent link">⚓︎</a></h3>
<p>下图展示了在基于目录的系统中，单个高速缓存的状态转换图：</p>
<div style="text-align: center">
<img src="images/C5/20.png" width="70%"/>
</div>
<ul>
<li>这张状态转换图操作与监听方案基本一致：状态和触发条件近乎相同。</li>
<li>不同之处是：监听机制通过总线（或其他网络）广播写失效操作，而在这里我们通过目录控制器，选择性地发送数据获取与无效化操作。</li>
<li>任何高速缓存块在写入时必须处于独占状态，且所有共享块必须在内存中保持最新值。</li>
<li>大多数多核处理器中，最外层的高速缓存由各核心共享，通过内部目录或监听机制来维护同一芯片上各核心私有高速缓存的一致性。因此只需接入最外层的共享高速缓存，便可利用芯片上多核一致性机制扩展至更庞大的处理器；而且此时处理器与一致性请求的竞争问题得以缓解，同时可避免标签位的重复。</li>
</ul>
<p>在基于目录的协议中，发送至目录的消息会触发两种不同类型的操作：<strong>更新目录状态</strong>，以及<strong>发送附加消息以满足请求</strong>。目录中的状态表示的是内存块中三种标准状态；但和监听式方案不同的是，这里的目录状态反映的是所有高速缓存副本的整体状况，而非单个块的状态。</p>
<p>为了追踪持有高速缓存块副本的节点集合，我们使用名为<strong>共享者</strong><span>(Sharers)<span class="heti-spacing"> </span></span>的位向量来实现这一功能。目录请求需要更新共享者，并通过读取该集合执行无效化操作。</p>
<p>下图展示了目录节点在接收消息后采取的操作（状态图结构和上图一致<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<img src="images/C5/21.png" width="70%"/>
</div>
<p>该目录会处理三种不同类型的请求：<strong>读失效</strong>(read miss)、<strong>写失效</strong><span>(write miss)<span class="heti-spacing"> </span></span>以及<strong>数据写回</strong>(data write-back)。</p>
<p>为了理解这些目录操作的机制，下面我们逐步分析各状态下收到的请求及执行的操作。</p>
<ul>
<li>
<p>当某个块处于<strong>未缓存</strong>状态时，内存中的副本即为当前有效值，因此可能出现以下请求类型：</p>
<ul>
<li><strong>读失效</strong>：请求节点从内存中获取所请求的数据，且该请求者成为唯一的共享节点；此时该数据块的状态被设为共享状态。</li>
<li><strong>写失效</strong>：请求节点接收值，并成为共享节点；该数据块被置为独占状态，以表明其唯一的有效副本已缓存；共享者<span class="heti-skip"><span class="heti-spacing"> </span>(Sharers)<span class="heti-spacing"> </span></span>字段标识其所有者身份。</li>
</ul>
</li>
<li>
<p>当块处于<strong>共享</strong>状态时，内存值是最新的，因此可能发生以下请求：</p>
<ul>
<li><strong>读失效</strong>：从内存中向请求节点发送所请求的数据，并将该请求节点加入共享者<span class="heti-skip"><span class="heti-spacing"> </span>(Sharers)<span class="heti-spacing"> </span></span>中。</li>
<li><strong>写失效</strong>：向请求节点发送值；向共享者中的所有节点发送失效消息，且共享者将更新为仅包含该请求节点的标识；此时该块的状态被设为独占状态。</li>
</ul>
</li>
<li>
<p>当块处于<strong>独占</strong>状态时，块的当前值由共享者（所有者）标识的节点上的缓存持有，因此存在以下目录请求：</p>
<ul>
<li><strong>读失效</strong>：<ul>
<li>向所有者发送数据获取消息，这使得所有者的高速缓存中的块状态转变为共享状态，并促使所有者将数据发送至目录。</li>
<li>数据在目录处被写入内存后回传给请求处理器。</li>
<li>请求节点的身份会被添加至仍包含原所有者处理器的身份（因它仍然持有可读副本）的共享者中。</li>
</ul>
</li>
<li><strong>数据写回</strong>：<ul>
<li>由于所有者正在替换该块，必须将其写回。</li>
<li>此操作使内存副本更新为最新状态（主目录实质上成为新的所有者<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，此时该块转为未缓存状态，且清空共享者。</li>
</ul>
</li>
<li><strong>写失效</strong>：<ul>
<li>该块将归属新的所有者。</li>
<li>系统会向原所有者发送消息，使其缓存中的块无效化，并将值传送至目录；随后目录将该值转发给请求节点使其成为新的所有者。</li>
<li>共享者更新为新所有者的信息，而该块的独占状态保持不变。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="synchronization">Synchronization<a class="headerlink" href="#synchronization" title="Permanent link">⚓︎</a></h2>
<p><strong>同步</strong><span>(synchronization)<span class="heti-spacing"> </span></span>机制通常由用户级的软件例程构建，这些例程依赖于硬件提供的同步指令。对于较小规模的多处理器系统或低竞争场景，关键的硬件能力在于提供一条不可中断的指令或指令序列，该指令能够以<strong>原子方式</strong>检索并修改数值。基于这一能力，便可构建出软件同步机制。本节重点探讨<strong>加锁</strong>与<strong>解锁</strong>这两类同步操作的实现原理；通过这两个操作，既能实现互斥访问控制，也可为更复杂的同步机制奠定基础。</p>
<h3 id="basic-hardware-primitives">Basic Hardware Primitives<a class="headerlink" href="#basic-hardware-primitives" title="Permanent link">⚓︎</a></h3>
<p>在多处理器系统中。实现同步所需的关键能力是一组能够实现<strong>原子化</strong>读取并修改内存位置的<strong>硬件原语</strong>(hardware primitives)。若缺乏这种能力，构建基本同步原语的成本将极为高昂，且会随着处理器数量的增加而递增。实际上存在多种基础硬件原语的替代方案，它们均提供对某一位置进行原子化读写的能力。但通常而言，架构师并不期望用户直接使用这些基础硬件原语，而是希望<strong>系统程序员</strong>利用它们来构建同步库。下面让我们从其中的一个硬件原语出发，展示如何利用它来构建一些基本的同步操作。</p>
<p>我们要介绍的硬件原语是<strong>原子交换</strong>(atomic exchange)，用于将寄存器中的值与内存中的值进行互换。</p>
<ul>
<li>假设我们需要构建一个简单锁：用<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>表示锁处于空闲状态，用<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>代表锁已被占用。</li>
<li>
<p>处理器尝试通过执行交换指令来获取锁：</p>
<ul>
<li>将寄存器中存放的<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>与锁对应的内存地址内容交换。</li>
<li>若其他处理器已持有该锁，则交换指令返回值为<span><span class="heti-spacing"> </span>1</span>；反之返回<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>时，该内存位置的值也会被同时更新为<span><span class="heti-spacing"> </span>1</span>，从而阻止其他竞争性交换操作同样获得<span><span class="heti-spacing"> </span>0</span>。</li>
</ul>
</li>
<li>
<p>例如：两个处理器同时尝试执行交换指令时，这种竞争会被打破：其中一个处理器必定会率先完成交换并返回<span><span class="heti-spacing"> </span>0</span>，而第二个处理器的交换操作将返回<span><span class="heti-spacing"> </span>1</span>。</p>
</li>
<li>使用交换原语实现同步的关键在于其<strong>原子性</strong>：整个交换过程不可分割，且两个并发执行的交换会通过<strong>写串行化</strong>机制确定先后顺序。</li>
</ul>
<p>此外还有其他用于实现同步的原子原语，但它们都具备一个关键特性：以可判断两项操作是否原子执行的方式读取并更新内存值。下面介绍其中一些原子原语：</p>
<ul>
<li><strong>测试并置位</strong>(test-and-set)：对值进行检测，若通过检测则设置新值。<ul>
<li>我们可以定义一个检测数值是否为<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>并将其置<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>的操作，其使用方式类似于原子交换操作。</li>
</ul>
</li>
<li><strong>获取并递增</strong>(fetch-and-increment)：返回内存位置的值，并以原子方式将其递增。<ul>
<li>通过用<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>表示同步变量未被占用，我们可以像运用交换操作那样使用这种指令。</li>
</ul>
</li>
</ul>
<p>实现单一原子内存操作会带来一些挑战，因为这需要在一个不可中断的指令中同时完成内存读取和写入。这一要求使得一致性的实现复杂化——硬件既不允许在读写之间插入任何其他操作，又必须避免死锁情况的发生。</p>
<p>另一种类型的硬件原语是使用<strong>一对指令</strong>，其中通过第二条指令的返回值来推断这对指令是否以原子方式执行。如果这对指令看起来像是所有其他处理器执行的操作都发生在它们之前或之后的话，那么这对指令实际上就具备原子性。这正是<span class="heti-skip"><span class="heti-spacing"> </span>MIPS<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>RISC-V<span class="heti-spacing"> </span></span>架构所采用的方法。</p>
<p>在<span class="heti-skip"><span class="heti-spacing"> </span>RISC-V<span class="heti-spacing"> </span></span>中，这对指令包括一种特殊的加载操作（称为<strong>保留加载</strong>(load reserved)）<code>lr</code> 和一种特殊的存储操作（称为<strong>条件存储</strong>(store conditional)<heti-adjacent class="heti-adjacent-half">）</heti-adjacent><code>sc</code>。</p>
<ul>
<li>保留加载将 <code>rs1</code> 指定的内存内容加载到 <code>rd</code> 寄存器中，并在该内存地址上创建一个保留标记</li>
<li>条件存储则将 <code>rs2</code> 中的值存入 <code>rs1</code> 指定的内存地址上</li>
<li>若在此期间有其他写入操作破坏了该内存位置的保留状态，则条件存储失败，并向 <code>rd</code> 写入非零值</li>
<li>若成功执行则向 <code>rd</code> 写入<span><span class="heti-spacing"> </span>0</span></li>
<li>如果在两条指令之间，处理器进行了上下文切换，那么条件存储也会失败</li>
<li>我们可以用这对指令来构建其他同步原语</li>
<li>用<strong>保留寄存器</strong><span>(reversed register)<span class="heti-spacing"> </span></span>中跟踪 <code>lr</code> 指令指定的地址</li>
<li>若发生中断，或链接寄存器中的地址对应的缓存块失效（例如由另一条 <code>sc</code> 指令导致<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，则链接寄存器会被清零</li>
<li><code>sc</code> 指令仅检查其地址是否与保留寄存器的地址匹配：匹配则成功执行，否则失败</li>
<li>由于在出现对加载保留地址的重复存储尝试或任何异常后，存储条件操作都将失败，因此必须谨慎选择插入这两条指令之间的其他指令，因此我们只应安全地允许<strong>寄存器<span class="heti-skip"><span class="heti-spacing"> </span>-<span class="heti-spacing"> </span></span>寄存器型操作</strong>，否则可能引发死锁</li>
<li>此外，为降低无关事件或竞争处理器频繁导致存储条件失败的概率，加载保留与存储条件之间的指令数量应当<strong>尽可能少</strong></li>
</ul>
<details class="example" open="open">
<summary>例子</summary>
<div class="language-asm highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nl">try:</span><span class="w"> </span><span class="nf">mov</span><span class="w"> </span><span class="no">x3</span><span class="p">,</span><span class="no">x4</span><span class="w">        </span><span class="c1">; mov exchange value</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="w">    </span><span class="nf">lr</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">x1</span><span class="w">         </span><span class="c1">; load reserved from</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="w">    </span><span class="nf">sc</span><span class="w"> </span><span class="no">x3</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">      </span><span class="c1">; store conditional</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="w">    </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x3</span><span class="p">,</span><span class="no">try</span><span class="w">      </span><span class="c1">; branch store fails</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="w">    </span><span class="nf">mov</span><span class="w"> </span><span class="no">x4</span><span class="p">,</span><span class="no">x2</span><span class="w">        </span><span class="c1">; put load value in x4</span>
</span></code></pre></div>
</details>
<h3 id="implementing-locks-using-coherence">Implementing Locks Using Coherence<a class="headerlink" href="#implementing-locks-using-coherence" title="Permanent link">⚓︎</a></h3>
<p>一旦有了原子操作后，便可以利用多处理器的一致性机制来实现<strong>自旋锁</strong>(spin lock)。处理器会持续尝试获取这类锁，循环等待直至成功。当程序员预估持有锁的时间很短，且希望加锁过程在锁可用时具备低延迟特性时，会采用自旋锁。不过，自旋锁会让处理器陷入等待释放的循环中占用资源，因此在某些场景下并不适用。</p>
<p>若没有缓存一致性机制，最简单的实现方式是将锁存储于内存中。</p>
<ul>
<li>处理器可通过原子操作不断尝试获取锁，并检测交换操作是否返回了空闲状态的锁</li>
<li>释放锁时，处理器仅需向该地址存入数值<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>即可解锁</li>
</ul>
<p>自旋锁的相关代码序列如下：</p>
<div class="language-asm highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="w">        </span><span class="nf">addi</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">R0</span><span class="p">,</span><span class="mi">#1</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="nl">lockit:</span><span class="w"> </span><span class="nf">EXCH</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">    </span><span class="c1">; atomic exchange</span>
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="w">        </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">lockit</span><span class="w">   </span><span class="c1">; already locked?</span>
</span></code></pre></div>
<p>若多处理器支持缓存一致性，便可通过该机制对锁进行缓存，以维持锁的一致性。<strong>缓存锁</strong><span>(caching lock)<span class="heti-spacing"> </span></span>具有以下优势：</p>
<ul>
<li>
<p>它使得<span class="heti-skip"><span class="heti-spacing"> </span>"<span class="heti-spacing"> </span></span>自旋<span class="heti-skip"><span class="heti-spacing"> </span>"<span class="heti-spacing"> </span></span>过程（即在紧凑的循环中反复测试并获取锁）可在本地缓存副本上完成，无需在每次尝试获取锁时都去访问全局内存。</p>
<ul>
<li>需要修改前面的自旋锁过程，使其通过在本地锁的副本上执行读取操作来自旋，直到成功看到锁可用。</li>
<li>该过程尝试通过执行交换操作来获取锁；处理器首先读取锁，以测试其状态。</li>
<li>处理器持续读取和测试，直到读取的值表明已经解锁。</li>
<li>然后处理器与其他所有类似“自旋等待”的过程竞争，看哪个可以首先为变量加锁。</li>
<li>所有进程都使用一个交换指令：该指令读取旧值，并将<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>存储到锁变量中；唯一的胜者会看到<span><span class="heti-spacing"> </span>0</span>，而失败者会看到胜者放置的<span><span class="heti-spacing"> </span>1</span>。</li>
<li>获胜的处理器执行锁之后的代码，完成后，将<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>存储到锁变量中以释放锁，然后重新开始了新的竞争。</li>
<li>
<p>以下是执行此自旋锁的代码（注意：<span>0<span class="heti-spacing"> </span></span>表示未锁定，<span>1<span class="heti-spacing"> </span></span>表示锁定<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div class="language-asm highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="nl">lockit:</span><span class="w"> </span><span class="nf">ld</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">         </span><span class="c1">; load of lock</span>
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="w">        </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">lockit</span><span class="w">      </span><span class="c1">; not available-spin</span>
</span><span id="__span-2-3"><a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="w">        </span><span class="nf">addi</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">R0</span><span class="p">,</span><span class="mi">#1</span><span class="w">       </span><span class="c1">; load locked value</span>
</span><span id="__span-2-4"><a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="w">        </span><span class="nf">EXCH</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">       </span><span class="c1">; swap</span>
</span><span id="__span-2-5"><a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="w">        </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">lockit</span><span class="w">      </span><span class="c1">; branch if lock wasn’t 0</span>
</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p>最近使用过该锁的处理器很可能在短期内再次使用。此时锁可能仍留在该处理器的缓存中，从而大幅缩短获取锁的时间。</p>
</li>
</ul>
<p>下表展示了多个进程通过原子交换指令争着为变量加锁时，处理器与总线<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>目录的交互过程：</p>
<div style="text-align: center">
<img src="images/C5/22.png" width="90%"/>
</div>
<ul>
<li>当持有锁的处理器向锁写入<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>时，所有其他高速缓存中的副本都会无效化，必须重新获取新值以更新本地副本。</li>
<li>其中某个高速缓存会率先获得解锁状态的值（0<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，并执行交换操作成功上锁；那么当其他处理器的高速缓存失效请求得到响应时，会发现该变量已被锁定，于是只能继续进入测试并保持自旋状态</li>
</ul>
<p>上述例子还揭示了保留加载<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>条件存储原语的另一优势：读操作与写操作被显式分离。这一特性使得以下代码序列能够实现与上述优化版交换指令相同的性能表现：</p>
<div class="language-asm highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="nl">lockit:</span><span class="w"> </span><span class="nf">lr</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">         </span><span class="c1">; load reserved</span>
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="w">        </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">lockit</span><span class="w">      </span><span class="c1">; not available-spin</span>
</span><span id="__span-3-3"><a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="w">        </span><span class="nf">addi</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">R0</span><span class="p">,</span><span class="mi">#1</span><span class="w">       </span><span class="c1">; locked value</span>
</span><span id="__span-3-4"><a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="w">        </span><span class="nf">sc</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="mi">0</span><span class="p">(</span><span class="no">x1</span><span class="p">)</span><span class="w">         </span><span class="c1">; store</span>
</span><span id="__span-3-5"><a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="w">        </span><span class="nf">bnez</span><span class="w"> </span><span class="no">x2</span><span class="p">,</span><span class="no">lockit</span><span class="w">      </span><span class="c1">; branch if store fails</span>
</span></code></pre></div>
<h2 id="models-of-memory-consistency">Models of Memory Consistency<a class="headerlink" href="#models-of-memory-consistency" title="Permanent link">⚓︎</a></h2>
<h2 id="cross-cutting-issues">Cross-Cutting Issues<a class="headerlink" href="#cross-cutting-issues" title="Permanent link">⚓︎</a></h2>
<h2 id="fallacies-and-pitfalls">Fallacies and Pitfalls<a class="headerlink" href="#fallacies-and-pitfalls" title="Permanent link">⚓︎</a></h2>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="最后更新">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年5月16日 18:34:31">2025年5月16日 18:34:31</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="创建日期">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年3月2日 21:04:42">2025年3月2日 21:04:42</span>
</span>
</aside>
<p style="font-size: 30px; font-weight: 600">评论区</p>
<div>
    如果大家有什么问题或想法，欢迎在下方留言~
  </div>
<!-- Insert generated snippet here -->
<script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOMAb9Zs4CfmpP" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="noughtq/notebook" data-repo-id="R_kgDOMAb9Zg" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
<!-- 标题计数器 -->
<link href="/css/counter.css" rel="stylesheet"/>
<!-- 主页个性化 -->
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="上一页: Chap 4: Data-Level Parallelism in Vector, SIMD, and GPU Architectures" class="md-footer__link md-footer__link--prev" href="4.html">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 320 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                上一页
              </span>
<div class="md-ellipsis">
                Chap 4: Data-Level Parallelism in Vector, SIMD, and GPU Architectures
              </div>
</div>
</a>
<a aria-label="下一页: 数据库系统" class="md-footer__link md-footer__link--next" href="../db/index.html">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                数据库系统
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 320 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright" style="margin-left: 33.5%">
<div class="md-copyright__highlight" style="text-align: center">
        Copyright © 2024-2025 <a href="https://github.com/NoughtQ">NoughtQ</a>
</div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" rel="noopener" target="_blank">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
        Material
      </a>
      modified by
      <a href="https://github.com/NoughtQ" rel="noopener" target="_blank">
        NoughtQ
      </a>
<!-- <br> -->
<div style="text-align: center;">
<a href="https://icp.gov.moe/?keyword=20252357" target="_blank">萌ICP备20252357号</a>
</div>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/noughtq" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://blog.noughtq.top" rel="noopener" target="_blank" title="blog.noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M192 32c0 17.7 14.3 32 32 32 123.7 0 224 100.3 224 224 0 17.7 14.3 32 32 32s32-14.3 32-32C512 128.9 383.1 0 224 0c-17.7 0-32 14.3-32 32m0 96c0 17.7 14.3 32 32 32 70.7 0 128 57.3 128 128 0 17.7 14.3 32 32 32s32-14.3 32-32c0-106-86-192-192-192-17.7 0-32 14.3-32 32m-96 16c0-26.5-21.5-48-48-48S0 117.5 0 144v224c0 79.5 64.5 144 144 144s144-64.5 144-144-64.5-144-144-144h-16v96h16c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48z"></path></svg>
</a>
<a class="md-social__link" href="mailto:noughtq666@gmail.com" rel="noopener" target="_blank" title="">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.copy", "content.code.annotate", "content.footnote.tooltips", "header.autohide", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.indexes", "navigation.tracking", "navigation.prune", "search.share"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.13a4f30d.min.js"></script>
<script src="../../js/anchor.js"></script>
<script src="../../js/katex.js"></script>
<script src="../../js/toc.js"></script>
<script src="../../js/typed.js"></script>
<script src="../../js/custom.js"></script>
<script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
<script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
</body>
</html>