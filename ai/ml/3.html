<!DOCTYPE html>
<html class="no-js" lang="zh"><head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="NoughtQ的笔记本，主要记录一些 CS 相关的笔记" name="description"/>
<meta content="NoughtQ" name="author"/>
<link href="https://notebook.noughtq.top/ai/ml/3.html" rel="canonical"/>
<link href="2.html" rel="prev"/>
<link href="4.html" rel="next"/>
<link href="../../feed_rss_created.xml" rel="alternate" title="RSS 订阅" type="application/rss+xml"/>
<link href="../../feed_rss_updated.xml" rel="alternate" title="已更新内容的 RSS 订阅" type="application/rss+xml"/>
<link href="../../assets/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.18" name="generator"/>
<title>Deep Learning - NoughtQ的笔记本</title>
<link href="../../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=JetBrains+Mono,+LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono,+Consolas:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"JetBrains Mono, LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono, Consolas"}</style>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="../../css/toc_extra.css" rel="stylesheet"/>
<link href="../../css/timeline.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/extra_changelog.css" rel="stylesheet"/>
<link href="../../css/header.css" rel="stylesheet"/>
<link href="../../css/sidebar.css" rel="stylesheet"/>
<link href="https://unpkg.com/katex@0/dist/katex.min.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&amp;display=swap" rel="stylesheet"/>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-43NH8CVRCJ"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-43NH8CVRCJ",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-43NH8CVRCJ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#deep-learning">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="NoughtQ的笔记本" class="md-header__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            NoughtQ的笔记本
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Deep Learning
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Dark Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Dark Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
<input aria-label="Light Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Light Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<a aria-label="分享" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="分享">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../index.html">
          
  
  
    
  
  🏫主页

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../lang/index.html">
          
  
  
    
  
  🔡编程语言

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../math/index.html">
          
  
  
    
  
  📊数学相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../algorithms/index.html">
          
  
  
    
  
  🧮算法相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../software/index.html">
          
  
  
    
  
  💾软件相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../system/index.html">
          
  
  
    
  
  💻系统相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../web/index.html">
          
  
  
    
  
  🌏Web相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../sec/ctf-101/index.html">
          
  
  
    
  
  🛡️信息安全

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../index.html">
          
  
  
    
  
  🤖人工智能

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../misc/index.html">
          
  
  
    
  
  🗃️杂项

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tools/index.html">
          
  
  
    
  
  🛠️工具

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../papers/index.html">
          
  
  
    
  
  📑论文阅读

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="NoughtQ的笔记本" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
    NoughtQ的笔记本
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../index.html">
<span class="md-ellipsis">
    🏫主页
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../lang/index.html">
<span class="md-ellipsis">
    🔡编程语言
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../math/index.html">
<span class="md-ellipsis">
    📊数学相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../algorithms/index.html">
<span class="md-ellipsis">
    🧮算法相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../software/index.html">
<span class="md-ellipsis">
    💾软件相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../system/index.html">
<span class="md-ellipsis">
    💻系统相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../web/index.html">
<span class="md-ellipsis">
    🌏Web相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../sec/ctf-101/index.html">
<span class="md-ellipsis">
    🛡️信息安全
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../index.html">
<span class="md-ellipsis">
    🤖人工智能
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
            🤖人工智能
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="index.html">
<span class="md-ellipsis">
    机器学习
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9_2" id="__nav_9_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_9_2">
<span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1.html">
<span class="md-ellipsis">
    Machine Learning - P1
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2.html">
<span class="md-ellipsis">
    Machine Learning - P2
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Deep Learning
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="3.html">
<span class="md-ellipsis">
    Deep Learning
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#introduction">
<span class="md-ellipsis">
      Introduction
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-deep">
<span class="md-ellipsis">
      Why Deep?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cnn">
<span class="md-ellipsis">
      CNN
    </span>
</a>
<nav aria-label="CNN" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#neuron-version-story">
<span class="md-ellipsis">
      Neuron Version Story
    </span>
</a>
<nav aria-label="Neuron Version Story" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#observation-and-simplification-1">
<span class="md-ellipsis">
      Observation and Simplification 1
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#observation-and-simplification-2">
<span class="md-ellipsis">
      Observation and Simplification 2
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-version-story">
<span class="md-ellipsis">
      Filter Version Story
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pooling">
<span class="md-ellipsis">
      Pooling
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4.html">
<span class="md-ellipsis">
    Self-Attention
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="5.html">
<span class="md-ellipsis">
    Transformer
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="6.html">
<span class="md-ellipsis">
    Generative Adversarial Network
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="7.html">
<span class="md-ellipsis">
    Self-Supervised Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="8.html">
<span class="md-ellipsis">
    Explainable Machine Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="9.html">
<span class="md-ellipsis">
    Adversarial Attack
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="10.html">
<span class="md-ellipsis">
    Adaptation
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="11.html">
<span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="12.html">
<span class="md-ellipsis">
    Network Compression
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="13.html">
<span class="md-ellipsis">
    Life-long Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="14.html">
<span class="md-ellipsis">
    Meta Learning
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../genai/index.html">
<span class="md-ellipsis">
    生成式人工智能
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../cv/index.html">
<span class="md-ellipsis">
    计算机视觉
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../toolbox/index.html">
<span class="md-ellipsis">
    工具箱
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../misc/index.html">
<span class="md-ellipsis">
    🗃️杂项
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tools/index.html">
<span class="md-ellipsis">
    🛠️工具
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../papers/index.html">
<span class="md-ellipsis">
    📑论文阅读
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#introduction">
<span class="md-ellipsis">
      Introduction
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-deep">
<span class="md-ellipsis">
      Why Deep?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cnn">
<span class="md-ellipsis">
      CNN
    </span>
</a>
<nav aria-label="CNN" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#neuron-version-story">
<span class="md-ellipsis">
      Neuron Version Story
    </span>
</a>
<nav aria-label="Neuron Version Story" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#observation-and-simplification-1">
<span class="md-ellipsis">
      Observation and Simplification 1
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#observation-and-simplification-2">
<span class="md-ellipsis">
      Observation and Simplification 2
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-version-story">
<span class="md-ellipsis">
      Filter Version Story
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pooling">
<span class="md-ellipsis">
      Pooling
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/edit/master/docs/ai/ml/3.md" rel="edit" title="编辑此页">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/raw/master/docs/ai/ml/3.md" title="查看本页的源代码">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
</a>
<h1 id="deep-learning">Deep Learning<a class="headerlink" href="#deep-learning" title="Permanent link">⚓︎</a></h1>
<div style="margin-top: -30px; font-size: 0.9em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>4528<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>23<span class="heti-spacing"> </span></span>分钟</p>
</div>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">⚓︎</a></h2>
<p>在前面介绍的机器学习的训练中，找到合适的参数后，便可以通过模型得到一组较为准确的一组预测值<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{a}\)</span></span>（向量<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。难道这样就结束了吗？我们还可以将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{a}\)</span><span class="heti-spacing"> </span></span>再一次代入这个模型中，得到<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{a}'\)</span></span>，...，以此类推。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/1.png"><img src="images/lec3/1.png" width="80%/"/></a>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/2.png"><img src="images/lec3/2.png" width="80%/"/></a>
</div>
<p>在机器学习中，我们通常为上图的计算过程赋予这些名称：</p>
<ul>
<li><strong>神经元</strong>(neuron)：包括输入（通过权重和偏移对一组数据求和<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>、激活函数和输出<ul>
<li>网络参数<span><span class="heti-spacing"> </span>(network parameter)<span class="arithmatex">\(\theta\)</span></span>：神经元的所有权重和偏移</li>
</ul>
</li>
<li><strong>神经网络</strong>(neural network)：由众多这样的神经元构成的集体，类似一张网（模拟人类的大脑）<ul>
<li>这里的神经网络称为<strong>全连接神经网络</strong>(fully-connected neural network)，这种网络的特点是每个神经元接受所有的输入，且都有各自的权重和偏移，因此相当灵活；但缺点是效率不高</li>
</ul>
</li>
<li><strong>层</strong>(layer)：相当于一次训练的过程<ul>
<li><strong>输入层</strong>(input layer)：初始输入的数据集</li>
<li><strong>隐藏层</strong>(hidden layer)：中间的一排排神经元</li>
<li><strong>输出层</strong>(output layer)：最后一层神经元，得到训练结果</li>
</ul>
</li>
</ul>
<p>多次训练意味着有多层的神经元，看起来就很“深”，因此称之为<strong>深度学习</strong>(deep learning)。</p>
<details class="example">
<summary>（有些过时的）例子</summary>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/3.png"><img src="images/lec3/3.png" width="80%/"/></a>
</div><p></p>
</details>
<p>根据实际经验，随着层数的加深，训练结果的质量会不断提升，但也不是始终能够提升——到达一定层数后，虽然对于训练数据的预测更准确，但是对未来的预测结果的质量反而会下降，这种情况称为<strong>过拟合</strong>(overfitting)。因此，我们不会让层数一直深下去的，合适的层数需要通过直觉<span class="heti-skip"><span class="heti-spacing"> </span>(intuition)<span class="heti-spacing"> </span></span>和不断的试错<span class="heti-skip"><span class="heti-spacing"> </span>(trial and error)<span class="heti-spacing"> </span></span>得到。</p>
<h2 id="why-deep">Why Deep?<a class="headerlink" href="#why-deep" title="Permanent link">⚓︎</a></h2>
<p>现在来思考一个问题：我们为什么要搭建深层的神经网络，而不是更浅更“胖”的神经网络呢？</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/30.png"><img src="images/lec3/30.png" width="60%/"/></a>
</div>
<p>假设上面的两个神经网络具备相同数量的参数，那么究竟哪一个的表现更好呢？前人对此做过研究了，结果如下（表格前两列表示深层网络，后两列表示浅层网络，同一行的网络参数数量相等<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/31.png"><img src="images/lec3/31.png" width="70%/"/></a>
</div>
<ul>
<li>随着层数（深度）的增加，神经网络的表现会越来越好</li>
<li>在参数数量相等的情况下，深层网络的表现显著优于浅层网络</li>
<li>同一层网络规模的增加（即变得更“胖”）并不一定会改善神经网络的表现</li>
</ul>
<p>因此，深层网络可以用更少的参数达到和浅层网络相等甚至更好的表现，而更少的参数也意味着更不容易发生过拟合等问题，因此我们才会推崇“深度学习”。</p>
<p>但是，为什么更深意味着更好呢？在前面的学习中，我们知道理论上是可以只用一层神经元来表示任意的函数（模型<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>（回忆一下：任意函数<span class="heti-skip"><span class="heti-spacing"> </span>=<span class="heti-spacing"> </span></span>常量<span class="heti-skip"><span class="heti-spacing"> </span>+ sigmoid/ReLu<span class="heti-spacing"> </span></span>函数的组合<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，当然这一层上会有很多很多的参数。然而，通过多层的结构，我们可以更加<strong>高效</strong>地表示函数，具体来说就是深层网络可以用更少的参数达到相同的效果：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/32.png"><img src="images/lec3/32.png" width="60%/"/></a>
</div>
<details class="example">
<summary>一些类比</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="1:3"><input checked="" id="__tabbed_1_1" name="__tabbed_1" type="radio"/><input id="__tabbed_1_2" name="__tabbed_1" type="radio"/><input id="__tabbed_1_3" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="__tabbed_1_1">逻辑电路</label><label for="__tabbed_1_2">编程</label><label for="__tabbed_1_3">剪纸</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/33.png"><img src="images/lec3/33.png" width="70%/"/></a>
</div><p></p>
<p>用逻辑门构建一个<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(d\)</span><span class="heti-spacing"> </span></span>位奇偶校验器（这里是偶校验）</p>
<ul>
<li>如果只用两层电路的话，那么需要<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(O(2^d)\)</span><span class="heti-spacing"> </span></span>个逻辑门（每一位都有<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>两种可能）</li>
<li>如果使用多层电路的话，电路图就如上所示，这时只需要<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(O(d)\)</span><span class="heti-spacing"> </span></span>个逻辑门就<span class="heti-skip"><span class="heti-spacing"> </span>OK<span class="heti-spacing"> </span></span>了</li>
</ul>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/34.png"><img src="images/lec3/34.png" width="70%/"/></a>
</div><p></p>
<p>在编写一个大型项目的时候，我们通常不会将所有的功能都放在主函数中实现（类比一层很胖的神经元<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，而是将不同功能放在不同模块（或子函数）中实现，而这些模块可能会调用下面的其他子模块，好比深层次的神经网络。</p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/35.png"><img src="images/lec3/35.png" width="70%/"/></a>
</div><p></p>
<p>在正式剪纸之前，我们往往会先将纸对折几次（类比深层的神经网络）后再开始剪，这样相比直接在纸上剪（类比浅层的神经网络<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，不仅可以剪得更快，而且更不容易失误。</p>
</div>
</div>
</div>
</details>
<p>下面用一个简单的例子来说明深层的神经网络是如何高效表示出复杂的函数：</p>
<details class="example" open="open">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="2:3"><input checked="" id="__tabbed_2_1" name="__tabbed_2" type="radio"/><input id="__tabbed_2_2" name="__tabbed_2" type="radio"/><input id="__tabbed_2_3" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="__tabbed_2_1">第一层</label><label for="__tabbed_2_2">第二层</label><label for="__tabbed_2_3">第三层</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>假设训练时只用到一个数据<span><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span></span>，通过不同神经元（偏移、权重、激活函数）的组合后，得到输出<span><span class="heti-spacing"> </span><span class="arithmatex">\(a_1\)</span></span>，它是一个<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>段的分段函数。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/36.png"><img src="images/lec3/36.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p>然后将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(a_1\)</span><span class="heti-spacing"> </span></span>作为第二层的输入，通过与第一层相同的神经元的计算后，得到<span><span class="heti-spacing"> </span><span class="arithmatex">\(a_2\)</span></span>，它是一个<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>段的分段函数（至于为什么是<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>段，这点不难推导，所以这里就不解释了<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/37.png"><img src="images/lec3/37.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p>然后将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(a_2\)</span><span class="heti-spacing"> </span></span>作为第三层的输入，通过与前两层相同的神经元的计算后，得到<span><span class="heti-spacing"> </span><span class="arithmatex">\(a_3\)</span></span>，它是一个<span class="heti-skip"><span class="heti-spacing"> </span>8<span class="heti-spacing"> </span></span>段的分段函数。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/38.png"><img src="images/lec3/38.png" width="70%/"/></a>
</div><p></p>
</div>
</div>
</div>
</details>
<p>假如我们要表示一个<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(2^k\)</span><span class="heti-spacing"> </span></span>段的分段函数，如果使用上面的深层神经网络（每层只有两个神经元<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，那么只需要<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(k\)</span><span class="heti-spacing"> </span></span>层，即<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(2k\)</span><span class="heti-spacing"> </span></span>个神经元就能完成任务。然而，如果用一层神经网络的话，就需要<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(2^k\)</span><span class="heti-spacing"> </span></span>个神经元。所以深层神经网络所需要的神经元数量明显更小，这样不仅成本低，而且更小的参数也意味着更少的模型可能性（即<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(|H|\)</span><span class="heti-spacing"> </span></span>更小<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，那么在训练集上得到的模型的表现与在真实情况下的表现更加接近。</p>
<div class="admonition note">
<p class="admonition-title">注</p>
<ul>
<li>当需要的函数是复杂而规整的话，深层的神经网络会优于相等数量参数下的浅层网络</li>
<li>当<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(y = x^2\)</span><span class="heti-spacing"> </span></span>时，深层的神经网络相比浅层的表现是指数级的好！</li>
</ul>
</div>
<p>呼应上一讲的结尾：<u><strong>深度学习</strong>是一个可以让鱼和熊掌可以兼得的方法</u>。</p>
<h2 id="cnn">CNN<a class="headerlink" href="#cnn" title="Permanent link">⚓︎</a></h2>
<p>接下来介绍一种非常有名的，主要为<strong>图像</strong><span>(image)<span class="heti-spacing"> </span></span>设计的神经网络架构——<strong>卷积神经网络</strong>(convolutional neural network, CNN)。我们将会从两个角度认识<span><span class="heti-spacing"> </span>CNN</span>，对<span class="heti-skip"><span class="heti-spacing"> </span>CNN<span class="heti-spacing"> </span></span>有一个全面而深入的理解。</p>
<h3 id="neuron-version-story">Neuron Version Story<a class="headerlink" href="#neuron-version-story" title="Permanent link">⚓︎</a></h3>
<p>现在要训练一个用于<strong>图像分类</strong><span>(image classification)<span class="heti-spacing"> </span></span>的模型，它的输入和输出为：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/4.png"><img src="images/lec3/4.png" width="70%/"/></a>
</div>
<ul>
<li>所有输入图像都应是固定的尺寸，这里假设均为<span><span class="heti-spacing"> </span>100 x 100</span></li>
<li>由于是分类问题，所以输出是一个独热向量（可能包含成千上万的元素<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，并且使用交叉熵来计算损失</li>
</ul>
<p>我们将一张图像看作是一个三维的<strong>张量</strong>(tensor)（简单理解成多维数组<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，它有宽度、高度、通道数量（或者称为深度）这三维。这里假定通道数量<span><span class="heti-spacing"> </span>= 3</span>，即<span class="heti-skip"><span class="heti-spacing"> </span>RGB<span class="heti-spacing"> </span></span>三个通道。在将图像输入给模型训练前，需要将这个三维张量“<strong>拉直</strong>”，即让这个三维张量变成一维向量，该向量的每个元素都是来自不同宽、高和通道的像素，其值表示的是图像上某个位置、某个通道下的亮度<span><span class="heti-spacing"> </span>(intensity)</span>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/5.png"><img src="images/lec3/5.png" width="70%/"/></a>
</div>
<p>现在，将拉直后的一维向量丢给全连接神经网络：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/6.png"><img src="images/lec3/6.png" width="70%/"/></a>
</div>
<p>假设网络的第一层有<span class="heti-skip"><span class="heti-spacing"> </span>1000<span class="heti-spacing"> </span></span>个神经元，由于有<span class="heti-skip"><span class="heti-spacing"> </span>100 x 100 x 3 = 30000<span class="heti-spacing"> </span></span>个输入项，所以第一个隐藏层就有<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(3 \times 10^7\)</span><span class="heti-spacing"> </span></span>个权重，因此产生了很多参数。前面提到过，虽然参数多意味着模型很灵活，但是这会带来过拟合的问题。所以全连接神经网络不太适合做图像处理相关的任务。现在我们来观察一下图像处理任务究竟有什么特性，以帮助我们设计出更合理的神经网络。</p>
<h4 id="observation-and-simplification-1">Observation and Simplification 1<a class="headerlink" href="#observation-and-simplification-1" title="Permanent link">⚓︎</a></h4>
<p>与其让神经元读取图像上的所有数据，不如让每个神经元读取部分图像区域上的数据，用于识别图像上的一些关键<strong>模式</strong>(patterns)。比如对于下面这张关于鸟的图片，机器可以从它的嘴巴、眼睛、爪子等特征（模式）来作出“这是一只鸟”的判断。实际上，人类也正是基于相似的方法来分辨图像。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/7.png"><img src="images/lec3/7.png" width="80%/"/></a>
</div>
<p>基于上述发现，我们可以着手简化神经网络的设计——每个神经元仅读取某一小块区域上的图像数据，因此用到了更少的参数；而我们通常称这一小块区域为<strong>感受野</strong>(receptive field)。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/8.png"><img src="images/lec3/8.png" width="70%/"/></a>
</div>
<div class="admonition note">
<p class="admonition-title">注</p>
<ul>
<li>不同神经元对应的感受野可以有重叠的地方</li>
<li>甚至不同神经元的感受野可以是相同的<ul>
<li>但由于不同神经元的权重和偏移不同，因此即使对于相同的一块区域，输出也是不一样的</li>
</ul>
</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/9.png"><img src="images/lec3/9.png" width="70%/"/></a>
</div><p></p>
</div>
<details class="question" open="open">
<summary>思考</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="3:3"><input checked="" id="__tabbed_3_1" name="__tabbed_3" type="radio"/><input id="__tabbed_3_2" name="__tabbed_3" type="radio"/><input id="__tabbed_3_3" name="__tabbed_3" type="radio"/><div class="tabbed-labels"><label for="__tabbed_3_1">问题<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span></label><label for="__tabbed_3_2">问题<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span></label><label for="__tabbed_3_3">问题<span><span class="heti-spacing"> </span>3</span></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>不同的神经元可以有不同大小的感受野吗？</p>
<p>可以的（而且也很常见<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。比如不同的模式可能有不同的大小，因此神经元需要用不同大小的感受野来检测对应的模式。</p>
</div>
<div class="tabbed-block">
<p>感受野可以仅包含部分通道吗？</p>
<p>可以。在其他的网络架构中会有这样的调整，但在一般的<span class="heti-skip"><span class="heti-spacing"> </span>CNN<span class="heti-spacing"> </span></span>中不会考虑。</p>
</div>
<div class="tabbed-block">
<p>感受野可以不是方的（可以是矩形或其他形状）吗？一定是一块邻近的连续区域吗？</p>
<p>可以。根据自己对任务的理解，可以确定不同形状的感受野。</p>
</div>
</div>
</div>
</details>
<ul>
<li>实际上，每个感受野都对应一组不同的神经元</li>
<li>而且，我们会让所有的感受野覆盖整张图像，最经典的安排方法是：<ul>
<li>先在图像左上角取图像的一部分作为感受野（但包含所有通道<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，这块感受野的大小称为<strong>核尺寸</strong>(kernel size)，一般设置为<span><span class="heti-spacing"> </span>3x3</span></li>
<li>然后移动这块感受野，从而得到新的感受野。每次移动都有规定的<strong>步幅</strong>(stride)，一般设为<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>或<span><span class="heti-spacing"> </span>2</span>。这可能会带来一些问题：<ul>
<li>相邻的感受野之间会有<strong>重叠</strong>，这是正常现象。而且如果没有做到重叠的话，那就有可能会漏掉那些位于重叠区域的模式，从而影响图像分类的效果</li>
<li>感受野移动到边界的时候，可能会有一部分不在图像内。一般采取的做法是在图像外围<strong>填充</strong><span>(padding)<span class="heti-spacing"> </span></span>一圈 <code>0</code>，也就是说不存在的部分用 <code>0</code> 表示即可</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/10.png"><img src="images/lec3/10.png" width="70%/"/></a>
</div>
<h4 id="observation-and-simplification-2">Observation and Simplification 2<a class="headerlink" href="#observation-and-simplification-2" title="Permanent link">⚓︎</a></h4>
<p>另一个不难发现的事实是：对于不同的图像而言，相同的模式可能出现在图像的不同位置上。比如下面有两张关于鸟的图片，上图鸟嘴出现在图像左上方，而下图鸟嘴出现在图像中央位置。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/11.png"><img src="images/lec3/11.png" width="80%/"/></a>
</div>
<p>因此，我们可以让某些神经元<strong>共享参数</strong>(parameter sharing)，那么这些神经元识别的是同一种模式，但针对的是不同的感受野，这样可以在确保识别不同位置上的模式的同时，还能减少一些参数。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/12.png"><img src="images/lec3/12.png" width="70%/"/></a>
</div>
<p>前面提到过，每个感受野都对应一组不同的神经元，但其中一些神经元之间共享参数，我们称这样的神经元为<strong>滤波器</strong>(filter)。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/13.png"><img src="images/lec3/13.png" width="80%/"/></a>
</div>
<div class="admonition abstract">
<p class="admonition-title">总结</p>
<p>现在总结一下我们目前学到过的有关深度学习的知识：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/14.png"><img src="images/lec3/14.png" width="70%/"/></a>
</div><p></p>
<p>从这张维恩图中可以看出，我们简单地认为：使用感受野和参数共享这两项简化技术的全连接层就是<strong>卷积层</strong>(convolutional layer)。</p>
<ul>
<li>虽然经过这两项简化技术后，卷积层的模型偏移会变得更大，但是相比全连接层而言，它还是更适合用于图像处理的任务</li>
<li>而全连接层的模型偏移较小，意味着灵活性高，可以胜任各种各样的任务，但这也意味着它没有特别擅长的事</li>
</ul>
</div>
<h3 id="filter-version-story">Filter Version Story<a class="headerlink" href="#filter-version-story" title="Permanent link">⚓︎</a></h3>
<p>现在我们知道，图像在经过一些卷积层的处理后，就可以得到关于图像的分类结果；而且在卷积过程中会用到一些滤波器，这些滤波器一般都是规模为<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>通道数量的张量。为了方便后续的讨论，</p>
<ul>
<li>假定通道数为<span><span class="heti-spacing"> </span>1</span>，即处理的是黑白图像。</li>
<li>
<p>且图像的尺寸为<span><span class="heti-spacing"> </span>6x6</span>，还有以下两个滤波器，里面的值就是模型的未知参数：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/15.png"><img src="images/lec3/15.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p>规定步幅<span><span class="heti-spacing"> </span>= 1</span>，即滤波器一次只能走一格</p>
</li>
</ul>
<p>滤波结果为：</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="" id="__tabbed_4_1" name="__tabbed_4" type="radio"/><input id="__tabbed_4_2" name="__tabbed_4" type="radio"/><div class="tabbed-labels"><label for="__tabbed_4_1">第<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个滤波器</label><label for="__tabbed_4_2">第<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个滤波器</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/16.png"><img src="images/lec3/16.png" width="70%/"/></a>
</div><p></p>
<p>观察第<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>个滤波器的特征，发现对角线上的值都是<span><span class="heti-spacing"> </span>1</span>，这也就意味着这个滤波器寻找的是图像上对角线均为<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>的模式。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/17.png"><img src="images/lec3/17.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/18.png"><img src="images/lec3/18.png" width="70%/"/></a>
</div><p></p>
<p>观察第<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个滤波器的特征，发现中间列上的值都是<span><span class="heti-spacing"> </span>1</span>，这也就意味着这个滤波器寻找的是图像上中间列均为<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>的模式。</p>
<p>我们将所有使用滤波器得到的结果汇总在一起，构成了一张<strong>特征图</strong>(feature map)。有多少个滤波器，这张特征图就有多少个通道。</p>
</div>
</div>
</div>
<hr/>
<p>一个神经网络中可以用多个卷积层，前一个卷积层的结果会作为下一个卷积层的输入。以上面的例子来说，假如有<span class="heti-skip"><span class="heti-spacing"> </span>64<span class="heti-spacing"> </span></span>个滤波器，那么就会得到一张有<span class="heti-skip"><span class="heti-spacing"> </span>64<span class="heti-spacing"> </span></span>个通道的特征图。我们可以将它看作是一张“图像”，传递到下一个卷积层中。而下一个卷积层中的滤波器可以是一个<span class="heti-skip"><span class="heti-spacing"> </span>3x3x64<span class="heti-spacing"> </span></span>大小的张量。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/19.png"><img src="images/lec3/19.png" width="70%/"/></a>
</div>
<details class="question">
<summary>思考：为什么一般使用<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>大小的滤波器就够了</summary>
<p>假如每个卷积层的滤波器的宽和高都是<span><span class="heti-spacing"> </span>3</span>。在第一个卷积层得到的特征点之上使用滤波器（此时来到了第二个卷积层<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，此时得到的每个特征点实际上包含了<span class="heti-skip"><span class="heti-spacing"> </span>5x5<span class="heti-spacing"> </span></span>的区域。因此随着层数的加深，即使滤波器的大小一直是<span><span class="heti-spacing"> </span>3x3</span>，但是特征点对原图的覆盖范围会越来越大，所以我们不用担心滤波器太小而无法覆盖图像上区域较大的模式的问题。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/20.png"><img src="images/lec3/20.png" width="60%/"/></a>
</div><p></p>
</details>
<div class="admonition abstract">
<p class="admonition-title">总结</p>
<table>
<thead>
<tr>
<th style="text-align: left;">从神经元角度看</th>
<th style="text-align: left;">从滤波器角度看</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">每个神经元仅考虑一块感受野</td>
<td style="text-align: left;">有一组用于检测小区域模式的滤波器</td>
</tr>
<tr>
<td style="text-align: left;">不同感受野下的神经元可能会共享参数</td>
<td style="text-align: left;">每个滤波器在输入图像上进行卷积操作</td>
</tr>
</tbody>
</table>
</div>
<h3 id="pooling">Pooling<a class="headerlink" href="#pooling" title="Permanent link">⚓︎</a></h3>
<p>对图像的第三个发现是：对原图像的像素进行二次采样<span class="heti-skip"><span class="heti-spacing"> </span>(subsampling)<span class="heti-spacing"> </span></span>后，不会改变图像中的物体。比如对下面关于鸟的图片进行二次采样，仅选择部分像素点，得到一张缩小了的图像，但是图像中的鸟没有发生太大的变化，依然可以识别出来。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/21.png"><img src="images/lec3/21.png" width="60%/"/></a>
</div>
<p>基于这一发现，我们在卷积神经网络中引入<strong>池化</strong><span>(pooling)<span class="heti-spacing"> </span></span>的概念。由于它没有任何权重（即无法“学习”<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，因此它算不上是一个“层”，反而类似一个像<span class="heti-skip"><span class="heti-spacing"> </span>sigmoid<span class="heti-spacing"> </span></span>之类的激活函数。有很多种池化方法，这里仅介绍<strong>最大池化</strong>(max pooling)——它接受来自滤波器的输出（一组数字，类似图像数据<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，将其按固定大小划分为多个组，然后取每个组中的最大值，扔掉其他值。结果就是保留更少的，但又能符合原图像特征的数据。</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="" id="__tabbed_5_1" name="__tabbed_5" type="radio"/><input id="__tabbed_5_2" name="__tabbed_5" type="radio"/><div class="tabbed-labels"><label for="__tabbed_5_1">池化前</label><label for="__tabbed_5_2">池化后</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/22.png"><img src="images/lec3/22.png" width="60%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/23.png"><img src="images/lec3/23.png" width="60%/"/></a>
</div><p></p>
</div>
</div>
</div>
<p>回到整个神经网络，比对池化前后的结果：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/24.png"><img src="images/lec3/24.png" width="70%/"/></a>
</div>
<div class="admonition abstract">
<p class="admonition-title">完整的<span class="heti-skip"><span class="heti-spacing"> </span>CNN<span class="heti-spacing"> </span></span>框架！</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/25.png"><img src="images/lec3/25.png" width="60%/"/></a>
</div><p></p>
<p>使用池化的最大原因是降低特征图的空间维度，减少计算量。但随着技术的发展，计算机的算力会越来越强，因此有时不必使用池化操作；而且过多的池化操作有可能会破坏原图像的特征，所以有些<span class="heti-skip"><span class="heti-spacing"> </span>CNN<span class="heti-spacing"> </span></span>甚至直接抛弃了池化（后面介绍的<span class="heti-skip"><span class="heti-spacing"> </span>Alpha Go<span class="heti-spacing"> </span></span>就是其中一个例子<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
</div>
<h3 id="applications">Applications<a class="headerlink" href="#applications" title="Permanent link">⚓︎</a></h3>
<p>事实上，<span>CNN<span class="heti-spacing"> </span></span>不仅可以用于图像处理，也能够完成其他领域内的任务，比如下围棋<span><span class="heti-spacing"> </span>(playing Go)</span>——著名的<span class="heti-skip"><span class="heti-spacing"> </span>Alpha Go<span class="heti-spacing"> </span></span>用的就是<span><span class="heti-spacing"> </span>CNN</span>。</p>
<ul>
<li>之所以这样是可行的，是因为可以将棋盘看作一张<span class="heti-skip"><span class="heti-spacing"> </span>19x19<span class="heti-spacing"> </span></span>的图像，每个位置上只有<span class="heti-skip"><span class="heti-spacing"> </span>3<span class="heti-spacing"> </span></span>种值：黑子（用<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>表示<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>、白子（用<span class="heti-skip"><span class="heti-spacing"> </span>-1<span class="heti-spacing"> </span></span>表示<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>、空（用<span class="heti-skip"><span class="heti-spacing"> </span>0<span class="heti-spacing"> </span></span>表示）</li>
<li><span>Alpha Go<span class="heti-spacing"> </span></span>内将棋盘划分为<span class="heti-skip"><span class="heti-spacing"> </span>48<span class="heti-spacing"> </span></span>个通道，每个通道表示不同的棋局</li>
<li><span>CNN<span class="heti-spacing"> </span></span>根据当前棋盘上的棋局，输出下一次移动的位置（<span>19x19<span class="heti-spacing"> </span></span>个类）</li>
</ul>
<p>此外，围棋也符合一些上述对图像的观察：</p>
<ul>
<li>
<p>图像上有一些区域更小的模式</p>
<ul>
<li><span>Alpha Go<span class="heti-spacing"> </span></span>在第一层上采用<span class="heti-skip"><span class="heti-spacing"> </span>5x5<span class="heti-spacing"> </span></span>大小的感受野</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/26.png"><img src="images/lec3/26.png" width="20%/"/></a>
</div><p></p>
</li>
<li>
<p>相同的模式可能会出现在图像的不同区域上</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/27.png"><img src="images/lec3/27.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p>但显然不能在棋盘上进行所谓的“二次采样”，因为随便抽走某一列或某一行，棋局就可能会发生很大的变化。因此<span class="heti-skip"><span class="heti-spacing"> </span>Alpha Go<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>CNN<span class="heti-spacing"> </span></span>并没有使用池化。</p>
</li>
</ul>
<details class="info" open="open">
<summary>更多的应用</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="6:2"><input checked="" id="__tabbed_6_1" name="__tabbed_6" type="radio"/><input id="__tabbed_6_2" name="__tabbed_6" type="radio"/><div class="tabbed-labels"><label for="__tabbed_6_1">语音</label><label for="__tabbed_6_2">自然语言处理</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/28.png"><img src="images/lec3/28.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec3/29.png"><img src="images/lec3/29.png" width="80%/"/></a>
</div><p></p>
</div>
</div>
</div>
</details>
<div class="admonition failure">
<p class="admonition-title"><span>CNN<span class="heti-spacing"> </span></span>的缺陷</p>
<p>如果对同一张图像进行缩放、旋转等操作，<span>CNN<span class="heti-spacing"> </span></span>就无法识别出这些变换后的图像（有点笨<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。因此需要在训练过程中使用<strong>数据增强</strong><span>(data augmentation)<span class="heti-spacing"> </span></span>的方法，将这些变换后的图像也作为训练资料喂给神经网络。</p>
<p>不过也有另一种方法：空间变换层<span class="heti-skip"><span class="heti-spacing"> </span>(spatial transformer layer)<span class="heti-spacing"> </span></span>能够解决这一问题。</p>
</div>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="最后更新">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年7月19日 19:48:36">2025年7月19日 19:48:36</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="创建日期">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2024年10月7日 21:20:16">2024年10月7日 21:20:16</span>
</span>
</aside>
<p style="font-size: 30px; font-weight: 600">评论区</p>
<div>
    如果大家有什么问题或想法，欢迎在下方留言~
  </div>
<!-- Insert generated snippet here -->
<script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOMAb9Zs4CfmpP" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="noughtq/notebook" data-repo-id="R_kgDOMAb9Zg" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
<!-- 标题计数器 -->
<link href="/css/counter.css" rel="stylesheet"/>
<!-- 主页个性化 -->
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="上一页: Machine Learning - P2" class="md-footer__link md-footer__link--prev" href="2.html">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                上一页
              </span>
<div class="md-ellipsis">
                Machine Learning - P2
              </div>
</div>
</a>
<a aria-label="下一页: Self-Attention" class="md-footer__link md-footer__link--next" href="4.html">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                Self-Attention
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z" fill="currentColor"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright" style="margin-left: 33.5%">
<div class="md-copyright__highlight" style="text-align: center">
        Copyright © 2024-2025 <a href="https://github.com/NoughtQ">NoughtQ</a>
</div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" rel="noopener" target="_blank">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
        Material
      </a>
      modified by
      <a href="https://github.com/NoughtQ" rel="noopener" target="_blank">
        NoughtQ
      </a>
<!-- <br> -->
<div style="text-align: center;">
<a href="https://icp.gov.moe/?keyword=20252357" target="_blank">萌ICP备20252357号</a>
</div>
</div>
<div class="md-social">
<a class="md-social__link" href="https://noughtq.top" rel="noopener" target="_blank" title="noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M277.8 8.6c-12.3-11.4-31.3-11.4-43.5 0l-224 208c-9.6 9-12.8 22.9-8 35.1S18.8 272 32 272h16v176c0 35.3 28.7 64 64 64h288c35.3 0 64-28.7 64-64V272h16c13.2 0 25-8.1 29.8-20.3s1.6-26.2-8-35.1zM240 320h32c26.5 0 48 21.5 48 48v96H192v-96c0-26.5 21.5-48 48-48" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://blog.noughtq.top" rel="noopener" target="_blank" title="blog.noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/noughtq" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="mailto:noughtq666@gmail.com" rel="noopener" target="_blank" title="">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.copy", "content.code.annotate", "content.footnote.tooltips", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.indexes", "navigation.tracking", "navigation.prune", "search.share"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
<script src="../../js/anchor.js"></script>
<script src="../../js/katex.js"></script>
<script src="../../js/toc.js"></script>
<script src="../../js/typed.js"></script>
<script src="../../js/custom.js"></script>
<script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
<script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>