<!DOCTYPE html>
<html class="no-js" lang="zh"><head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="NoughtQ的笔记本，主要记录一些 CS 相关的笔记" name="description"/>
<meta content="NoughtQ" name="author"/>
<link href="https://notebook.noughtq.top/ai/ml/7.html" rel="canonical"/>
<link href="6.html" rel="prev"/>
<link href="8.html" rel="next"/>
<link href="../../feed_rss_created.xml" rel="alternate" title="RSS 订阅" type="application/rss+xml"/>
<link href="../../feed_rss_updated.xml" rel="alternate" title="已更新内容的 RSS 订阅" type="application/rss+xml"/>
<link href="../../assets/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.18" name="generator"/>
<title>Self-Supervised Learning - NoughtQ的笔记本</title>
<link href="../../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=JetBrains+Mono,+LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono,+Consolas:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"JetBrains Mono, LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono, Consolas"}</style>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="../../css/toc_extra.css" rel="stylesheet"/>
<link href="../../css/timeline.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/extra_changelog.css" rel="stylesheet"/>
<link href="../../css/header.css" rel="stylesheet"/>
<link href="../../css/sidebar.css" rel="stylesheet"/>
<link href="https://unpkg.com/katex@0/dist/katex.min.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&amp;display=swap" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-43NH8CVRCJ"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-43NH8CVRCJ",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-43NH8CVRCJ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#self-supervised-learning">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="NoughtQ的笔记本" class="md-header__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            NoughtQ的笔记本
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Self-Supervised Learning
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Dark Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Dark Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
<input aria-label="Light Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Light Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<a aria-label="分享" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="分享">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../index.html">
          
  
  
    
  
  🏫主页

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../lang/index.html">
          
  
  
    
  
  🔡语言

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../math/index.html">
          
  
  
    
  
  📊数学相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../algorithms/index.html">
          
  
  
    
  
  🧮算法相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../software/index.html">
          
  
  
    
  
  💾软件相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../system/index.html">
          
  
  
    
  
  💻系统相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../web/index.html">
          
  
  
    
  
  🌏Web相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../sec/ctf-101/index.html">
          
  
  
    
  
  🛡️信息安全

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../index.html">
          
  
  
    
  
  🤖人工智能

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../misc/index.html">
          
  
  
    
  
  🗃️杂项

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tools/index.html">
          
  
  
    
  
  🛠️工具

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../papers/index.html">
          
  
  
    
  
  📑论文阅读

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="NoughtQ的笔记本" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
    NoughtQ的笔记本
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../index.html">
<span class="md-ellipsis">
    🏫主页
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../lang/index.html">
<span class="md-ellipsis">
    🔡语言
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../math/index.html">
<span class="md-ellipsis">
    📊数学相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../algorithms/index.html">
<span class="md-ellipsis">
    🧮算法相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../software/index.html">
<span class="md-ellipsis">
    💾软件相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../system/index.html">
<span class="md-ellipsis">
    💻系统相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../web/index.html">
<span class="md-ellipsis">
    🌏Web相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../sec/ctf-101/index.html">
<span class="md-ellipsis">
    🛡️信息安全
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../index.html">
<span class="md-ellipsis">
    🤖人工智能
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
            🤖人工智能
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="index.html">
<span class="md-ellipsis">
    机器学习
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9_2" id="__nav_9_2_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_9_2">
<span class="md-nav__icon md-icon"></span>
            机器学习
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1.html">
<span class="md-ellipsis">
    Machine Learning - P1
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2.html">
<span class="md-ellipsis">
    Machine Learning - P2
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="3.html">
<span class="md-ellipsis">
    Deep Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4.html">
<span class="md-ellipsis">
    Self-Attention
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="5.html">
<span class="md-ellipsis">
    Transformer
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="6.html">
<span class="md-ellipsis">
    Generative Adversarial Network
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Self-Supervised Learning
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="7.html">
<span class="md-ellipsis">
    Self-Supervised Learning
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#bert">
<span class="md-ellipsis">
      BERT
    </span>
</a>
<nav aria-label="BERT" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#glue">
<span class="md-ellipsis">
      GLUE
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
<nav aria-label="Applications" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sentiment-analysis">
<span class="md-ellipsis">
      Sentiment Analysis
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pos-tagging">
<span class="md-ellipsis">
      POS Tagging
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#natural-language-inference">
<span class="md-ellipsis">
      Natural Language Inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extraction-based-question-answering">
<span class="md-ellipsis">
      Extraction-based Question Answering
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training">
<span class="md-ellipsis">
      Training
    </span>
</a>
<nav aria-label="Training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#bert-embryology">
<span class="md-ellipsis">
      BERT Embryology
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pre-training-a-seq2seq-model">
<span class="md-ellipsis">
      Pre-training a Seq2seq Model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-does-bert-work">
<span class="md-ellipsis">
      Why Does BERT Work?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#multi-lingual-bert">
<span class="md-ellipsis">
      Multi-lingual BERT
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cross-discipline">
<span class="md-ellipsis">
      Cross Discipline
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#gpt">
<span class="md-ellipsis">
      GPT
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#other-domains">
<span class="md-ellipsis">
      Other Domains
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#more-about-pre-trained-language-models">
<span class="md-ellipsis">
      More about Pre-trained Language Models
    </span>
</a>
<nav aria-label="More about Pre-trained Language Models" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas_1">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#problems">
<span class="md-ellipsis">
      Problems
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#solutions">
<span class="md-ellipsis">
      Solutions
    </span>
</a>
<nav aria-label="Solutions" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#data-efficient-fine-tuning">
<span class="md-ellipsis">
      Data-Efficient Fine-tuning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reducing-the-number-of-parameters">
<span class="md-ellipsis">
      Reducing the Number of Parameters
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pretrain-without-human-language">
<span class="md-ellipsis">
      Pretrain without Human Language
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#self-supervised-learning-for-speech-and-images">
<span class="md-ellipsis">
      Self-Supervised Learning for Speech and Images
    </span>
</a>
<nav aria-label="Self-Supervised Learning for Speech and Images" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#generative-approaches">
<span class="md-ellipsis">
      Generative Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#predictive-approaches">
<span class="md-ellipsis">
      Predictive Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#contrastive-learning">
<span class="md-ellipsis">
      Contrastive Learning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#bootstrapping-approaches">
<span class="md-ellipsis">
      Bootstrapping Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#simply-extra-regularization">
<span class="md-ellipsis">
      Simply Extra Regularization
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#auto-encoder">
<span class="md-ellipsis">
      Auto-encoder
    </span>
</a>
<nav aria-label="Auto-encoder" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas_2">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#feature-disentanglement">
<span class="md-ellipsis">
      Feature Disentanglement
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#discrete-latent-representation">
<span class="md-ellipsis">
      Discrete Latent Representation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#more-applications">
<span class="md-ellipsis">
      More Applications
    </span>
</a>
<nav aria-label="More Applications" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#generator">
<span class="md-ellipsis">
      Generator
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#compression">
<span class="md-ellipsis">
      Compression
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#anomaly-detection">
<span class="md-ellipsis">
      Anomaly Detection
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="8.html">
<span class="md-ellipsis">
    Explainable Machine Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="9.html">
<span class="md-ellipsis">
    Adversarial Attack
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="10.html">
<span class="md-ellipsis">
    Adaptation
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="11.html">
<span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="12.html">
<span class="md-ellipsis">
    Network Compression
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="13.html">
<span class="md-ellipsis">
    Life-long Learning
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="14.html">
<span class="md-ellipsis">
    Meta Learning
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../genai/index.html">
<span class="md-ellipsis">
    生成式人工智能
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../cv/index.html">
<span class="md-ellipsis">
    计算机视觉导论
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../misc/index.html">
<span class="md-ellipsis">
    🗃️杂项
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tools/index.html">
<span class="md-ellipsis">
    🛠️工具
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../papers/index.html">
<span class="md-ellipsis">
    📑论文阅读
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#bert">
<span class="md-ellipsis">
      BERT
    </span>
</a>
<nav aria-label="BERT" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#glue">
<span class="md-ellipsis">
      GLUE
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
<nav aria-label="Applications" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sentiment-analysis">
<span class="md-ellipsis">
      Sentiment Analysis
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pos-tagging">
<span class="md-ellipsis">
      POS Tagging
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#natural-language-inference">
<span class="md-ellipsis">
      Natural Language Inference
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extraction-based-question-answering">
<span class="md-ellipsis">
      Extraction-based Question Answering
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training">
<span class="md-ellipsis">
      Training
    </span>
</a>
<nav aria-label="Training" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#bert-embryology">
<span class="md-ellipsis">
      BERT Embryology
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pre-training-a-seq2seq-model">
<span class="md-ellipsis">
      Pre-training a Seq2seq Model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#why-does-bert-work">
<span class="md-ellipsis">
      Why Does BERT Work?
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#multi-lingual-bert">
<span class="md-ellipsis">
      Multi-lingual BERT
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cross-discipline">
<span class="md-ellipsis">
      Cross Discipline
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#gpt">
<span class="md-ellipsis">
      GPT
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#other-domains">
<span class="md-ellipsis">
      Other Domains
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#more-about-pre-trained-language-models">
<span class="md-ellipsis">
      More about Pre-trained Language Models
    </span>
</a>
<nav aria-label="More about Pre-trained Language Models" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas_1">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#problems">
<span class="md-ellipsis">
      Problems
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#solutions">
<span class="md-ellipsis">
      Solutions
    </span>
</a>
<nav aria-label="Solutions" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#data-efficient-fine-tuning">
<span class="md-ellipsis">
      Data-Efficient Fine-tuning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reducing-the-number-of-parameters">
<span class="md-ellipsis">
      Reducing the Number of Parameters
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pretrain-without-human-language">
<span class="md-ellipsis">
      Pretrain without Human Language
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#self-supervised-learning-for-speech-and-images">
<span class="md-ellipsis">
      Self-Supervised Learning for Speech and Images
    </span>
</a>
<nav aria-label="Self-Supervised Learning for Speech and Images" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#generative-approaches">
<span class="md-ellipsis">
      Generative Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#predictive-approaches">
<span class="md-ellipsis">
      Predictive Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#contrastive-learning">
<span class="md-ellipsis">
      Contrastive Learning
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#bootstrapping-approaches">
<span class="md-ellipsis">
      Bootstrapping Approaches
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#simply-extra-regularization">
<span class="md-ellipsis">
      Simply Extra Regularization
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#auto-encoder">
<span class="md-ellipsis">
      Auto-encoder
    </span>
</a>
<nav aria-label="Auto-encoder" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-ideas_2">
<span class="md-ellipsis">
      Basic Ideas
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#feature-disentanglement">
<span class="md-ellipsis">
      Feature Disentanglement
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#discrete-latent-representation">
<span class="md-ellipsis">
      Discrete Latent Representation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#more-applications">
<span class="md-ellipsis">
      More Applications
    </span>
</a>
<nav aria-label="More Applications" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#generator">
<span class="md-ellipsis">
      Generator
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#compression">
<span class="md-ellipsis">
      Compression
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#anomaly-detection">
<span class="md-ellipsis">
      Anomaly Detection
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/edit/master/docs/ai/ml/7.md" rel="edit" title="编辑此页">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/raw/master/docs/ai/ml/7.md" title="查看本页的源代码">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
</a>
<h1 id="self-supervised-learning">Self-Supervised Learning<a class="headerlink" href="#self-supervised-learning" title="Permanent link">⚓︎</a></h1>
<div style="margin-top: -30px; font-size: 0.9em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>12576<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>63<span class="heti-spacing"> </span></span>分钟</p>
</div>
<details class="abstract">
<summary>各模型参数量比较</summary>
<p>由于课程是<span class="heti-skip"><span class="heti-spacing"> </span>2021<span class="heti-spacing"> </span></span>年的，所以列出的模型都有些过时了<span><span class="heti-spacing"> </span>...</span></p>
<ul>
<li>ELMO：94M</li>
<li>BERT：340M</li>
<li>GPT-2：1542M</li>
<li>Megatron：8B</li>
<li>T5：11B</li>
<li>Turing NLG：17B</li>
<li>GPT-3：175B</li>
<li>Switch Transformer：1.6T</li>
</ul>
</details>
<p>前面讲的内容几乎都属于<strong>监督学习</strong>(supervised learning)：我们手边有成对的数据<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span><span class="arithmatex">\(\hat{y}\)</span></span>（标签<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，将<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>丢给模型后，模型会输出<span><span class="heti-spacing"> </span><span class="arithmatex">\(y\)</span></span>，和标签数据<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\hat{y}\)</span><span class="heti-spacing"> </span></span>做比较，预期效果是通过不断的训练，让<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(y\)</span><span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\hat{y}\)</span><span class="heti-spacing"> </span></span>尽可能接近。</p>
<p>对应地，<strong>无监督学习</strong><span>(unsupervised learning)<span class="heti-spacing"> </span></span>没有用到标签。而且上一讲提到过的<strong>自监督学习</strong><span>(self-supervised learning)<span class="heti-spacing"> </span></span>实际上是无监督学习的一种。它将已有的数据<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>分作两堆，一堆记作<span><span class="heti-spacing"> </span><span class="arithmatex">\(x'\)</span></span>，作为模型的输入；另一堆记作<span><span class="heti-spacing"> </span><span class="arithmatex">\(x''\)</span></span>，作为模型输出的比较对象。训练的目标就是让模型输出<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(y\)</span><span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x''\)</span><span class="heti-spacing"> </span></span>越接近越好。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/1.png"><img src="images/lec7/1.png" width="70%/"/></a>
</div>
<h2 id="bert">BERT<a class="headerlink" href="#bert" title="Permanent link">⚓︎</a></h2>
<h3 id="basic-ideas">Basic Ideas<a class="headerlink" href="#basic-ideas" title="Permanent link">⚓︎</a></h3>
<p>首先介绍的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>便是一种经典的自监督学习的模型。简单来看，<span>BERT<span class="heti-spacing"> </span></span>就是<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>中的<a href="5.html#encoder">编码器</a>，接收一个序列，输出另一个序列。由于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>一般用于<span class="heti-skip"><span class="heti-spacing"> </span>NLP<span class="heti-spacing"> </span></span>的任务上，所以之后就假设<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>将一串文字作为输入（当然也可以将图像和语音作为输入，不过这里不会展开介绍了<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p>首先，相较于<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>编码器的一个不同在于训练时要随机掩盖<span class="heti-skip"><span class="heti-spacing"> </span>(mask)<span class="heti-spacing"> </span></span>序列中的某个记号<span><span class="heti-spacing"> </span>(token)</span>，具体的掩盖方式有：</p>
<ul>
<li>采用特殊记号（对应字典中不存在的字）</li>
<li>从已有的记号集中随机挑选一个记号（对应从字典中随机挑一个字）</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/2.png"><img src="images/lec7/2.png" width="40%/"/></a>
</div>
<p>接下来要对被掩盖输入对应的输出做一个线性变换（就是乘上一个矩阵<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，然后做一个<span class="heti-skip"><span class="heti-spacing"> </span>softmax<span class="heti-spacing"> </span></span>操作，这样得到了一个关于文字的分布（和<span class="heti-skip"><span class="heti-spacing"> </span>seq2seq<span class="heti-spacing"> </span></span>模型中的类似，本质上还是一个向量<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/3.png"><img src="images/lec7/3.png" width="50%/"/></a>
</div>
<p>我们已经知道被掩盖的输入是什么，而这个输入将被表示为一个独热向量，和上面得到的输出做比较。训练的目的就是要最小化两者的交叉熵。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/4.png"><img src="images/lec7/4.png" width="50%/"/></a>
</div>
<hr/>
<p>除了上述的训练方法外，还有一种叫做<strong>下一句预测</strong><span>(next sentence prediction)<span class="heti-spacing"> </span></span>的技术。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/5.png"><img src="images/lec7/5.png" width="50%/"/></a>
</div>
<ul>
<li>输入由<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个句子组成</li>
<li>此外输入还包括了两类特殊记号<ul>
<li>CLS：仅出现在开头，并且之后仅考虑它的输出</li>
<li>SEP：作为句子间的分隔符</li>
</ul>
</li>
<li>仅考虑<span class="heti-skip"><span class="heti-spacing"> </span>CLS<span class="heti-spacing"> </span></span>对应的输出，将其做线性转换<span><span class="heti-spacing"> </span>+ softmax</span>，得到的结果为<span><span class="heti-spacing"> </span>yes/no</span>，即表明这两个句子是否是相关联的</li>
</ul>
<p>不过有论文（<a href="https://arxiv.org/abs/1907.11692">Robustly optimized BERT approach (RoBERTa)</a>）指出，这个训练方法不太有用。但是有一种类似的，但是比较有用的方法，叫做<strong>句子顺序预测</strong>(sentence order prediction, SOP)，它被用在<a href="https://arxiv.org/abs/1909.11942"><span class="heti-skip"><span class="heti-spacing"> </span>ALBERT<span class="heti-spacing"> </span></span></a>模型中。也许是该方法提出的问题比较困难，因而得到不错的训练效果。</p>
<hr/>
<p>所以总的来说，<span>BERT<span class="heti-spacing"> </span></span>能做的就是“填空题”（即第一个训练<strong>掩码记号预测</strong>(masked token prediction)，<del>第二个训练没啥用</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。看似用处不大，但在<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>基础上<strong>微调</strong><span>(fine-tune)<span class="heti-spacing"> </span></span>后的模型就能完成<strong>下游任务</strong>(downstream tasks)（即我们关心的具体任务，且有一些标注过的数据）了。所以<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>就像一个胚胎干细胞，有着无限的发展潜能，可分化成各式各样的细胞完成不同工作。而训练<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的过程我们称为<strong>预训练</strong>(pre-train)（这里就是自监督学习<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。 </p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/6.png"><img src="images/lec7/6.png" width="70%/"/></a>
</div>
<h3 id="glue">GLUE<a class="headerlink" href="#glue" title="Permanent link">⚓︎</a></h3>
<p>由于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>可分化成各式各样的模型完成不同任务，所以在测试<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的时候也会用多种任务来测。其中较为知名的任务集是 <strong>GLUE</strong>（全称<span><span class="heti-spacing"> </span>General Language Understanding Evaluation</span>，通用语言理解评估<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，它包含以下几个任务：</p>
<ul>
<li><span style="color: red">Corpus of Linguistic Acceptability (CoLA)</span></li>
<li><span style="color: red">Stanford Sentiment Treebank (SST-2)</span></li>
<li><span style="color: green">Microsoft Research Paraphrase Corpus (MRPC)</span></li>
<li><span style="color: green">Quora Question Pairs (QQP)</span></li>
<li><span style="color: green">Semantic Textual Similarity Benchmark (STS-B)</span></li>
<li><span style="color: cornflowerblue">Multi-Genre Natural Language Inference (MNLI)</span></li>
<li><span style="color: cornflowerblue">Question-answering NLI (QNLI)</span></li>
<li><span style="color: cornflowerblue">Recognizing Textual Entailment (RTE)</span></li>
<li><span style="color: cornflowerblue">Winograd NLI (WNLI) </span></li>
</ul>
<blockquote>
<p><a href="https://gluebenchmark.com/">官网</a>，<a href="https://www.cluebenchmarks.com/">中文网站</a></p>
</blockquote>
<p>下面是一些用到<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的模型在<span class="heti-skip"><span class="heti-spacing"> </span>GLUE<span class="heti-spacing"> </span></span>下的分数：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/7.png"><img src="images/lec7/7.png" width="80%/"/></a>
</div>
<ul>
<li>黑线表示人类能够达到的水平</li>
<li>蓝线表示模型在<span class="heti-skip"><span class="heti-spacing"> </span>GLUE<span class="heti-spacing"> </span></span>中的分数（其他几项任务的平均分）</li>
</ul>
<h3 id="applications">Applications<a class="headerlink" href="#applications" title="Permanent link">⚓︎</a></h3>
<p>下面介绍一些用到<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的，但用于不同场合下的模型，来感受一下<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>真正强大的地方。</p>
<h4 id="sentiment-analysis">Sentiment Analysis<a class="headerlink" href="#sentiment-analysis" title="Permanent link">⚓︎</a></h4>
<p>在<strong>情感分析</strong><span>(sentiment analysis)<span class="heti-spacing"> </span></span>任务中，模型输入的是一个序列（文本<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，输出的是一个类（积极的<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>消极的<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。具体的模型架构如下所示：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/8.png"><img src="images/lec7/8.png" width="70%/"/></a>
</div>
<ul>
<li>除了将整个句子作为输入外，还要在开头输入一个特殊记号<span><span class="heti-spacing"> </span>CLS</span></li>
<li>对<span class="heti-skip"><span class="heti-spacing"> </span>CLS<span class="heti-spacing"> </span></span>在<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>中的输出做一个线性变换<span class="heti-skip"><span class="heti-spacing"> </span>+ softmax<span class="heti-spacing"> </span></span>操作（图上省略了<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，得到的输出就是句子所属的类</li>
<li>
<p><span>BERT<span class="heti-spacing"> </span></span>模型就是之前预训练得到的<span><span class="heti-spacing"> </span>BERT</span>，这比从头开始用随机数初始化效果好很多，但之后仍然会通过训练继续改进</p>
<ul>
<li>
<p>下图比较了预训练和随机的效果，可以看到采用预训练的模型，无论是训练速度还是训练效果都比随机来的好</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/9.png"><img src="images/lec7/9.png" width="70%/"/></a>
</div><p></p>
</li>
</ul>
</li>
<li>
<p>但线性变换那边的参数可以用随机数来初始化，会在训练过程中不断调整</p>
</li>
</ul>
<h4 id="pos-tagging">POS Tagging<a class="headerlink" href="#pos-tagging" title="Permanent link">⚓︎</a></h4>
<p>在<strong>词性标注</strong><span>(POS tagging)<span class="heti-spacing"> </span></span>任务中，输入和输出都是序列，但输入是原始的句子，而输出是句子中每个词对应的词性。其对应的模型如下所示：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/10.png"><img src="images/lec7/10.png" width="70%/"/></a>
</div>
<p>可以看到，这次考虑的不是<span class="heti-skip"><span class="heti-spacing"> </span>CLS<span class="heti-spacing"> </span></span>的输出，而是其余每个词对应的输出，这正符合任务的要求。</p>
<h4 id="natural-language-inference">Natural Language Inference<a class="headerlink" href="#natural-language-inference" title="Permanent link">⚓︎</a></h4>
<p><strong>自然语言推断</strong><span>(natural langauge inference, NLI)<span class="heti-spacing"> </span></span>任务相对复杂些：</p>
<ul>
<li>输入的是两个句子，其中一个叫做<strong>前提</strong>(premise)，另一个叫做<strong>假设</strong>(hypothesis)</li>
<li>输出的是一个类，表示前提和假设之间的关联，有矛盾<span><span class="heti-spacing"> </span>(contradiction)</span>（假<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>、蕴含<span><span class="heti-spacing"> </span>(entailment)</span>（真）和中立<span><span class="heti-spacing"> </span>(neutral)</span>（未定）这样几类</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/11.png"><img src="images/lec7/11.png" width="70%/"/></a>
</div>
<p>相应的模型如下：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/12.png"><img src="images/lec7/12.png" width="70%/"/></a>
</div>
<p>整体结构类似<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的“下一句预测”训练方法，所以就不再赘述。</p>
<h4 id="extraction-based-question-answering">Extraction-based Question Answering<a class="headerlink" href="#extraction-based-question-answering" title="Permanent link">⚓︎</a></h4>
<p>“<strong>基于提取的问答</strong>(extraction-based QA)”这一任务更为复杂，它的输入和输出均有<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个，其中</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/13.png"><img src="images/lec7/13.png" width="30%/"/></a>
</div>
<ul>
<li>输入（可简单看做两个字符串）<ul>
<li>文档<span><span class="heti-spacing"> </span>(document) <span class="arithmatex">\(D = \{d_1, d_2, \dots, d_N\}\)</span></span></li>
<li>查询<span><span class="heti-spacing"> </span>(query) <span class="arithmatex">\(Q = \{q_1, q_2, \dots, q_M\}\)</span></span></li>
</ul>
</li>
<li>输出是两个整数<ul>
<li>起始位置<span><span class="heti-spacing"> </span><span class="arithmatex">\(s\)</span></span></li>
<li>结束位置<span><span class="heti-spacing"> </span><span class="arithmatex">\(e\)</span></span></li>
</ul>
</li>
<li>答案为<span><span class="heti-spacing"> </span><span class="arithmatex">\(A = \{d_s, \dots, d_e\}\)</span></span></li>
</ul>
<details class="example">
<summary>例子</summary>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/14.png"><img src="images/lec7/14.png" width="50%/"/></a>
</div><p></p>
</details>
<p>下面来看模型的结构，先仅考虑<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的部分：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/15.png"><img src="images/lec7/15.png" width="70%/"/></a>
</div>
<p>同样也和“下一句预测”训练方法中的类似，但我们规定第一句话作为查询，第二句话作为文档。</p>
<p>该模型唯一要训练的是两个向量。它们是用随机数初始化的，长度和<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的输出向量长度一致，一个用于寻找起始位置<span><span class="heti-spacing"> </span><span class="arithmatex">\(s\)</span></span>（橙色矩形<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，另一个用于寻找结束位置<span><span class="heti-spacing"> </span><span class="arithmatex">\(e\)</span></span>（蓝色矩形<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/16.png"><img src="images/lec7/16.png" width="30%/"/></a>
</div>
<ul>
<li>
<p>先让文档对应的输出向量和橙色矩形对应的向量做内积，再放到<span class="heti-skip"><span class="heti-spacing"> </span>softmax<span class="heti-spacing"> </span></span>中，将分数最大者对应的位置作为答案的起始位置</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/17.png"><img src="images/lec7/17.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p>再让文档对应的输出向量和蓝色矩形对应的向量做内积，再放到<span class="heti-skip"><span class="heti-spacing"> </span>softmax<span class="heti-spacing"> </span></span>中，将分数最大者对应的位置作为答案的结束位置</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/18.png"><img src="images/lec7/18.png" width="70%/"/></a>
</div><p></p>
</li>
</ul>
<p>对于上面的例子，答案就是<span><span class="heti-spacing"> </span><span class="arithmatex">\(A = \{d_2, d_3\}\)</span></span></p>
<h3 id="training">Training<a class="headerlink" href="#training" title="Permanent link">⚓︎</a></h3>
<p>在自己电脑上训练<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>是一件比较困难的事，因为<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的训练需要<span class="heti-skip"><span class="heti-spacing"> </span>3B<span class="heti-spacing"> </span></span>词的数据，如果用<span class="heti-skip"><span class="heti-spacing"> </span>TPU v3<span class="heti-spacing"> </span></span>来训练的话需要<span class="heti-skip"><span class="heti-spacing"> </span>8<span class="heti-spacing"> </span></span>天时间。</p>
<blockquote>
<p>不过现在<span class="heti-skip"><span class="heti-spacing"> </span>v7<span class="heti-spacing"> </span></span>都出来了，应该会快得多；而且<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>和现在的模型比就是小巫见大巫了<span><span class="heti-spacing"> </span>...</span></p>
</blockquote>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/19.png"><img src="images/lec7/19.png" width="70%/"/></a>
</div>
<h4 id="bert-embryology">BERT Embryology<a class="headerlink" href="#bert-embryology" title="Permanent link">⚓︎</a></h4>
<p>由于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>训练需要耗费大量运算资源，因此人们想办法节省资源，让训练变得更快。而想要让训练变得更快，就得关注训练<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的过程，而在之前可能没什么人会关注。<span>BERT<span class="heti-spacing"> </span></span>胚胎学<span class="heti-skip"><span class="heti-spacing"> </span>(embryology)<span class="heti-spacing"> </span></span>就是观察<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>训练过程中在何时已经具备了处理某些具体任务（词性标注、句法解析、语义分析等）的能力，就像观察从胚胎到婴儿的进化过程中何时发展了什么样的器官（<del>后半句是个人理解</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p>具体的答案就不展开介绍（<span>PPT<span class="heti-spacing"> </span></span>上说是“反直觉的”<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，感兴趣的读者可参考这篇<a href="https://arxiv.org/abs/2010.02480">论文</a>。</p>
<h4 id="pre-training-a-seq2seq-model">Pre-training a Seq2seq Model<a class="headerlink" href="#pre-training-a-seq2seq-model" title="Permanent link">⚓︎</a></h4>
<p>前面介绍的任务没有包含<span class="heti-skip"><span class="heti-spacing"> </span>seq2seq<span class="heti-spacing"> </span></span>的任务，因为原始的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>只考虑了编码器。但实际上也可以对解码器进行预训练，具体做法是给<span class="heti-skip"><span class="heti-spacing"> </span>seq2seq<span class="heti-spacing"> </span></span>模型一个被“破坏<span><span class="heti-spacing"> </span>(corrupt)</span>”过的输入序列，我们希望模型的输出和被破坏前的输入尽可能接近，也就是想要让模型具备重构<span class="heti-skip"><span class="heti-spacing"> </span>(reconstruct)<span class="heti-spacing"> </span></span>或还原输入的能力。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/20.png"><img src="images/lec7/20.png" width="70%/"/></a>
</div>
<p>在一篇叫做<span class="heti-skip"><span class="heti-spacing"> </span>MASS<span class="heti-spacing"> </span></span>的论文中给出了以下“搞破坏”的方法：</p>
<ul>
<li>像<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>那样对输入中的部分记号做掩码</li>
<li>删掉某个记号</li>
<li>重新排列</li>
<li>翻转顺序</li>
<li>结合各种方法</li>
</ul>
<p>而在另一篇名为<span class="heti-skip"><span class="heti-spacing"> </span>BART<span class="heti-spacing"> </span></span>的论文中采用了上述全部方法，发现训练的效果是比较不错的。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/21.png"><img src="images/lec7/21.png" width="70%/"/></a>
</div>
<p>至于上述方法哪种更好的话，已经有研究做过了，比如：</p>
<ul>
<li>Transfer Text-to-Text Transformer (T5)</li>
<li>Colossal Clean Crawled Corpus (C4)</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/22.png"><img src="images/lec7/22.png" width="90%/"/></a>
</div>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/23.png"><img src="images/lec7/23.png" width="60%/"/></a>
</div>
<h3 id="why-does-bert-work">Why Does BERT Work?<a class="headerlink" href="#why-does-bert-work" title="Permanent link">⚓︎</a></h3>
<p><span>BERT<span class="heti-spacing"> </span></span>的输出向量称为<strong>嵌入</strong>(embedding)。在处理文本任务中，嵌入就代表了每个文字（记号）的意思，并且有一个结论是相似意思的记号会有相似的嵌入。</p>
<p>有时还得考虑一词多义的情况——不过不用担心，<span>BERT<span class="heti-spacing"> </span></span>会考虑上下文<span class="heti-skip"><span class="heti-spacing"> </span>(context)<span class="heti-spacing"> </span></span>的。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/24.png"><img src="images/lec7/24.png" width="70%/"/></a>
</div>
<p>考虑“喝苹果汁”中的“果”和“苹果电脑”中的“果”，因为在不同的上下文中，它们的相似度是不大的。下面比较了更多上下文中“果”的相似度（颜色越黄表示相似度越大，越蓝表示相似度越小<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/25.png"><img src="images/lec7/25.png" width="70%/"/></a>
</div>
<blockquote>
<p>注：横轴的内容和纵轴是一样的。</p>
</blockquote>
<p>很明显，由于图中左上角和右下角的上下文比较接近，因此相似度会更大一些，另外两部分的相似度则很小。</p>
<p>那么<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>是如何得知每个字对应的意思的呢？方法和一开始介绍的掩码记号预测类似，同样要先盖住想要知道意思的那个字，然后让<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>根据其他输入的字来推测这个字的意思。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/26.png"><img src="images/lec7/26.png" width="40%/"/></a>
</div>
<p>不过在<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>之前就出现了类似的技术，比如<strong>词嵌入</strong><span>(word embedding)<span class="heti-spacing"> </span></span>中的<span><span class="heti-spacing"> </span>CROW</span>，它也是考虑除了需要知道意思的那个字外的（相邻的）其他字，但是它只用两个变换（线性模型）就能完成任务，计算效率会更高些（<del>当然也受限于当时的计算资源</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/27.png"><img src="images/lec7/27.png" width="40%/"/></a>
</div>
<p>相比<span><span class="heti-spacing"> </span>CROW</span>，<span>BERT<span class="heti-spacing"> </span></span>更加强大，它能根据上下文为相同的字给出不同的嵌入向量输出，因此<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>这里的技术又称为<strong>上下文化的词嵌入</strong>(contextualized word embedding)。</p>
<h3 id="multi-lingual-bert">Multi-lingual BERT<a class="headerlink" href="#multi-lingual-bert" title="Permanent link">⚓︎</a></h3>
<p>顾名思义，<strong>多语言</strong>(multi-lingual) <strong>BERT</strong> 需要用多种语言来训练的<span><span class="heti-spacing"> </span>BERT</span>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/31.png"><img src="images/lec7/31.png" width="70%/"/></a>
</div>
<p>多语言<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的强大之处在于，它能完成<strong>零样本阅读理解</strong><span>(zero-shot reading comprehension)<span class="heti-spacing"> </span></span>的任务，例如仅根据英文<span class="heti-skip"><span class="heti-spacing"> </span>QA<span class="heti-spacing"> </span></span>例子（SQuAD）来训练，就能在中文<span><span class="heti-spacing"> </span>QA</span> （DRCD）的测试取得不错的成绩。测试结果如下：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/32.png"><img src="images/lec7/32.png" width="70%/"/></a>
</div>
<p>为什么能够实现这样的效果呢？一种简单的解释是<strong>跨语言对齐</strong>(cross-lingual alignment)，即对于不同语言，但意思相近的文字，它们对应的嵌入向量也是比较接近的，如下图所示。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/33.png"><img src="images/lec7/33.png" width="70%/"/></a>
</div>
<p>用于衡量多语言<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>表现的任务集是平均倒数排名<span><span class="heti-spacing"> </span>(Mean Reciprocal Rank, MRR)</span>。下图比较了<span class="heti-skip"><span class="heti-spacing"> </span>Google<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>和李宏毅老师团队自己训练的较小的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的表现：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/34.png"><img src="images/lec7/34.png" width="70%/"/></a>
</div>
<p>从李宏毅老师团队训练的两个模型中可以看出，训练数据量对于跨语言对齐而言是很关键的——从<span class="heti-skip"><span class="heti-spacing"> </span>200k<span class="heti-spacing"> </span></span>到<span><span class="heti-spacing"> </span>1000k</span>，准确率高了不少（不过训练的时候比较坎坷，中间有段时间损失一直降不下去，训练了<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>天后就突然降下去了😂<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/35.png"><img src="images/lec7/35.png" width="80%/"/></a>
</div>
<p>也许读者产生这样的疑问：不同语言的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>不是单独训练的吗，那为什么模型能从英文语料的训练中学到了解决中文问题的能力呢？事实上，多语言<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>能够在多种语言的训练中找到不同语言间存在的一些关联，比如意思相近的中英文嵌入向量之间的距离保持在一定范围内，因此可以记录所有中文嵌入向量的平均和英文嵌入向量的平均之差（也是一个向量<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/36.png"><img src="images/lec7/36.png" width="60%/"/></a>
</div>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/152.png"><img src="images/lec7/152.png" width="70%/"/></a>
</div>
<details class="example">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="" id="__tabbed_1_1" name="__tabbed_1" type="radio"/><input id="__tabbed_1_2" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="__tabbed_1_1">例<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span></label><label for="__tabbed_1_2">例<span><span class="heti-spacing"> </span>2</span></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><a href="https://arxiv.org/abs/2004.05160">On the Language Neutrality of Pre-trained Multilingual Representations</a></p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/150.png"><img src="images/lec7/150.png" width="60%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p><a href="https://arxiv.org/abs/2010.08275">It’s not Greek to mBERT: Inducing Word-Level Translations from Multilingual BERT</a></p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/151.png"><img src="images/lec7/151.png" width="70%/"/></a>
</div><p></p>
</div>
</div>
</div>
</details>
<p>通过这种方法，我们可以让多语言<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>完成无监督记号级翻译<span class="heti-skip"><span class="heti-spacing"> </span>(unsupervised token-level translation)<span class="heti-spacing"> </span></span>的任务。尽管完成的并不是很出色，但是从中可以看出<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的跨语言学习能力：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/37.png"><img src="images/lec7/37.png" width="80%/"/></a>
</div>
<p>跨语言模型的基准测试：<a href="https://sites.research.google/xtreme">Cross-lingual TRansfer Evaluation of Multilingual Encoders(XTREME)</a></p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/149.png"><img src="images/lec7/149.png" width="60%/"/></a>
</div>
<h3 id="cross-discipline">Cross Discipline<a class="headerlink" href="#cross-discipline" title="Permanent link">⚓︎</a></h3>
<p>接下来介绍<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的一种神奇应用：完成蛋白质、<span>DNA<span class="heti-spacing"> </span></span>和音乐的分类。下面是一个关于<span class="heti-skip"><span class="heti-spacing"> </span>DNA<span class="heti-spacing"> </span></span>分类的示意图：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/28.png"><img src="images/lec7/28.png" width="70%/"/></a>
</div>
<p>那么接下来就以<span class="heti-skip"><span class="heti-spacing"> </span>DNA<span class="heti-spacing"> </span></span>分类任务为例展示用到<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的模型架构图：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/29.png"><img src="images/lec7/29.png" width="70%/"/></a>
</div>
<p>可以看到这个架构图和情感分析的模型是类似的，但不同之处在于我们不会将<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>种碱基直接丢给<span><span class="heti-spacing"> </span>BERT</span>，而是先将碱基转化为文字（自己决定，什么文字都行）然后再丢给<span><span class="heti-spacing"> </span>BERT</span>。这种做法看似莫名其妙，但更奇妙的地方在于这样做真的能将模型训练起来，而且还能取得不错的效果（红色方框，蓝色方框对应从随机参数开始训练起来的模型<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>（<del>黑人问号<span><span class="heti-spacing"> </span>.png</span></del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/30.png"><img src="images/lec7/30.png" width="70%/"/></a>
</div>
<p>至于背后的原因仍然没能搞清楚（<del>赛博玄学了属于是</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。不过能够肯定的是，预训练模型能从分类任务中学习到一些通用能力，从而解决一些跨学科（而不是仅和语言相关）的任务。</p>
<p>上述结果并非巧合，不少预训练模型也具备这种跨学科的能力，结果如下：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/153.png"><img src="images/lec7/153.png" width="80%/"/></a>
</div>
<p>那么这种在人类语言上经过预训练的模型是在哪个层面上起到帮助作用呢？实验结果表明，无论是在优化阶段，还是泛化（举一反三的能力）的时候，使用预训练的模型相比从头开始训练的模型在损失和精确率上都有不小的提升。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/154.png"><img src="images/lec7/154.png" width="80%/"/></a>
</div>
<hr/>
<p>下面介绍一些跨学科能力的应用：</p>
<ul>
<li>托福听力理解测试：<a href="https://github.com/iamyuanchung/TOEFL-QA"><span>Github<span class="heti-spacing"> </span></span>仓库</a>，<a href="https://arxiv.org/abs/1608.06378">论文</a></li>
<li>
<p><a href="https://arxiv.org/abs/1804.00320">SQuAD-style Spoken QA</a>：级联模型（ASR + Text QA）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/155.png"><img src="images/lec7/155.png" width="70%/"/></a>
</div> <p></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1910.11559">Speech BERT</a>：一种端到端<span><span class="heti-spacing"> </span>(end-to-end)</span>（这里指语音输入问题，语音回答问题）的模型，但训练的时候需要成对的语音和文本数据</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/156.png"><img src="images/lec7/156.png" width="60%/"/></a>
</div><p></p>
</li>
<li>
<p>我们希望在训练的时候只用语音数据，而不使用文本数据</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/157.png"><img src="images/lec7/157.png" width="70%/"/></a>
</div><p></p>
<p>在过去这是一个难题，不过现在有了像<span class="heti-skip"><span class="heti-spacing"> </span>HuBERT<span class="heti-spacing"> </span></span>这样的语音预训练模型后，可以尝试着完成这项任务。若直接用这种预训练模型，模型还是没法训练起来，因为输出向量缺少语义信息。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/158.png"><img src="images/lec7/158.png" width="70%/"/></a>
</div> <p></p>
<p>解决方法是将输出向量离散化，得到一系列的<span><span class="heti-spacing"> </span>token ID</span>，然后在后面再用一个文本预训练模型（比如<span><span class="heti-spacing"> </span>BERT</span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，从而让模型具备理解的能力。但由于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>要求的输入是文本内容而非<span><span class="heti-spacing"> </span>ID</span>，所以<span class="heti-skip"><span class="heti-spacing"> </span>token ID<span class="heti-spacing"> </span></span>和文本之间有一个映射（类似前面介绍<span class="heti-skip"><span class="heti-spacing"> </span>DNA<span class="heti-spacing"> </span></span>分类任务中碱基和词汇的匹配<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/159.png"><img src="images/lec7/159.png" width="70%/"/></a>
</div> <p></p>
<p>下图展现了该模型的表现：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/160.png"><img src="images/lec7/160.png" width="80%/"/></a>
</div><p></p>
</li>
</ul>
<h2 id="gpt">GPT<a class="headerlink" href="#gpt" title="Permanent link">⚓︎</a></h2>
<p><span>GPT<span class="heti-spacing"> </span></span>要做的任务是预测下一个出现的记号。它的结构类似<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>中的<a href="5.html#decoder">解码器</a>，在预测当前记号时不会去看下一个记号（采用掩码<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，但区别在于原来的解码器并没有<span class="heti-skip"><span class="heti-spacing"> </span>BOS<span class="heti-spacing"> </span></span>这个记号。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/38.png"><img src="images/lec7/38.png" width="70%/"/></a>
</div>
<p>由于<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>具备预测下一个记号的能力，因此它也具备<strong>生成</strong><span>(generation)<span class="heti-spacing"> </span></span>的能力。</p>
<p>接下来看<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>在<span class="heti-skip"><span class="heti-spacing"> </span>QA<span class="heti-spacing"> </span></span>这个下游任务中的应用。一种做法是让<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>像使用<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>那样做微调，训练出一个分类器出来。但这显得没新意，而且<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>模型参数量太大，微调有些困难。所以我们采用另一种做法：让<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>像人类一样，根据问题描述和一些例子（包括题目和答案<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，预测其他题目（给定提示词<span><span class="heti-spacing"> </span>(prompt)</span>）的答案。根据训练用到例子的多少，可以分为以下几类：</p>
<ul>
<li><strong>少样本学习</strong>(few-shot learning)</li>
<li><strong>单样本学习</strong>(one-shot learning)</li>
<li><strong>零样本学习</strong>(zero-shot learning)</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/39.png"><img src="images/lec7/39.png" width="70%/"/></a>
</div>
<p>由于上述学习不是一般的学习（没有用到梯度下降法<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，所以这类学习方法又称为<strong>语境中学习</strong>(in-context learning)。下面比较了这<span class="heti-skip"><span class="heti-spacing"> </span>3<span class="heti-spacing"> </span></span>种学习方法的训练效果：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/40.png"><img src="images/lec7/40.png" width="70%/"/></a>
</div>
<p>显然，随着参数量的增加，训练效果越来越好；而且训练用到的样本数越多，训练效果也越好。</p>
<h2 id="other-domains">Other Domains<a class="headerlink" href="#other-domains" title="Permanent link">⚓︎</a></h2>
<blockquote>
<p>【<span>7.17<span class="heti-spacing"> </span></span>补充】更详细的内容见<a href="#self-supervised-learning-for-speech-and-images">最后一小节</a>。</p>
</blockquote>
<p>介绍<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>的时候，我们基本上都是以文本处理相关的任务为例子的。实际上这些模型均能用于文本之外的任务，比如图像、语音等等。下面列出了一些适用于其他领域的一些模型：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/41.png"><img src="images/lec7/41.png" width="80%/"/></a>
</div>
<details class="example">
<summary>具体应用</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="" id="__tabbed_2_1" name="__tabbed_2" type="radio"/><input id="__tabbed_2_2" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="__tabbed_2_1">图像</label><label for="__tabbed_2_2">语音</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="" id="__tabbed_3_1" name="__tabbed_3" type="radio"/><input id="__tabbed_3_2" name="__tabbed_3" type="radio"/><div class="tabbed-labels"><label for="__tabbed_3_1">SimCLR</label><label for="__tabbed_3_2">BYOL</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/42.gif"><img src="images/lec7/42.gif" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/43.png"><img src="images/lec7/43.png" width="80%/"/></a>
</div><p></p>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/44.png"><img src="images/lec7/44.png" width="60%/"/></a>
</div><p></p>
</div>
</div>
</div>
</details>
<p>不过相较于文本，语音领域缺乏可用的基准测试集（<del>课是<span class="heti-skip"><span class="heti-spacing"> </span>2021<span class="heti-spacing"> </span></span>年的，现在情况可能不一样了</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，所以李宏毅老师团队和其他团队共同构建了一个叫做 <strong>SUPERB</strong> 的基准测试。下面截取了<span class="heti-skip"><span class="heti-spacing"> </span>PPT<span class="heti-spacing"> </span></span>的描述，所以这里就不再赘述了。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/45.png"><img src="images/lec7/45.png" width="60%/"/></a>
</div>
<p>下面是工具箱<span class="heti-skip"><span class="heti-spacing"> </span>(toolkit)<span class="heti-spacing"> </span></span>包含的内容：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/46.png"><img src="images/lec7/46.png" width="70%/"/></a>
</div>
<h2 id="more-about-pre-trained-language-models">More about Pre-trained Language Models<a class="headerlink" href="#more-about-pre-trained-language-models" title="Permanent link">⚓︎</a></h2>
<h3 id="basic-ideas_1">Basic Ideas<a class="headerlink" href="#basic-ideas_1" title="Permanent link">⚓︎</a></h3>
<p><strong>神经语言模型</strong>(neural language model)：一种确定词句出现概率的神经网络。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/47.png"><img src="images/lec7/47.png" width="70%/"/></a>
</div>
<blockquote>
<p>很明显左边句子出现概率更大，因为右边是一段无意义的句子。</p>
</blockquote>
<p>这种语言模型的训练思路是：给定一个不完整的句子，让模型预测句子的剩余部分。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/48.png"><img src="images/lec7/48.png" width="50%/"/></a>
</div>
<p>有以下几类语言模型：</p>
<ul>
<li>
<p><strong>自回归语言模型</strong>(autoregressive language model, ALMs)：基于前半部分补全句子</p>
<details class="example">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="4:3"><input checked="" id="__tabbed_4_1" name="__tabbed_4" type="radio"/><input id="__tabbed_4_2" name="__tabbed_4" type="radio"/><input id="__tabbed_4_3" name="__tabbed_4" type="radio"/><div class="tabbed-labels"><label for="__tabbed_4_1">预测第<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个字</label><label for="__tabbed_4_2">预测第<span class="heti-skip"><span class="heti-spacing"> </span>3<span class="heti-spacing"> </span></span>个字</label><label for="__tabbed_4_3">预测第<span class="heti-skip"><span class="heti-spacing"> </span>6<span class="heti-spacing"> </span></span>个字</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/49.png"><img src="images/lec7/49.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/50.png"><img src="images/lec7/50.png" width="70%/"/></a>
</div><p></p>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/51.png"><img src="images/lec7/51.png" width="70%/"/></a>
</div><p></p>
</div>
</div>
</div>
</details>
</li>
<li>
<p><strong>掩码语言模型</strong>(masked language model, MLMs)：使用未被掩码的词来预测被掩码的词（填空<span><span class="heti-spacing"> </span>(cloze)</span>）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/52.png"><img src="images/lec7/52.png" width="70%/"/></a>
</div><p></p>
</li>
</ul>
<p>训练语言模型的方式属于<strong>自监督学习</strong>(self-supervised learning)，即从其他输入部分预测输入的某些部分。</p>
<p>另外，语言模型的内部结构一般是基于<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>的，对应前面的两类模型，架构图分别如下所示：</p>
<ul>
<li>
<p>基于<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>ALMs</span></p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/53.png"><img src="images/lec7/53.png" width="90%/"/></a>
</div><p></p>
</li>
<li>
<p>基于<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>PLMs</span>（对应<span><span class="heti-spacing"> </span>MLMs</span>）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/54.png"><img src="images/lec7/54.png" width="90%/"/></a>
</div><p></p>
</li>
</ul>
<p>这里的<span class="heti-skip"><span class="heti-spacing"> </span>"PLM"<span class="heti-spacing"> </span></span>是<strong>预训练语言模型</strong><span>(pre-trained language model)<span class="heti-spacing"> </span></span>的缩写。其中“预训练”的意思是用一个很大的数据集（语料库）来训练神经语言模型，具体可分为：</p>
<ul>
<li>自回归预训练：<span>GPT<span class="heti-spacing"> </span></span>系列（GPT, GPT-2, GPT-3）</li>
<li>基于<span class="heti-skip"><span class="heti-spacing"> </span>MLM<span class="heti-spacing"> </span></span>的预训练：<span>BERT<span class="heti-spacing"> </span></span>系列（BERT, RoBERTa, ALBERT）</li>
</ul>
<p>通常认为经过预训练后，<span>PLM<span class="heti-spacing"> </span></span>会学到一些知识，这些知识会被编码在模型的隐藏层中，在后续下游任务的完成中发挥作用。在将<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>用于下游任务前，往往要对模型先做<strong>微调</strong>(fine-tuning)，即使用<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>中预训练好的权重参数来初始化用于下游任务的模型。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/79.png"><img src="images/lec7/79.png" width="80%/"/></a>
</div>
<details class="example">
<summary>例子：情感分析</summary>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/55.png"><img src="images/lec7/55.png" width="70%/"/></a>
</div><p></p>
<p>更底层的架构图如下所示：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/56.png"><img src="images/lec7/56.png" width="90%/"/></a>
</div><p></p>
<p>可以看到，我们去掉了<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>原有的<span class="heti-skip"><span class="heti-spacing"> </span>LM<span class="heti-spacing"> </span></span>头（用于输出概率分布<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，并添加了一个分类器头，用于输出分类结果（积极<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>消极<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
</details>
<p>在实践中，微调后的<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>在多项不同的下游任务中能够取得优异的表现。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/57.png"><img src="images/lec7/57.png" width="90%/"/></a>
</div>
<p>因此，<span>PLMs<span class="heti-spacing"> </span></span>被广泛用于不同情况和不同领域中。可以看到，<span>PLM<span class="heti-spacing"> </span></span>的概念随处可见：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/58.png"><img src="images/lec7/58.png" width="60%/"/></a>
</div>
<p>这个故事看起来很圆满——既然<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>能够“斩下”多个基准测试数据集，那是不是说它就是无所不能的了？但现实往往是残酷的，在有些现实场景下，<span>PLMs<span class="heti-spacing"> </span></span>的应用往往是不现实的。下面就让我们来认识一下<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>存在的问题。</p>
<h3 id="problems">Problems<a class="headerlink" href="#problems" title="Permanent link">⚓︎</a></h3>
<p>这里列出有关<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>的一系列问题：</p>
<ul>
<li>
<p>下游任务的数据短缺</p>
<ul>
<li>并不是所有任务都有足够多的标注好的数据，因为标注数据需要不小的成本，而且有些任务能提供的数据量一般是很少的</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/59.png"><img src="images/lec7/59.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p><span>PLMs<span class="heti-spacing"> </span></span>太大了，而且还会继续大下去</p>
<ul>
<li>
<p><span>PLMs<span class="heti-spacing"> </span></span>各模型的大小比较（按时间排序<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，可以看到总体上每年呈增长趋势</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/60.png"><img src="images/lec7/60.png" width="50%/"/></a>
</div><p></p>
</li>
<li>
<p>对于不同的下游任务，需要有不同的<span class="heti-skip"><span class="heti-spacing"> </span>PLMs<span class="heti-spacing"> </span></span>拷贝，这些拷贝会占据过多的空间</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/61.png"><img src="images/lec7/61.png" width="80%/"/></a>
</div><p></p>
</li>
<li>
<p>推理时间长（下图中的<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>有<span class="heti-skip"><span class="heti-spacing"> </span>96<span class="heti-spacing"> </span></span>层<span><span class="heti-spacing"> </span>Transformer</span>，训练下来得花不少时间）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/62.png"><img src="images/lec7/62.png" width="70%/"/></a>
</div><p></p>
</li>
</ul>
</li>
</ul>
<h3 id="solutions">Solutions<a class="headerlink" href="#solutions" title="Permanent link">⚓︎</a></h3>
<h4 id="data-efficient-fine-tuning">Data-Efficient Fine-tuning<a class="headerlink" href="#data-efficient-fine-tuning" title="Permanent link">⚓︎</a></h4>
<p>对于标注数据短缺的问题，采用的解决方案是<strong>数据高效的微调</strong>(data-efficient fine-tuning)，具体包括以下几类：</p>
<ul>
<li>
<p><strong>提示调优</strong>(prompt tuning)</p>
<ul>
<li>在<strong>自然语言推理</strong><span>(natural language inference)<span class="heti-spacing"> </span></span>任务中，通常需要给模型喂足够多的形如（前提，假设，结论）的数据</li>
<li>但假如现有数据量不多的话，可能无法将模型训练到令人满意的效果，此时我们可以向数据插入一些东西，便于模型“理解”</li>
<li>具体来说就是将数据集中的数据点转化为自然语言提示，以便模型理解它应该要完成的任务</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/63.png"><img src="images/lec7/63.png" width="70%/"/></a>
</div><p></p>
<ul>
<li>提示调优中的“<strong>提示</strong>(prompt)”就是将下游任务格式化为具有预定义模板的语言建模任务，形成自然语言提示</li>
<li>
<p>提示调优包括：</p>
<ul>
<li>
<p><strong>提示模板</strong>(prompt template)：数据点<span class="heti-skip"><span class="heti-spacing"> </span>-&gt;<span class="heti-spacing"> </span></span>自然语言提示</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/64.png"><img src="images/lec7/64.png" width="90%/"/></a>
</div><p></p>
</li>
<li>
<p>PLM：执行语言建模</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/65.png"><img src="images/lec7/65.png" width="60%/"/></a>
</div><p></p>
</li>
<li>
<p><strong>词汇化器</strong>(verbalizer)：标签到词汇的映射</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/66.png"><img src="images/lec7/66.png" width="80%/"/></a>
</div><p></p>
</li>
</ul>
</li>
<li>
<p>比较提示调优和标准的微调：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/67.png"><img src="images/lec7/67.png" width="80%/"/></a>
</div><p></p>
</li>
<li>
<p>提示调优在数据短缺的情况下能取得更好的表现，因为</p>
<ul>
<li>包括了人类知识</li>
<li>没有引入新的参数</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/68.png"><img src="images/lec7/68.png" width="80%/"/></a>
</div><p></p>
</li>
</ul>
</li>
<li>
<p><strong>少样本学习</strong>(few-shot learning)：有一些标注好的数据</p>
<ul>
<li>“一些”的概念往往含糊不清，这里就假定是十几份数据了</li>
<li>关于<span><span class="heti-spacing"> </span>GPT-3</span>，好消息是它适用于少样本的情景下，坏消息是它不是免费的，且参数量太大（175B）</li>
<li>所以我们想要一种更小的，能在少样本上表现较好的<span><span class="heti-spacing"> </span>PLMs</span>——一种满足要求的模型是 <strong>LM-BFF</strong>，全称是更好的少样本微调语言模型<span><span class="heti-spacing"> </span>(better few-shot fine-tuning of language model)</span>，它的核心部分是<strong>提示词</strong>(prompt) + <strong>演示</strong>(demonstration)</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/69.png"><img src="images/lec7/69.png" width="90%/"/></a>
</div> <p></p>
</li>
<li>
<p><strong>半监督学习</strong>(semi-supervised learning)：有少量标注数据和大量未标注数据</p>
<ul>
<li>
<p>采用的训练方式是<strong>模式利用的训练</strong>(pattern-exploiting training, PET)，具体步骤为</p>
<ol>
<li>
<p>在标注数据集上，用不同的提示词和词汇化器来提示调优出不同的<span><span class="heti-spacing"> </span>PLMs</span></p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/70.png"><img src="images/lec7/70.png" width="90%/"/></a>
</div> <p></p>
</li>
<li>
<p>在未标注的数据集上进行预测，并将来自不同模型的预测结果结合起来</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/71.png"><img src="images/lec7/71.png" width="90%/"/></a>
</div> <p></p>
</li>
<li>
<p>用带有分类器头的<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>在软标记<span class="heti-skip"><span class="heti-spacing"> </span>(soft-labeled)<span class="heti-spacing"> </span></span>的数据集（第二步得到的汇总结果）上进行训练</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/72.png"><img src="images/lec7/72.png" width="90%/"/></a>
</div> <p></p>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>零样本学习</strong>(zero-shot learning)</p>
<ul>
<li>零样本推理：在没有训练数据的情况下对下游任务的推理</li>
<li>只要模型足够大，<span>GPT-3<span class="heti-spacing"> </span></span>就还能在零样本的情况下发挥作用，这是因为在预训练的时候，训练数据集内含不同任务的混合体，使得模型具备这种零样本生成的能力</li>
<li>有人因此获得了灵感，尝试直接基于多任务数据集来训练模型</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/73.png"><img src="images/lec7/73.png" width="80%/"/></a>
</div><p></p>
<ul>
<li>
<p>使用<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>进行多任务的微调</p>
<details class="example">
<summary>例子</summary>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/74.png"><img src="images/lec7/74.png" width="80%/"/></a>
</div> <p></p>
</details>
</li>
<li>
<p>有时像这样的得到的小模型（参数量：11B）的表现甚至好过<span><span class="heti-spacing"> </span>GPT-3</span>（参数量：175B）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/75.png"><img src="images/lec7/75.png" width="80%/"/></a>
</div><p></p>
</li>
</ul>
</li>
</ul>
<h4 id="reducing-the-number-of-parameters">Reducing the Number of Parameters<a class="headerlink" href="#reducing-the-number-of-parameters" title="Permanent link">⚓︎</a></h4>
<p>减少参数量的可行思路有：</p>
<ul>
<li>
<p>先预训练一个大模型，然后在下游任务中采用更小的模型（<strong>蒸馏</strong>(distillation)/<strong>剪枝</strong>(pruning)）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/76.png"><img src="images/lec7/76.png" width="80%/"/></a>
</div><p></p>
</li>
<li>
<p>在<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>层中共用参数</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/77.png"><img src="images/lec7/77.png" width="60%/"/></a>
</div><p></p>
</li>
</ul>
<p>一般采用以下方法：</p>
<ul>
<li>
<p><strong>参数高效的微调</strong>(parameter-efficient fine-tuning)：每个下游任务使用少量参数</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/78.png"><img src="images/lec7/78.png" width="80%/"/></a>
</div><p></p>
<ul>
<li>
<p><strong>适配器</strong>(adapter)：使用特殊的子模块来改变隐藏层中的表示</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/80.png"><img src="images/lec7/80.png" width="80%/"/></a>
</div><p></p>
<p>适配器内部结构如右图所示：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/81.png"><img src="images/lec7/81.png" width="80%/"/></a>
</div><p></p>
<p>简单来说，适配器要做的事就是先将向量<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{h}\)</span><span class="heti-spacing"> </span></span>从高维转为低维，然后经过一个非线性转换后，又从低维转为高维，再加上原来的向量，得到一个新向量<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{h}'\)</span></span>。训练的时候只需更新适配器和分类器头的参数即可。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/82.png"><img src="images/lec7/82.png" width="70%/"/></a>
</div><p></p>
<p>另外，所有的下游任务可共享同一个<span><span class="heti-spacing"> </span>PLM</span>，而适配器和分类器头对每个任务而言是不同的模块。</p>
</li>
<li>
<p><strong>LoRA</strong>：同样使用特殊的子模块来改变隐藏层中的表示，但是并行地加在网络中，不改变网络深度</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/83.png"><img src="images/lec7/83.png" width="70%/"/></a>
</div><p></p>
<p>具体结构如下：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/84.png"><img src="images/lec7/84.png" width="80%/"/></a>
</div><p></p>
<p>放大红框部分的细节：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/85.png"><img src="images/lec7/85.png" width="70%/"/></a>
</div><p></p>
<p>和适配器类似，训练时也只需更新<span class="heti-skip"><span class="heti-spacing"> </span>LoRA<span class="heti-spacing"> </span></span>和分类器头的参数即可。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/86.png"><img src="images/lec7/86.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p><strong>前缀调优</strong>(prefix tuning)：向每一层插入前缀向量</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/87.png"><img src="images/lec7/87.png" width="80%/"/></a>
</div><p></p>
<p>具体细节为：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/88.png"><img src="images/lec7/88.png" width="90%/"/></a>
</div><p></p>
<blockquote>
<p>注：前缀向量无需生成查询向量。</p>
</blockquote>
<p>训练的时候只需更新前缀向量（包括键和值）即可。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/89.png"><img src="images/lec7/89.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p><strong>软提示</strong>(soft prompting)：在嵌入向量前面添加一些前缀向量（位于输入层）</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/90.png"><img src="images/lec7/90.png" width="80%/"/></a>
</div><p></p>
<p>相对地，硬提示就是一般的提示，即在输入句子中插入一些词（微调模型的时候固定提示词<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/91.png"><img src="images/lec7/91.png" width="80%/"/></a>
</div><p></p>
<p>所以，软提示词本质上是向量（可以从一些词嵌入向量中初始化<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，而硬提示词本质上就是来自词汇表的单词</p>
</li>
<li>
<p>上述方法的优势有：</p>
<ul>
<li>
<p>显著降低具体任务所需的参数量</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/92.png"><img src="images/lec7/92.png" width="80%/"/></a>
</div><p></p>
</li>
<li>
<p>更不容易发生在训练数据上的过拟合，并且在领域外任务中具备更好的表现</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/93.png"><img src="images/lec7/93.png" width="70%/"/></a>
</div><p></p>
</li>
<li>
<p>在小数据集上训练时可能具有不错的表现</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/94.png"><img src="images/lec7/94.png" width="90%/"/></a>
</div><p></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>早退出</strong>(early exit)</p>
<ul>
<li>在整个模型上推理可能会花费大量的时间</li>
<li>对于较简单的数据，获取答案付出的努力可以更少</li>
<li>早退出就是要减少推理所需的层数</li>
<li>
<p>要实现这一点，需要为每一层增加一个分类器头，以便随时从某个层退出</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/95.png"><img src="images/lec7/95.png" width="80%/"/></a>
</div><p></p>
</li>
<li>
<p>实验证明，早退出能在不影响性能的情况下减小推理时间</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/96.png"><img src="images/lec7/96.png" width="80%/"/></a>
</div><p></p>
</li>
</ul>
</li>
</ul>
<hr/>
<p>尽管介绍了一系列的解决方案，但实际上<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>的问题尚未得到彻底解决，而且这里也只讨论了<span class="heti-skip"><span class="heti-spacing"> </span>PLM<span class="heti-spacing"> </span></span>众多问题中的冰山一角。下面的这些问题我们还没涉及到，不过后面也不讲了，留给读者自己思考吧：</p>
<ul>
<li>为什么自监督的预训练有作用？</li>
<li>模型预测的可解释性<span><span class="heti-spacing"> </span>(interpretability)</span></li>
<li>领域调整</li>
<li>连续学习<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>终身学习</li>
<li>安全和隐私</li>
</ul>
<h3 id="pretrain-without-human-language">Pretrain without Human Language<a class="headerlink" href="#pretrain-without-human-language" title="Permanent link">⚓︎</a></h3>
<p>前面介绍的预训练基本都是在人类语言之上的，但实际上预训练也可以用在人造数据上。大致做法为：将根据规则产生的人造<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>用于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>等模型的预训练，微调后就能用于下游任务中。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/161.png"><img src="images/lec7/161.png" width="80%/"/></a>
</div>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/162.png"><img align="right" alt="" src="images/lec7/162.png" width="30%"/></a></p>
<p>下面来看在人造数据上预训练究竟有多大的提升：</p>
<ul>
<li>英文数据：效果最好</li>
<li>随机数据：没有起到正面效果（和从头开始训练模型差不多<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，体现了数据质量的重要性</li>
<li>
<p>成对数据：</p>
<ul>
<li>
<p>“成对”的意思是在生成的句子中，所有的词都是成对的</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/163.png"><img src="images/lec7/163.png" width="60%/"/></a>
</div><p></p>
</li>
<li>
<p>之所以这样也有不小提升，是因为人类语言中也有这种“成对出现”的规律——某些词一起出现的概率就是会比其他词大一些</p>
</li>
<li>由此可见，即便是考虑到简单的规则，也能提高预训练的表现</li>
<li>另见：<a href="https://arxiv.org/abs/2004.14601">Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models</a></li>
<li>打乱数据：将原来的数据顺序打乱后再喂给模型，然后让模型做填空题</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/164.png"><img src="images/lec7/164.png" width="40%/"/></a>
</div><p></p>
<p>下面是不同打乱情况的提升效果：</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/165.png"><img src="images/lec7/165.png" width="70%/"/></a>
</div><p></p>
<p>从中可以得到一个结论：在较长范围中学习一个句子是至关重要的</p>
</li>
</ul>
<h2 id="self-supervised-learning-for-speech-and-images">Self-Supervised Learning for Speech and Images<a class="headerlink" href="#self-supervised-learning-for-speech-and-images" title="Permanent link">⚓︎</a></h2>
<p>回想一下，前面介绍的自监督学习的任务大多是基于文本的任务，比如情感分析等。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/97.png"><img src="images/lec7/97.png" width="70%/"/></a>
</div>
<p>本节主要带大家认识一下自监督学习在语音和图像这两类任务上的应用。先来看语音相关的任务——对应的模型架构图如下：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/98.png"><img src="images/lec7/98.png" width="70%/"/></a>
</div>
<blockquote>
<p>注：左上角的小图表示少部分标注的语音数据，它们主要用于下游模型的训练，不过也可以用在底层的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>模型的微调，但不是必要的。</p>
</blockquote>
<p>可以看到，这和针对文本任务的的模型差别不大。</p>
<p>和语音任务相关的知名任务集是 <a href="https://superbbenchmark.org/"><strong>SUPERB</strong></a>，全称语音处理通用性能基准测试<span><span class="heti-spacing"> </span>(Speech processing Universal PERformance Benchmark)</span>，总共包含了以下<span class="heti-skip"><span class="heti-spacing"> </span>14<span class="heti-spacing"> </span></span>个细分的子任务，并且可以分成五大类。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/99.png"><img src="images/lec7/99.png" width="70%/"/></a>
</div>
<hr/>
<p>自监督学习可完成以下关于图像的任务：</p>
<ul>
<li>图像识别<span><span class="heti-spacing"> </span>(image recognition)</span></li>
<li>物体检测<span><span class="heti-spacing"> </span>(object detection)</span></li>
<li>语义分段<span><span class="heti-spacing"> </span>(semantic segmentation)</span></li>
<li>视觉导航<span><span class="heti-spacing"> </span>(visual navigation)</span></li>
</ul>
<p>下图展示了自监督学习在图像任务中的表现：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/100.png"><img src="images/lec7/100.png" width="60%/"/></a>
</div>
<p>图中的虚线表示监督学习（即在有足够标注数据的情况下训练模型）取得的表现。可以看到，尽管多数情况下自监督学习的表现不如监督学习，但是还是存在某些任务下自监督学习胜过监督学习的现象。</p>
<p>下面将会详细介绍一些专门训练用于完成语音和图像任务的模型的训练方法。</p>
<h3 id="generative-approaches">Generative Approaches<a class="headerlink" href="#generative-approaches" title="Permanent link">⚓︎</a></h3>
<p>首先介绍的是生成式的方法，而这样的方法正是原本<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>系列和<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>系列所做的事，所以我们只是在其基础上做了一些小修改。</p>
<p>在语音任务中，一种基于<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的语音模型叫做 <strong>Mockingjay</strong>（学舌鸟<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。正如其字面意思，该模型能做的事简单来说就是模仿它听到的声音。进一步来看，它的模型结构如下所示：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/101.png"><img src="images/lec7/101.png" width="60%/"/></a>
</div>
<p>其实和文本版的<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>差不多：将一段语音用一个个向量表示，然后掩盖其中一些向量，通过其余向量来预测对应的输出，希望与预期结果越接近越好，以达到重构的效果。</p>
<p>不过毕竟语音和文本还是有一些区别的，所以在训练时我们需要做以下调整：</p>
<ul>
<li>
<p>声学特征的平滑性：</p>
<ul>
<li>需要注意的是，表示语音的相邻的一组向量的特征会比较接近，所以只掩盖单个向量的话，模型很容易根据其相邻的向量猜出结果，从而影响到训练的质量</li>
<li>因此，在掩盖向量时，需要掩盖一连串的向量，以避免上述情况发生</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/102.png"><img src="images/lec7/102.png" width="50%/"/></a>
</div><p></p>
</li>
<li>
<p>语音的掩码策略：</p>
<ul>
<li>有时我们可以只对向量中的部分元素进行掩盖，这样做的好处是可以让模型习得更多有关说话者的信息</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/103.png"><img src="images/lec7/103.png" width="50%/"/></a>
</div><p></p>
</li>
</ul>
<p>将<span class="heti-skip"><span class="heti-spacing"> </span>GPT<span class="heti-spacing"> </span></span>系列模型用于语音任务的时候，道理同样和文本版的类似。下面展示了其中一个叫做 <strong>APC</strong>（全程自回归预测编码，autoregressive predictive coding）的模型的结构图：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/104.png"><img src="images/lec7/104.png" width="50%/"/></a>
</div>
<p>与文本的一个不同是，语音任务需要预测隔几个向量后的向量（通常会预测后<span class="heti-skip"><span class="heti-spacing"> </span>n<span class="heti-spacing"> </span></span>个向量，n &gt; 3<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，而文本任务只预测下一个向量。这还是因为语音任务中相邻向量的特征太过接近，仅预测下一个向量的话没有挑战性。</p>
<hr/>
<p>有关图像的这里不会详细介绍，感兴趣的读者可以阅读<span class="heti-skip"><span class="heti-spacing"> </span>OpenAI<span class="heti-spacing"> </span></span>的关于 <a href="https://openai.com/index/image-gpt/"><strong>Image GPT</strong> 的博客</a>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/105.png"><img src="images/lec7/105.png" width="90%/"/></a>
</div>
<h3 id="predictive-approaches">Predictive Approaches<a class="headerlink" href="#predictive-approaches" title="Permanent link">⚓︎</a></h3>
<p>上面介绍的生成法有一个问题：相比于文本，语音和图像会包含更多难以通过生成得到的细节。所以我们能否尝试用一种不用生成的方法来训练模型？所以下面就来介绍预测法，它就是那种没有用到生成的方法。</p>
<p>在图像中，一种预测法的用途是<strong>预测旋转</strong>(predicting rotation)：模型要做的是对于给定图像的多种旋转后的图像，判断图像旋转的度数。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/106.png"><img src="images/lec7/106.png" width="70%/"/></a>
</div>
<p>另一种有趣的应用是<strong>上下文预测</strong>(context prediction)：模型能根据两张图像（截取自同一图像上的两个不同的部分<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，判断图像<span class="heti-skip"><span class="heti-spacing"> </span>A<span class="heti-spacing"> </span></span>应该在图像<span class="heti-skip"><span class="heti-spacing"> </span>B<span class="heti-spacing"> </span></span>的哪个方位上。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/107.png"><img src="images/lec7/107.png" width="60%/"/></a>
</div>
<p>相似的思想也可用在语音任务上——给定两段相距一定距离的语音片段，让模型判断这两段语音相距多远。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/108.png"><img src="images/lec7/108.png" width="60%/"/></a>
</div>
<hr/>
<p>下面介绍一种比较通用的预测法（以语音任务为例<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/109.png"><img src="images/lec7/109.png" width="70%/"/></a>
</div>
<ul>
<li>先对语音做特征提取，得到一组向量，然后根据向量的特征进行分群<span class="heti-skip"><span class="heti-spacing"> </span>(clustering)<span class="heti-spacing"> </span></span>操作，每个向量会对应一个不同集群的<span><span class="heti-spacing"> </span>ID</span></li>
<li>然后将语音丢到模型中，对输出向量做线性转换，得到的也是一个集群的<span><span class="heti-spacing"> </span>ID</span>。训练的目标就是让模型输出的<span class="heti-skip"><span class="heti-spacing"> </span>ID<span class="heti-spacing"> </span></span>和真正的<span class="heti-skip"><span class="heti-spacing"> </span>ID<span class="heti-spacing"> </span></span>越接近越好</li>
</ul>
<p>这种方法做到了“化连续为离散”，简化了一些细节。下面列举了一些用到这种思想的模型：</p>
<ul>
<li>图像：<a href="https://arxiv.org/abs/2106.07447">HuBERT</a>, <a href="https://arxiv.org/abs/2202.01855">BEST-RQ</a></li>
<li>语音：<a href="https://arxiv.org/abs/1807.05520">DeepCluster</a></li>
</ul>
<h3 id="contrastive-learning">Contrastive Learning<a class="headerlink" href="#contrastive-learning" title="Permanent link">⚓︎</a></h3>
<p>另一种无需生成的方法是<strong>对比学习</strong>(contrastive learning)，它的基本思想是（以图像为例<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：对于相同类别的图像，希望它们经过编码器的输出向量越接近越好；对于不同类别的图像，希望它们经过编码器的输出向量相差越大越好。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/110.png"><img src="images/lec7/110.png" width="70%/"/></a>
</div>
<p>但有一个问题：我们现在讨论的是自监督学习，手边没有标注好的数据，所以不清楚图像属于哪个类别。其中一种最知名的方法是<a href="https://arxiv.org/abs/2002.05709"><span><span class="heti-spacing"> </span>SimCLR</span></a>，它的想法是先对已有的图像进行（随机的）<strong>数据增强</strong>(data augmentation)，比如随机剪切、颜色失真、高斯模糊等等。而同一图像经不同数据增强处理后的图像是属于同一类别的（是<span class="heti-skip"><span class="heti-spacing"> </span>positive<span class="heti-spacing"> </span></span>的<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，而不同图像的就不属于同一类别。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/111.png"><img src="images/lec7/111.png" width="70%/"/></a>
</div>
<blockquote>
<p>注：该方法也有<a href="https://arxiv.org/abs/2010.13991">适用于语音任务的版本</a>。</p>
</blockquote>
<p>另一种方法叫做<a href="https://arxiv.org/abs/1911.05722"><span><span class="heti-spacing"> </span>MoCo</span></a>，它其实先于<span class="heti-skip"><span class="heti-spacing"> </span>SimCLR<span class="heti-spacing"> </span></span>出现，但后来又根据<span class="heti-skip"><span class="heti-spacing"> </span>SimCLR<span class="heti-spacing"> </span></span>更新至<a href="https://arxiv.org/abs/2003.04297"><span class="heti-skip"><span class="heti-spacing"> </span>v2<span class="heti-spacing"> </span></span>版本</a>。相比<span class="heti-skip"><span class="heti-spacing"> </span>SimCLR<span class="heti-spacing"> </span></span>它多了内存分区<span class="heti-skip"><span class="heti-spacing"> </span>(memory bank)<span class="heti-spacing"> </span></span>和动量编码器<span><span class="heti-spacing"> </span>(momentum encoder)</span>。具体细节就留给大家自行探索了，这里不会展开介绍。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/112.png"><img src="images/lec7/112.png" width="80%/"/></a>
</div>
<hr/>
<p>类似地，对比学习同样能用于完成语音任务的自监督学习中，相应的架构图如下：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/113.png"><img src="images/lec7/113.png" width="80%/"/></a>
</div>
<blockquote>
<p>注：个人认为上图两个编码器应该是连在一起的，这里好像没画好<span><span class="heti-spacing"> </span>...</span></p>
</blockquote>
<p>不同于针对图像的模型，这里的模型除了编码器外，还用到一个预测器。对于某一段输入的语音，在训练的时候我们要将它在预测器的输出向量经过线性变换后的结果，和其他来自编码器的输出向量做比较：</p>
<ul>
<li>与相邻位置的输出是<span class="heti-skip"><span class="heti-spacing"> </span>postive<span class="heti-spacing"> </span></span>的关系，即希望两者越接近越好</li>
<li>与其他位置的输出是<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>的关系，即希望两者越疏远越好</li>
</ul>
<p>下面是一些比较知名的模型：</p>
<ul>
<li><a href="https://arxiv.org/abs/1807.03748">CPC</a>：用的是<span><span class="heti-spacing"> </span>GRU</span>（门控循环单元，gated recurrent unit）</li>
<li><a href="https://arxiv.org/abs/1904.05862">Wav2vec</a>：用的是<span><span class="heti-spacing"> </span>CNN</span></li>
</ul>
<p>后来有了一个叫做<a href="https://arxiv.org/abs/1910.05453"><span class="heti-skip"><span class="heti-spacing"> </span>VQ-wav2vec<span class="heti-spacing"> </span></span></a>的模型，它的特殊之处在于编码器输出的不是向量，而是离散的<span><span class="heti-spacing"> </span>ID</span>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/114.png"><img src="images/lec7/114.png" width="80%/"/></a>
</div>
<blockquote>
<p>关于如何针对这种离散输出进行训练的问题，请见<a href="8.html">后续章节</a>。</p>
</blockquote>
<p>接下来将这个离散输出喂给另一个类似文本版<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>的编码器（前提是前一个编码器已经训练过了<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。然后固定<span class="heti-skip"><span class="heti-spacing"> </span>VQ-wav2vec<span class="heti-spacing"> </span></span>的编码器，对另一个编码器训练，训练方式类似做填空题的那种。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/115.png"><img src="images/lec7/115.png" width="60%/"/></a>
</div>
<p>这种做法的好处是可以去掉说话者信息和其他不必要的噪音，让模型专注于语音内容。</p>
<p>现在回过头来看<span><span class="heti-spacing"> </span>Wav2vec 2.0</span>。相比<span><span class="heti-spacing"> </span>VQ-wav2vec</span>，它要求两个编码器是一起训练而不是单独分开训练的。还有一个较大的不同是第二个编码器接收的输入不是离散的<span><span class="heti-spacing"> </span>ID</span>，而是第一个编码器输出的向量，并且输出的也是向量。训练的时候会盖住第一个编码器的某个输出向量，然后希望它对应的第二个编码器的向量能够准确预测出相应的离散<span><span class="heti-spacing"> </span>ID</span>，而产生其他向量的离散<span class="heti-skip"><span class="heti-spacing"> </span>ID<span class="heti-spacing"> </span></span>的可能性则越小越好。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/116.png"><img src="images/lec7/116.png" width="70%/"/></a>
</div>
<p>该模型值得注意的点有：</p>
<ul>
<li>第二个模型的连续型输入（第一个模型的输出向量）是很关键的，因为向量相比单个离散值包含了更多的信息</li>
<li>量化目标（离散<span><span class="heti-spacing"> </span>ID</span>）有助于提高表现：之所以不直接比较向量，是因为实验结果表明，比较离散<span class="heti-skip"><span class="heti-spacing"> </span>ID<span class="heti-spacing"> </span></span>能取得更好的训练效果；但相比第一点，这一点并不是那么关键</li>
<li>也许一些聪明的读者会想到它和分类模型很像——确实如此，下面列出了分类和对比学习的简化结构：</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/117.png"><img src="images/lec7/117.png" width="70%/"/></a>
</div>
<p>但之所以没有按照分类方式来处理语音任务，是因为语音是连续的，可以分出无穷多个类，这显然是不现实的。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/118.png"><img src="images/lec7/118.png" width="80%/"/></a>
</div>
<p>下图展示了分类任务和<span class="heti-skip"><span class="heti-spacing"> </span>Wav2vec 2.0<span class="heti-spacing"> </span></span>各模块的对应关系（红框<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/119.png"><img src="images/lec7/119.png" width="80%/"/></a>
</div>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/120.png"><img src="images/lec7/120.png" width="80%/"/></a>
</div>
<hr/>
<p>对比学习的问题是，我们很难把握好<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>例子的分寸——既不能太简单（区分度太高，模型训练不出什么东西<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，也不能太难（区分度太低，比如硬要在同一类中找不同，这样训练很难<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/121.png"><img src="images/lec7/121.png" width="60%/"/></a>
</div>
<p>其中左图是原图，右图从上到下难度依次增大（太简单<span class="heti-skip"><span class="heti-spacing"> </span>-&gt;<span class="heti-spacing"> </span></span>适中<span class="heti-skip"><span class="heti-spacing"> </span>-&gt;<span class="heti-spacing"> </span></span>太难<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<h3 id="bootstrapping-approaches">Bootstrapping Approaches<a class="headerlink" href="#bootstrapping-approaches" title="Permanent link">⚓︎</a></h3>
<p>由于“很难把握好<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>例子的分寸”，所以我们干脆在模型学习的时候不管<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>例子了。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/122.png"><img src="images/lec7/122.png" width="40%/"/></a>
</div>
<p>但这样做显然会有问题：由于没有<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>例子，模型会认为所有的输入数据都是类似的，那么最后大家得到几近相同的输出，那就没有任何意义了（这种现象称为<strong>崩溃</strong>(collapse)<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。因此在原模型的基础上，做以下改动：</p>
<ul>
<li>只更新其中一侧的编码器，而且那一侧用到了预测器（以区分两边的网络架构，否则还是会崩溃）</li>
<li>更新好一侧的编码器后，将该编码器的参数复制给另一个编码器</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/123.png"><img src="images/lec7/123.png" width="40%/"/></a>
</div>
<p>这又是一个很玄学的做法，至今也没有人能给出很好的解释<span><span class="heti-spacing"> </span>...</span></p>
<hr/>
<p>下面从另一个角度来理解这个叫做<strong>自举</strong><span>(bootstrapping)<span class="heti-spacing"> </span></span>法的方法——<strong>典型知识蒸馏</strong>(typical knowledge distillation)</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/124.png"><img src="images/lec7/124.png" width="70%/"/></a>
</div>
<blockquote>
<p>左图是原来只考虑<span class="heti-skip"><span class="heti-spacing"> </span>positive<span class="heti-spacing"> </span></span>例子的模型，右图是用到自举法的模型。</p>
</blockquote>
<p>自举法的具体实现有：</p>
<ul>
<li>
<p>图像：</p>
<ul>
<li>
<p>Bootstrap Your Own Latent(<a href="https://arxiv.org/abs/2006.07733">BYOL</a>)</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/125.png"><img src="images/lec7/125.png" width="50%/"/></a>
</div><p></p>
</li>
<li>
<p>Simple Siamese(<a href="https://arxiv.org/abs/2011.10566">SimSiam</a>)</p>
</li>
<li>语音：</li>
<li><a href="https://arxiv.org/abs/2202.03555">Data2vec</a>: the student learns from multiple layers of the teacher </li>
</ul>
</li>
</ul>
<h3 id="simply-extra-regularization">Simply Extra Regularization<a class="headerlink" href="#simply-extra-regularization" title="Permanent link">⚓︎</a></h3>
<p>另一种没有用到<span class="heti-skip"><span class="heti-spacing"> </span>negative<span class="heti-spacing"> </span></span>例子的方法是做一些简单的，额外的<strong>正则化</strong>(regularization)，包括<a href="https://arxiv.org/abs/2103.03230"><span class="heti-skip"><span class="heti-spacing"> </span>Barlow Twins<span class="heti-spacing"> </span></span></a>和<a href="https://arxiv.org/abs/2105.04906"><span class="heti-skip"><span class="heti-spacing"> </span>Variance-Invariance-Covariance Regularization (VICReg)<span class="heti-spacing"> </span></span></a>两类相似的方法。下面就以后者为例展开介绍：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/126.png"><img src="images/lec7/126.png" width="90%/"/></a>
</div>
<ul>
<li><strong>不变性</strong>(invariance)：还是用原来的模型</li>
<li><strong>方差</strong>(variance)：考虑不同图像经过编码器得到向量的每个维度，要求每一维元素的方差足够大</li>
<li><strong>协方差</strong>(covariance)：将前面得到的一组向量看做一个矩阵，要求这个矩阵非对角线上的元素尽可能接近<span><span class="heti-spacing"> </span>0</span>，这样可以让训练得到的特征尽可能发散，不至于分布过于集中</li>
</ul>
<p>其中最重要的还是不变性<span class="heti-skip"><span class="heti-spacing"> </span>+<span class="heti-spacing"> </span></span>方差的要求。</p>
<p>该方法也可以用在语音上，对应的模型叫做<a href="https://arxiv.org/abs/2203.13628"><span><span class="heti-spacing"> </span>DeLoRes</span></a>。</p>
<h2 id="auto-encoder">Auto-encoder<a class="headerlink" href="#auto-encoder" title="Permanent link">⚓︎</a></h2>
<h3 id="basic-ideas_2">Basic Ideas<a class="headerlink" href="#basic-ideas_2" title="Permanent link">⚓︎</a></h3>
<p><strong>自编码器</strong><span>(auto-encoder)<span class="heti-spacing"> </span></span>也是自监督学习的一种方式。以图像为例，它能做的是：</p>
<ul>
<li>将未标注的图像丢给一个编码器，得到一个向量（称为<strong>嵌入</strong>(embedding)/<strong>代表</strong>(representation)/<strong>编码</strong>(code)）</li>
<li>然后将向量丢给一个解码器，得到新的图像，这个图像应当和原图像越接近越好（因此这个过程也称为<strong>重构</strong>(reconstruction)）</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/127.png"><img src="images/lec7/127.png" width="70%/"/></a>
</div>
<blockquote>
<p>看起来是不是很熟悉？上一讲的<a href="6.html#learning-from-unpaired-data"><span class="heti-skip"><span class="heti-spacing"> </span>Cycle GAN<span class="heti-spacing"> </span></span></a>的做法也是类似的！</p>
</blockquote>
<p>我们将原图像当做高维的旧特征，而向量当做用于下游任务的低维（因而这个向量又被称作<strong>瓶颈</strong>(bottleneck)）的新特征，所以从原图像到向量的过程被称为<strong>降维</strong>(dimension reduction)。</p>
<details class="info">
<summary>补充</summary>
<p>下面是一些不涉及到深度学习的降维技术，这部分的细节不再涉及，感兴趣的读者可点击链接观看相关视频：</p>
<ul>
<li><a href="https://youtu.be/iwh5o_M4BNU">PCA</a></li>
<li><a href="https://youtu.be/GBUEjkpoxXc">t-SNE</a></li>
</ul>
</details>
<p>下面来解释一下为什么我们要用到自编码器。现在假设输入的图像规模是<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>的，而向量是<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>维的。可以想到的是，图像（<del>这里尤指二次元人像</del>）可不是一堆无意义的像素——要想成为一张对人类来说内容有意义的图像，其图像内容必定会有一些部分遵循一定的<strong>模式</strong>(pattern)，所以会出现一些图像在某些地方具备相同模式的情况。而模式的数量往往是有限多个，所以用原图像规模表示所有的模式可能是多余的。这时可以用更少维度的向量来表示这些模式，这样模型便能抓住了图像中某些本质上的东西。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/128.png"><img src="images/lec7/128.png" width="70%/"/></a>
</div>
<p>对于这里的例子，<span>3x3<span class="heti-spacing"> </span></span>的图像就只有两种类型，也就是说只有两类模式，那么我们可以用<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>维向量来简化模式的表示。</p>
<details class="info">
<summary>自编码器并不是全新的概念</summary>
<ul>
<li>早在<span class="heti-skip"><span class="heti-spacing"> </span>06<span class="heti-spacing"> </span></span>年，辛顿等人就已经提出过相关概念了，只不过当时的神经网络还没现在这么成熟</li>
<li>图中的<span class="heti-skip"><span class="heti-spacing"> </span>RBM<span class="heti-spacing"> </span></span>全称为受限玻尔兹曼机<span><span class="heti-spacing"> </span>(Restricted Boltzmann Machine)</span>，对现在而言是一种过时的技术</li>
</ul>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/129.png"><img src="images/lec7/129.png" width="60%/"/></a>
</div> <p></p>
</details>
<hr/>
<p>自编码器的一种简单变体是<strong>去噪自编码器</strong>(de-noising auto-encoder)。它不直接将原图像丢给编码器，而是先向原图像加一点噪音，将这个新图像丢给编码器，后续通过解码器得到的图像还是跟原图像对比，要求越接近越好。个人认为这样可以增强模型的抗干扰能力。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/130.png"><img src="images/lec7/130.png" width="70%/"/></a>
</div>
<p>去噪自编码器的原理和<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>很像：<span>BERT<span class="heti-spacing"> </span></span>掩盖某些输入<span class="heti-skip"><span class="heti-spacing"> </span>token<span class="heti-spacing"> </span></span>相当于去噪自编码器中为图像加的噪音。所以有时我们可以将<span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span>看做是一个去噪自编码器。</p>
<h3 id="feature-disentanglement">Feature Disentanglement<a class="headerlink" href="#feature-disentanglement" title="Permanent link">⚓︎</a></h3>
<p>值得注意的是，自编码器中间产生的向量包含了关于输入数据的多种不同方面的信息。对于不同类型的数据，这种向量也许会包含以下信息：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/131.png"><img src="images/lec7/131.png" width="70%/"/></a>
</div>
<p>如果不加处理的话，可能会存在多种信息混杂在向量的单个或多个维度的元素中，这样我们很难直接从向量各元素中找出有用信息（换句话说，这些信息纠缠<span class="heti-skip"><span class="heti-spacing"> </span>(entangle)<span class="heti-spacing"> </span></span>在了一起<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。因此，我们希望做的就是让向量各元素“各司其职”：一部分元素只记录其中一类信息，另外的元素记录另外的信息。这种做法就叫做<strong>特征解缠</strong>(feature disentanglement)。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/132.png"><img src="images/lec7/132.png" width="70%/"/></a>
</div>
<hr/>
<p>特征解缠的一大应用是<strong>语音转换</strong>(voice conversion)，简单来说就是让<span class="heti-skip"><span class="heti-spacing"> </span>A<span class="heti-spacing"> </span></span>说过的话通过<span class="heti-skip"><span class="heti-spacing"> </span>B<span class="heti-spacing"> </span></span>的语气说出来（<del>最直接的例子就是柯南领结上的变声器</del><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<p>在没有自编码器的年代，要想训练完成这一任务的模型，需要有一组关于说话者<span class="heti-skip"><span class="heti-spacing"> </span>A<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>B<span class="heti-spacing"> </span></span>的语音，其内容必须是一致的。但有了自编码器后，就不需要遵守这样严苛的要求了：<span>A<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>B<span class="heti-spacing"> </span></span>可以讲不同的话，甚至可以是不同语言的话。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/133.png"><img src="images/lec7/133.png" width="70%/"/></a>
</div>
<details class="example" open="open">
<summary>例子</summary>
<p>假如让模型训练了一段关于李宏毅老师和新垣结衣的语音。注意到语音内容和语言都是不同的。</p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/134.png"><img src="images/lec7/134.png" width="70%/"/></a>
</div><p></p>
<p>如果在经过编码器后，将李宏毅老师那边有关语音内容的向量部分和<span class="heti-skip"><span class="heti-spacing"> </span>gakki<span class="heti-spacing"> </span></span>那边有关说话者的向量部分拼接在一起，然后将得到的新向量丢给解码器，就能生成一段用<span class="heti-skip"><span class="heti-spacing"> </span>gakki<span class="heti-spacing"> </span></span>语气念李宏毅老师语音内容的语音。</p>
<p>（<del>看到油管评论区有人说可以训一个模型，用<span class="heti-skip"><span class="heti-spacing"> </span>gakki<span class="heti-spacing"> </span></span>的语气讲李宏毅老师的课</del>）</p>
</details>
<h3 id="discrete-latent-representation">Discrete Latent Representation<a class="headerlink" href="#discrete-latent-representation" title="Permanent link">⚓︎</a></h3>
<p>中间向量的元素不一定只能用实数表示，也可以表示成二进制表示或独热向量。</p>
<ul>
<li>在二进制表示中，每一维元素表示图像的一个特征，比如男女，是否戴眼镜等等</li>
<li>而独热向量则可以表示属于某个特定类别的图像（相当于让模型完成一个分类任务）</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/135.png"><img src="images/lec7/135.png" width="70%/"/></a>
</div>
<hr/>
<p>还有一种离散表示法叫做 <a href="https://arxiv.org/abs/1711.00937"><strong>VQVAE</strong></a>（全称向量量化变分自编码器，vector quantized variational auto-encoder<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。相比一般的自编码器，它在解码器部分的输入处理上有所不同——不是直接接收编码器的输出向量，而是从一个<strong>编码本</strong>(codebook)（即一组给定向量）中挑选一个和编码器输出向量最接近（相似度最高）的那个向量作为输入。这样我们就让解码器的输入限制在一个有限的范围内，而不是像原来那样有各种各样的输入可能。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/136.png"><img src="images/lec7/136.png" width="70%/"/></a>
</div>
<p>其中计算相似度的步骤类似自注意机制中计算注意分数的步骤类似。</p>
<p>该方法同样适用于<a href="https://arxiv.org/pdf/1901.08810.pdf">语音任务</a>中，此时编码本的表示的是发音上的信息（比如中文拼音<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<hr/>
<p>另外一种神奇的表示法是用<strong>文本</strong>替代中间向量。这种方法用在文档总结这样的任务中非常合适——让模型接收文档输入，编码器的输出就作为文档的总结内容，然后将总结丢给解码器得到新文档，训练目标就是让两个文档越接近越好。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/137.png"><img src="images/lec7/137.png" width="70%/"/></a>
</div>
<ul>
<li>由于输入<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>输出是文档<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>总结，它们都是文本序列，因此编码器和解码器都是<span class="heti-skip"><span class="heti-spacing"> </span>seq2seq<span class="heti-spacing"> </span></span>的模型</li>
<li>自编码器用大量（未标注）的文档训练模型，因此这个任务被称为<strong>无监督总结</strong>(unsupervised summarization)</li>
<li>事实上，如果不加控制，所谓的“总结”不一定是一段有意义的文本<ul>
<li>解决方法是借鉴<span class="heti-skip"><span class="heti-spacing"> </span>GAN<span class="heti-spacing"> </span></span>的做法，引入一个判别器，将“总结”丢给判别器</li>
<li>判别器为真实的人类手写总结打高分，为机器生成的总结打低分，因此编码器应想办法骗过“判别器”</li>
<li>在这一过程中，生成总结的质量得以提高</li>
</ul>
</li>
</ul>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/138.png"><img src="images/lec7/138.png" width="70%/"/></a>
</div>
<details class="example" open="open">
<summary>模型表现</summary>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/139.png"><img src="images/lec7/139.png" width="60%/"/></a>
</div><p></p>
<p></p><div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/140.png"><img src="images/lec7/140.png" width="60%/"/></a>
</div><p></p>
</details>
<hr/>
<p>中间向量还可以用一棵树表示：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/141.png"><img src="images/lec7/141.png" width="70%/"/></a>
</div>
<h3 id="more-applications">More Applications<a class="headerlink" href="#more-applications" title="Permanent link">⚓︎</a></h3>
<h4 id="generator">Generator<a class="headerlink" href="#generator" title="Permanent link">⚓︎</a></h4>
<p>自编码器中的解码器可以看作一个生成器：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/142.png"><img src="images/lec7/142.png" width="70%/"/></a>
</div>
<p>在此基础上稍作修改，我们可以得到一种叫做<strong>变分自编码器</strong><span>(variational auto-encoder, VAE)<span class="heti-spacing"> </span></span>的生成式模型。</p>
<h4 id="compression">Compression<a class="headerlink" href="#compression" title="Permanent link">⚓︎</a></h4>
<p>自编码器中，高维图像转为低维向量的过程可看作是一个<strong>压缩</strong><span>(compression)<span class="heti-spacing"> </span></span>的操作，反之就是一个<strong>解压缩</strong><span>(decompression)<span class="heti-spacing"> </span></span>的操作。但自编码器的压缩是一种<strong>有损</strong><span>(lossy)<span class="heti-spacing"> </span></span>压缩，所以自编码器的输入输出不一定一模一样。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/143.png"><img src="images/lec7/143.png" width="70%/"/></a>
</div>
<h4 id="anomaly-detection">Anomaly Detection<a class="headerlink" href="#anomaly-detection" title="Permanent link">⚓︎</a></h4>
<p>自编码器还可用于<strong>异常检测</strong><span>(anormaly detection)<span class="heti-spacing"> </span></span>的任务中。这个任务的内容是：先让模型在给定的数据集<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\{x^1, x^2, \dots, x^N\}\)</span><span class="heti-spacing"> </span></span>上训练，然后让模型看一个输入<span><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span></span>，判断该输入是否和训练数据集的数据相似。如果相似的话，那么认为<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>是正常的，否则认为<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>是异常的。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/144.png"><img src="images/lec7/144.png" width="70%/"/></a>
</div>
<p>对于不同的训练数据集，模型的评判“异常”数据的标准也会有所不同：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/145.png"><img src="images/lec7/145.png" width="70%/"/></a>
</div>
<p>异常检测在实际生活中的应用：</p>
<ul>
<li>欺诈检测<span><span class="heti-spacing"> </span>(fraud detection)</span><ul>
<li>训练数据：信用卡交易记录</li>
<li><span class="arithmatex">\(x\)</span>：是否有欺诈</li>
<li>相关工作：<a href="https://www.kaggle.com/ntnu-testimon/paysim1/home">链接<span><span class="heti-spacing"> </span>1</span></a>，<a href="https://www.kaggle.com/mlg-ulb/creditcardfraud/home">链接<span><span class="heti-spacing"> </span>2</span></a></li>
</ul>
</li>
<li>网络入侵检测<span><span class="heti-spacing"> </span>(network intrusion detection)</span><ul>
<li>训练数据：网络连接信息</li>
<li><span class="arithmatex">\(x\)</span>：是否属于攻击</li>
<li><a href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html">相关工作</a></li>
</ul>
</li>
<li>癌症检测<span><span class="heti-spacing"> </span>(cancer detection)</span><ul>
<li>训练数据：正常细胞</li>
<li><span class="arithmatex">\(x\)</span>：是否是癌细胞</li>
<li><a href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/home">相关工作</a></li>
</ul>
</li>
</ul>
<p>下面来看异常检测在自编码器中是如何实现的——我们将真实人像作为训练数据集训练：</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/146.png"><img src="images/lec7/146.png" width="70%/"/></a>
</div>
<p>接下来让训练好的模型来判断输入的图像是否是真实人像，如果是的话，模型就能重构图像；</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/147.png"><img src="images/lec7/147.png" width="70%/"/></a>
</div>
<p>否则的话模型无法重构图像。</p>
<div style="text-align: center">
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="auto" href="images/lec7/148.png"><img src="images/lec7/148.png" width="70%/"/></a>
</div>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="最后更新">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年8月23日 18:28:24">2025年8月23日 18:28:24</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="创建日期">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年3月2日 21:04:42">2025年3月2日 21:04:42</span>
</span>
</aside>
<p style="font-size: 30px; font-weight: 600">评论区</p>
<div>
    如果大家有什么问题或想法，欢迎在下方留言~
  </div>
<!-- Insert generated snippet here -->
<script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOMAb9Zs4CfmpP" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="noughtq/notebook" data-repo-id="R_kgDOMAb9Zg" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
<!-- 标题计数器 -->
<link href="/css/counter.css" rel="stylesheet"/>
<!-- 主页个性化 -->
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="上一页: Generative Adversarial Network" class="md-footer__link md-footer__link--prev" href="6.html">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                上一页
              </span>
<div class="md-ellipsis">
                Generative Adversarial Network
              </div>
</div>
</a>
<a aria-label="下一页: Explainable Machine Learning" class="md-footer__link md-footer__link--next" href="8.html">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                Explainable Machine Learning
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z" fill="currentColor"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright" style="margin-left: 33.5%">
<div class="md-copyright__highlight" style="text-align: center">
        Copyright © 2024-2025 <a href="https://github.com/NoughtQ">NoughtQ</a>
</div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" rel="noopener" target="_blank">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
        Material
      </a>
      modified by
      <a href="https://github.com/NoughtQ" rel="noopener" target="_blank">
        NoughtQ
      </a>
<!-- <br> -->
<div style="text-align: center;">
<a href="https://icp.gov.moe/?keyword=20252357" target="_blank">萌ICP备20252357号</a>
</div>
</div>
<div class="md-social">
<a class="md-social__link" href="https://noughtq.top" rel="noopener" target="_blank" title="noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M277.8 8.6c-12.3-11.4-31.3-11.4-43.5 0l-224 208c-9.6 9-12.8 22.9-8 35.1S18.8 272 32 272h16v176c0 35.3 28.7 64 64 64h288c35.3 0 64-28.7 64-64V272h16c13.2 0 25-8.1 29.8-20.3s1.6-26.2-8-35.1zM240 320h32c26.5 0 48 21.5 48 48v96H192v-96c0-26.5 21.5-48 48-48" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://blog.noughtq.top" rel="noopener" target="_blank" title="blog.noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/noughtq" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="mailto:noughtq666@gmail.com" rel="noopener" target="_blank" title="">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.copy", "content.code.annotate", "content.footnote.tooltips", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.indexes", "navigation.tracking", "navigation.prune", "search.share"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
<script src="../../js/anchor.js"></script>
<script src="../../js/katex.js"></script>
<script src="../../js/toc.js"></script>
<script src="../../js/typed.js"></script>
<script src="../../js/custom.js"></script>
<script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
<script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>