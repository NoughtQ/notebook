<!DOCTYPE html>
<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="NoughtQ的笔记本，主要记录一些 CS 相关的笔记" name="description"/>
<meta content="NoughtQ" name="author"/>
<link href="https://notebook.noughtq.top/ai/genai/9.html" rel="canonical"/>
<link href="8.html" rel="prev"/>
<link href="10.html" rel="next"/>
<link href="../../feed_rss_created.xml" rel="alternate" title="RSS 订阅" type="application/rss+xml"/>
<link href="../../feed_rss_updated.xml" rel="alternate" title="已更新内容的 RSS 订阅" type="application/rss+xml"/>
<link href="../../assets/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.18" name="generator"/>
<title>Image and Video Generation - NoughtQ的笔记本</title>
<link href="../../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=JetBrains+Mono,+LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono,+Consolas:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"JetBrains Mono, LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono, Consolas"}</style>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="../../css/toc_extra.css" rel="stylesheet"/>
<link href="../../css/timeline.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/extra_changelog.css" rel="stylesheet"/>
<link href="../../css/header.css" rel="stylesheet"/>
<link href="../../css/sidebar.css" rel="stylesheet"/>
<link href="https://unpkg.com/katex@0/dist/katex.min.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&amp;display=swap" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-43NH8CVRCJ"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-43NH8CVRCJ",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-43NH8CVRCJ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#image-and-video-generation">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="NoughtQ的笔记本" class="md-header__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            NoughtQ的笔记本
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Image and Video Generation
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Dark Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: dark)" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Dark Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
<input aria-label="Light Mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefer-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Light Mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<a aria-label="分享" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="分享">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../index.html">
          
  
  
    
  
  🏫主页

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../lang/index.html">
          
  
  
    
  
  🔡语言

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../math/index.html">
          
  
  
    
  
  📊数学相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../algorithms/index.html">
          
  
  
    
  
  🧮算法相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../software/index.html">
          
  
  
    
  
  💾软件相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../system/index.html">
          
  
  
    
  
  💻系统相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../web/index.html">
          
  
  
    
  
  🌏Web相关

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../sec/ctf-101/index.html">
          
  
  
    
  
  🛡️信息安全

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../index.html">
          
  
  
    
  
  🤖人工智能

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../misc/index.html">
          
  
  
    
  
  🗃️杂项

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tools/index.html">
          
  
  
    
  
  🛠️工具

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../papers/index.html">
          
  
  
    
  
  📑论文阅读

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="NoughtQ的笔记本" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="NoughtQ的笔记本">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.05 9H7.06V6h1.99V4.03H7.06v-1c0-1.11.89-1.99 1.99-1.99h5.98V8l2.47-1.5L20 8V1.04h1c1.05 0 2 .96 2 1.99V17c0 1.03-.95 2-2 2H9.05c-1.05 0-1.99-.95-1.99-2v-1h1.99v-2H7.06v-3h1.99zM1 18h2v-3H1v-2h2v-3H1V8h2V5h2v3H3v2h2v3H3v2h2v3H3v2h2v1h16v2H5a2 2 0 0 1-2-2v-1H1z"></path></svg>
</a>
    NoughtQ的笔记本
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/noughtq/notebook" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    NoughtQ/Notebook
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../index.html">
<span class="md-ellipsis">
    🏫主页
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../lang/index.html">
<span class="md-ellipsis">
    🔡语言
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../math/index.html">
<span class="md-ellipsis">
    📊数学相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../algorithms/index.html">
<span class="md-ellipsis">
    🧮算法相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../software/index.html">
<span class="md-ellipsis">
    💾软件相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../system/index.html">
<span class="md-ellipsis">
    💻系统相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../web/index.html">
<span class="md-ellipsis">
    🌏Web相关
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../sec/ctf-101/index.html">
<span class="md-ellipsis">
    🛡️信息安全
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../index.html">
<span class="md-ellipsis">
    🤖人工智能
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
            🤖人工智能
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../ml/index.html">
<span class="md-ellipsis">
    机器学习
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_9_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="index.html">
<span class="md-ellipsis">
    生成式人工智能
    
  </span>
</a>
<label class="md-nav__link" for="__nav_9_3" id="__nav_9_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_9_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_9_3">
<span class="md-nav__icon md-icon"></span>
            生成式人工智能
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1.html">
<span class="md-ellipsis">
    Introduction
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2.html">
<span class="md-ellipsis">
    Prompt Engineering
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="3.html">
<span class="md-ellipsis">
    LLM Training
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4.html">
<span class="md-ellipsis">
    AI Agent
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="5.html">
<span class="md-ellipsis">
    Explainability
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="6.html">
<span class="md-ellipsis">
    Evaluation
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="7.html">
<span class="md-ellipsis">
    Security
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="8.html">
<span class="md-ellipsis">
    Generation Strategies
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Image and Video Generation
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="9.html">
<span class="md-ellipsis">
    Image and Video Generation
    
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#images">
<span class="md-ellipsis">
      Images
    </span>
</a>
<nav aria-label="Images" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#text-to-image">
<span class="md-ellipsis">
      Text-to-Image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#evaluation">
<span class="md-ellipsis">
      Evaluation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#customization">
<span class="md-ellipsis">
      Customization
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#videos">
<span class="md-ellipsis">
      Videos
    </span>
</a>
<nav aria-label="Videos" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#challenge">
<span class="md-ellipsis">
      Challenge
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#approaches">
<span class="md-ellipsis">
      Approaches
    </span>
</a>
<nav aria-label="Approaches" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#vae-and-flow-based">
<span class="md-ellipsis">
      VAE and Flow-based
    </span>
</a>
<nav aria-label="VAE and Flow-based" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#flow-based-generative-model">
<span class="md-ellipsis">
      Flow-based Generative Model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#diffusion">
<span class="md-ellipsis">
      Diffusion
    </span>
</a>
<nav aria-label="Diffusion" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#stable-diffusion">
<span class="md-ellipsis">
      Stable Diffusion
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#denoising-diffusion-probabilistic-model">
<span class="md-ellipsis">
      Denoising Diffusion Probabilistic Model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#gan">
<span class="md-ellipsis">
      GAN
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#others">
<span class="md-ellipsis">
      Others
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="10.html">
<span class="md-ellipsis">
    Voice Mode of GPT-4o
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="11.html">
<span class="md-ellipsis">
    Inner Workings of Transformer-based LM
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../cv/index.html">
<span class="md-ellipsis">
    计算机视觉导论
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../misc/index.html">
<span class="md-ellipsis">
    🗃️杂项
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tools/index.html">
<span class="md-ellipsis">
    🛠️工具
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../papers/index.html">
<span class="md-ellipsis">
    📑论文阅读
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
        目录
      </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#images">
<span class="md-ellipsis">
      Images
    </span>
</a>
<nav aria-label="Images" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#text-to-image">
<span class="md-ellipsis">
      Text-to-Image
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#evaluation">
<span class="md-ellipsis">
      Evaluation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#customization">
<span class="md-ellipsis">
      Customization
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#videos">
<span class="md-ellipsis">
      Videos
    </span>
</a>
<nav aria-label="Videos" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#challenge">
<span class="md-ellipsis">
      Challenge
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#approaches">
<span class="md-ellipsis">
      Approaches
    </span>
</a>
<nav aria-label="Approaches" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#vae-and-flow-based">
<span class="md-ellipsis">
      VAE and Flow-based
    </span>
</a>
<nav aria-label="VAE and Flow-based" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#flow-based-generative-model">
<span class="md-ellipsis">
      Flow-based Generative Model
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#diffusion">
<span class="md-ellipsis">
      Diffusion
    </span>
</a>
<nav aria-label="Diffusion" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#stable-diffusion">
<span class="md-ellipsis">
      Stable Diffusion
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#denoising-diffusion-probabilistic-model">
<span class="md-ellipsis">
      Denoising Diffusion Probabilistic Model
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#applications">
<span class="md-ellipsis">
      Applications
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#gan">
<span class="md-ellipsis">
      GAN
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#others">
<span class="md-ellipsis">
      Others
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/edit/master/docs/ai/genai/9.md" rel="edit" title="编辑此页">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<a class="md-content__button md-icon" href="https://github.com/noughtq/notebook/raw/master/docs/ai/genai/9.md" title="查看本页的源代码">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
</a>
<div><h1 id="image-and-video-generation">Image and Video Generation<a class="headerlink" href="#image-and-video-generation" title="Permanent link">⚓︎</a></h1>
<div style="margin-top: -30px; font-size: 0.9em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>8288<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>41<span class="heti-spacing"> </span></span>分钟</p>
</div>
<p>和影像有关的生成式<span class="heti-skip"><span class="heti-spacing"> </span>AI<span class="heti-spacing"> </span></span>包括：</p>
<div style="text-align: center">
<img src="images/lec9/1.png" width="60%/"/>
</div>
<blockquote>
<p>当然还有图生图的架构，不过这里没有列出来。</p>
</blockquote>
<p>其中第一种形式（“看图说话”）在前面已多次介绍过，而且现在的模型基本具备阅读和理解图像的能力了，所以这里不再赘述了。那么接下来就直接看第二种形式——文生图了。<span>24<span class="heti-spacing"> </span></span>年年初<span class="heti-skip"><span class="heti-spacing"> </span>OpenAI<span class="heti-spacing"> </span></span>爆出的<a href="https://sora.chatgpt.com/"><span class="heti-skip"><span class="heti-spacing"> </span>Sora<span class="heti-spacing"> </span></span></a>就是一种文生图的模型，下面展示了一些使用<span class="heti-skip"><span class="heti-spacing"> </span>Sora<span class="heti-spacing"> </span></span>的例子：</p>
<details class="example">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="" id="__tabbed_1_1" name="__tabbed_1" type="radio"/><input id="__tabbed_1_2" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="__tabbed_1_1">例<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span></label><label for="__tabbed_1_2">例<span><span class="heti-spacing"> </span>2</span></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div class="video-container"><video alt="type:video" controls="" style="position:relative;width:100%;height:22.172vw"><source src="images/lec9/2.mp4" type="video/mp4"/></video></div>
<p>Prompt: Animated scene features a close-up of a short fluffy monster kneeling beside a melting red candle. The art style is 3D and realistic, with a focus on lighting and texture.</p>
</div>
<div class="tabbed-block">
<p></p><div class="video-container"><video alt="type:video" controls="" style="position:relative;width:100%;height:22.172vw"><source src="images/lec9/3.mp4" type="video/mp4"/></video></div>
<p>Prompt: New York City submerged like Atlantis. Fish, whales, sea turtles and sharks swim through the streets of New York.</p>
</div>
</div>
</div>
<p>这里生成的都是一些现实世界中不存在的东西。不过这些视频还都有些小瑕疵，比如例<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span>小怪兽没动，后面的墙壁却移动了；例<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>的龟变成了鱼等等。</p>
<hr/>
<p>下面<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>个例子的<span class="heti-skip"><span class="heti-spacing"> </span>bug<span class="heti-spacing"> </span></span>还要多</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="" id="__tabbed_2_1" name="__tabbed_2" type="radio"/><input id="__tabbed_2_2" name="__tabbed_2" type="radio"/><div class="tabbed-labels"><label for="__tabbed_2_1">例<span class="heti-skip"><span class="heti-spacing"> </span>3<span class="heti-spacing"> </span></span></label><label for="__tabbed_2_2">例<span><span class="heti-spacing"> </span>4</span></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div class="video-container"><video alt="type:video" controls="" style="position:relative;width:100%;height:22.172vw"><source src="images/lec9/4.mp4" type="video/mp4"/></video></div>
<p>Prompt: Five gray wolf pups frolicking and chasing each other around a remote gravel road, surrounded by grass. The pups run and leap, chasing each other, and nipping at each other, playing.</p>
</div>
<div class="tabbed-block">
<p></p><div class="video-container"><video alt="type:video" controls="" style="position:relative;width:100%;height:22.172vw"><source src="images/lec9/5.mp4" type="video/mp4"/></video></div>
<p>Prompt: Archeologists discover a generic plastic chair in the desert, excavating and dusting it with great care.</p>
</div>
</div>
</div>
</details>
<p>第三种没列出来的形式是影像生影像，它的具体应用包括：</p>
<ul>
<li>影片补全</li>
<li>风格转换</li>
<li>画质提升（分辨率 ⬆️）</li>
<li>...</li>
</ul>
<div style="text-align: center">
<img src="images/lec9/6.png" width="60%/"/>
</div>
<p>此外，还有通过其他输入生成图像的方式，比如<span class="heti-skip"><span class="heti-spacing"> </span>Talking Head<span class="heti-spacing"> </span></span>模型将一段语音和一张图像作为输入，生成基于这些输入的视频。</p>
<p><img align="left" alt="" src="images/lec9/7.png" width="45%"/></p>
<p></p><div class="video-container"><video alt="type:video" controls="" style="width: 30%"><source src="images/lec9/8.mp4" type="video/mp4"/></video></div>
<ul>
<li><a href="https://arxiv.org/abs/2403.17694">论文</a></li>
<li><a href="https://huggingface.co/spaces/ZJYang/AniPortrait_official">Demo</a></li>
</ul>
<p>另一个例子是根据简笔画生成具体的图像（<a href="https://arxiv.org/abs/2302.05543">ControlNet</a><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<img src="images/lec9/9.png" width="60%/"/>
</div>
<hr/>
<p>在正式了解<span class="heti-skip"><span class="heti-spacing"> </span>AI<span class="heti-spacing"> </span></span>生成图像<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>视频的原理前，先来认识一下它们的基本单位：</p>
<ul>
<li>
<p>图像由像素构成</p>
<p></p><div style="text-align: center">
<img src="images/lec9/10.png" width="50%/"/>
</div>
</li>
<li>
<p>视频实际上由多张图像构成</p>
</li>
<li>
<p>每张图像被称作<strong>帧</strong>(frame)</p>
</li>
<li>
<p>对应的基本单位为 <strong>FPS</strong>（帧每秒，frame per second<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，显然<span class="heti-skip"><span class="heti-spacing"> </span>FPS<span class="heti-spacing"> </span></span>越高视频越流畅</p>
<p></p><div style="text-align: center">
<img src="images/lec9/11.png" width="60%/"/>
</div>
</li>
</ul>
<p><span>AI<span class="heti-spacing"> </span></span>理解图像时会把图像划分为多个<strong>块</strong>(patch)。经过一个叫做<strong>编码器</strong><span>(encoder)<span class="heti-spacing"> </span></span>的模型后，每个块的所有像素就会被转换为一个值。随后这些值排成一行，被丢到另一个叫做<strong>解码器</strong><span>(decoder)<span class="heti-spacing"> </span></span>的模型中，它的任务是根据这些值尽可能还原图像。</p>
<div style="text-align: center">
<img src="images/lec9/12.png" width="70%/"/>
</div>
<blockquote>
<p><a href="https://arxiv.org/abs/2111.06377">相关资料</a></p>
</blockquote>
<p><span>AI<span class="heti-spacing"> </span></span>理解视频的方法是类似的，只是现在要理解多张图像。相应地，编码器会输出多组向量值（一个向量对应一帧的编码<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。之后还要再用一个编码器，从时间维度上对视频进行编码，简单来说即相邻的向量会被合并成一个向量。经过第二个编码器得到的一组向量最后会被放在一排，丢给解码器做后续处理。</p>
<div style="text-align: center">
<img src="images/lec9/13.png" width="70%/"/>
</div>
<blockquote>
<p><a href="https://arxiv.org/abs/2103.15691">相关资料</a></p>
</blockquote>
<ul>
<li>
<p><span>Sora<span class="heti-spacing"> </span></span>也用到了类似的技术</p>
<p></p><div style="text-align: center">
<img src="images/lec9/14.png" width="70%/"/>
</div>
</li>
</ul>
<h2 id="images">Images<a class="headerlink" href="#images" title="Permanent link">⚓︎</a></h2>
<h3 id="text-to-image">Text-to-Image<a class="headerlink" href="#text-to-image" title="Permanent link">⚓︎</a></h3>
<p>对于文生图模型，训练用的标注数据应当是成对的文本描述和对应的图像。</p>
<div style="text-align: center">
<img src="images/lec9/15.png" width="70%/"/>
</div>
<p>有一个知名的训练数据集叫做<a href="https://laion.ai/blog/laion-5b/"><span><span class="heti-spacing"> </span>LAION</span></a>，里面收集了<span class="heti-skip"><span class="heti-spacing"> </span>5.85B<span class="heti-spacing"> </span></span>左右的图像。</p>
<div style="text-align: center">
<img src="images/lec9/16.png" width="60%/"/>
</div>
<p>现在来看文生图模型的具体训练过程。与文本模型的“文字接龙”训练类似，这里的训练方式是块<span class="heti-skip"><span class="heti-spacing"> </span>(patch)<span class="heti-spacing"> </span></span>接龙。开始训练时，对于原始文本输入，模型要输出一个块，之后训练的时候将这个块加入到输入文本中。接下来模型根据文本和第一个块，输出第二个块，之后将第二个块加到输入中用于后续生成，以此类推。</p>
<div style="text-align: center">
<img src="images/lec9/17.png" width="70%/"/>
</div>
<p>当然，这样一个个生成块的方式太慢了，所以也存在一种能够并行生成所有块的方式，如图所示：</p>
<div style="text-align: center">
<img src="images/lec9/18.png" width="70%/"/>
</div>
<p>既然要用到相同的<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>架构，那么干脆让一个<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>同时考虑所有位置上的块。虽然还是独立生成每个位置上的块，但<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>的注意机制会在生成每个位置的块的时候考虑到其他位置，这样得到的图像质量可能更高。</p>
<div style="text-align: center">
<img src="images/lec9/19.png" width="70%/"/>
</div>
<h3 id="evaluation">Evaluation<a class="headerlink" href="#evaluation" title="Permanent link">⚓︎</a></h3>
<p>下面考虑如何评估生成图像质量的好坏。这里介绍的方法不是由人类完成的，而是让另一个模型负责评估。其中比较著名的一个模型叫做<a href="https://arxiv.org/abs/2103.00020"><span><span class="heti-spacing"> </span>CLIP</span></a>，它将一段文本描述和一幅图像作为输入，输出一个表明两者相关程度的分数，分越高表明生成图像质量越高。</p>
<div style="text-align: center">
<img src="images/lec9/20.png" width="70%/"/>
</div>
<div style="text-align: center">
<img src="images/lec9/21.png" width="60%/"/>
</div>
<h3 id="customization">Customization<a class="headerlink" href="#customization" title="Permanent link">⚓︎</a></h3>
<p>我们还可以对文生图做一些操作，以实现个性化的图像生成。具体方法为：先让模型阅读一张图像，记作<span><span class="heti-spacing"> </span><span class="arithmatex">\(S_*\)</span></span>（之后模型就要基于这张图像生成其他图像<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。为了让模型更深入理解<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(S_*\)</span><span class="heti-spacing"> </span></span>对应的图像，我们还可以在原图像的基础上加一些噪音，得到一些与原图像类似的图像。对模型而言，这些图像需均被视为<span><span class="heti-spacing"> </span><span class="arithmatex">\(S_*\)</span></span>。</p>
<div style="text-align: center">
<img src="images/lec9/22.png" width="60%/"/>
</div>
<p>接下来，模型根据<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(S_*\)</span><span class="heti-spacing"> </span></span>和用户的文本输入，输出基于<span><span class="heti-spacing"> </span><span class="arithmatex">\(S_*\)</span></span>，又符合文本描述的图像。</p>
<div style="text-align: center">
<img src="images/lec9/23.png" width="60%/"/>
</div>
<blockquote>
<p><a href="https://arxiv.org/abs/2208.01618">相关研究</a></p>
</blockquote>
<h2 id="videos">Videos<a class="headerlink" href="#videos" title="Permanent link">⚓︎</a></h2>
<h3 id="challenge">Challenge<a class="headerlink" href="#challenge" title="Permanent link">⚓︎</a></h3>
<p>也许读者想将训练文生图模型的思路应用在文本生视频的模型的训练中，但这是不切实际的。试想一下：假如一个视频为<span><span class="heti-spacing"> </span>24 FPS</span>，且每一帧有<span class="heti-skip"><span class="heti-spacing"> </span>64x64<span class="heti-spacing"> </span></span>的块。那么一分钟的视频就有<span class="heti-skip"><span class="heti-spacing"> </span>1440<span class="heti-spacing"> </span></span>个帧（约六百万的块）如果这些块都丢给<span class="heti-skip"><span class="heti-spacing"> </span>Transformer<span class="heti-spacing"> </span></span>且每两个块都要计算注意分数，那么就要做<span class="heti-skip"><span class="heti-spacing"> </span>36<span class="heti-spacing"> </span></span>兆次注意计算——这么庞大的计算量显然是我们无法承受的。</p>
<div style="text-align: center">
<img src="images/lec9/24.png" width="70%/"/>
</div>
<p>所以近些年来的一些研究致力于减少计算量，下面展示了相关方法：</p>
<ul>
<li>
<p><strong>时空注意</strong>(spatial-temporal attention)（3D<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：对于某一帧的块，仅考虑与该帧相邻的一些帧</p>
<p></p><div style="text-align: center">
<img src="images/lec9/25.png" width="60%/"/>
</div>
<ul>
<li>但现在很少有人采用这种方法，因为计算量太大</li>
</ul>
</li>
<li>
<p><strong>空间注意</strong>(spatial attention)（2D<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：仅考虑块所在帧的所有快</p>
<p></p><div style="text-align: center">
<img src="images/lec9/26.png" width="60%/"/>
</div>
</li>
<li>
<p><strong>时间注意</strong>(temporal attention)（1D<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：仅考虑与该块在其他帧上的相同位置上的块</p>
<p></p><div style="text-align: center">
<img src="images/lec9/27.png" width="60%/"/>
</div>
</li>
</ul>
<p>但是后两者方法都具有一定的局限性（仅考虑时间或空间<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，不过我们可以将两者结合起来使用，构成一种伪<span class="heti-skip"><span class="heti-spacing"> </span>3D<span class="heti-spacing"> </span></span>的注意计算。</p>
<div style="text-align: center">
<img src="images/lec9/28.png" width="70%/"/>
</div>
<details class="example">
<summary>例子</summary>
<p></p><div style="text-align: center">
<img src="images/lec9/29.png" width="70%/"/>
</div>
</details>
<hr/>
<p>另一种减小计算量的思路是生成视频不必一步到位——将生成的过程拆分成多个阶段完成。</p>
<div style="text-align: center">
<img src="images/lec9/30.png" width="60%/"/>
</div>
<p>前一版和后一版的差别可以是：</p>
<ul>
<li>
<p>后一版的图像分辨率更高</p>
<p></p><div style="text-align: center">
<img src="images/lec9/31.png" width="40%/"/>
</div>
</li>
<li>
<p>后一版的帧数更高</p>
<p></p><div style="text-align: center">
<img src="images/lec9/32.png" width="40%/"/>
</div>
</li>
</ul>
<details class="example" open="open">
<summary>例子</summary>
<p><span>Google<span class="heti-spacing"> </span></span>的<a href="https://arxiv.org/abs/2210.02303"><span class="heti-skip"><span class="heti-spacing"> </span>Imagen<span class="heti-spacing"> </span></span></a>模型采用了这种思路。视频生成的过程如下所示：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/33.png" width="70%/"/>
</div>
</details>
<h2 id="approaches">Approaches<a class="headerlink" href="#approaches" title="Permanent link">⚓︎</a></h2>
<p>下面将介绍一些经典的图像<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>视频生成方法：</p>
<ul>
<li><strong>变分自编码器</strong>(variational auto-encoder, <strong>VAE</strong>)</li>
<li><strong>基于流的方法</strong>(flow-based method)</li>
<li><strong>扩散法</strong>(diffusion method)</li>
<li><strong>生成式对抗网络</strong>(generative adversarial network, <strong>GAN</strong>)</li>
</ul>
<h3 id="vae-and-flow-based">VAE and Flow-based<a class="headerlink" href="#vae-and-flow-based" title="Permanent link">⚓︎</a></h3>
<p>其实上一讲有提到过：对于相同的描述，模型可能有多种生成的可能。比如对于“一只奔跑的狗”的描述，模型既可以画一张在草原奔跑的哈士奇，也可以画一张在都市行走的柴犬。这种“既要又要”的局面可能会让模型绘制出四不像的东西，所以我们需要为图像生成的模型增加额外“脑补”的内容。具体做法为：</p>
<ul>
<li>
<p>训练：采用<a href="../ml/7.html#auto-encoder"><strong>自编码器</strong></a>的架构，其中解码器就是图像生成的模型，而编码器负责从图像中提取有用信息，作为图像生成模型“脑补”的内容。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/34.png" width="70%/"/>
</div>
</li>
<li>
<p>测试：脑补的内容随机生成，而不是来自编码器的输出</p>
<p></p><div style="text-align: center">
<img src="images/lec9/35.png" width="50%/"/>
</div>
</li>
</ul>
<p><span>VAE<span class="heti-spacing"> </span></span>和基于流的方法均以该思路作为基础：</p>
<ul>
<li>
<p>VAE</p>
<p></p><div style="text-align: center">
<img src="images/lec9/36.png" width="60%/"/>
</div>
</li>
<li>
<p>基于流的方法：解码器是一个可逆的函数，而编码器就是解码器的反函数</p>
<p></p><div style="text-align: center">
<img src="images/lec9/37.png" width="60%/"/>
</div>
</li>
</ul>
<p>虽然中间产物叫做<strong>噪音</strong>(noise)，但实际上它包含了关于图像的有用信息（只是人类无法直接看出来<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。</p>
<details class="example" open="open">
<summary>例子</summary>
<p>给编码器看一组人脸图像，它会提取关于面部表情相关的信息。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/38.png" width="70%/"/>
</div>
<p>利用前面训练的结果，我们可提取出通用的臭脸和笑脸向量。这样，对于一张模型从未见过的图像，我们可以先将其编码为向量，然后减去臭脸向量，再加上笑脸向量，最后用解码器还原为图像，这样图像上的人脸就会笑的更加灿烂。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/39.png" width="60%/"/>
</div>
<blockquote>
<p><a href="https://openai.com/blog/glow/">相关研究</a></p>
</blockquote>
</details>
<h4 id="flow-based-generative-model">Flow-based Generative Model<a class="headerlink" href="#flow-based-generative-model" title="Permanent link">⚓︎</a></h4>
<details class="bug">
<summary>在基于流的模型出现前，其他生成模型的问题</summary>
<ul>
<li>自回归模型：<ul>
<li>什么样的顺序是最佳的生成顺序<heti-adjacent class="heti-adjacent-half">？</heti-adjacent>（不同的顺序可能会影响生成质量）</li>
<li>生成速度太慢</li>
</ul>
</li>
<li>VAE：只能优化下界，不能直接优化函数本身</li>
<li>GAN：训练不稳定</li>
</ul>
<p>基于流的模型能够解决上述痛点。</p>
</details>
<p>基于流的模型的核心部分是一个叫做<strong>生成器</strong><span>(generator)<span class="heti-spacing"> </span></span>的网络，记作<span><span class="heti-spacing"> </span><span class="arithmatex">\(G\)</span></span>，它定义了一个概率分布<span><span class="heti-spacing"> </span><span class="arithmatex">\(p_G\)</span></span>。其输入是一个来自正态分布<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\pi(z)\)</span><span class="heti-spacing"> </span></span>的值<span><span class="heti-spacing"> </span><span class="arithmatex">\(z\)</span></span>，对应的输出记作<span><span class="heti-spacing"> </span><span class="arithmatex">\(x = G(z)\)</span></span>，而输出的分布就是<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(G)\)</span></span>。训练的目标就是让生成器的输出分布<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(p_G\)</span><span class="heti-spacing"> </span></span>和标准答案（也是一个分布）<span><span class="arithmatex">\(p_{data}\)</span><span class="heti-spacing"> </span></span>越接近越好。</p>
<div style="text-align: center">
<img src="images/lec9/48.png" width="70%/"/>
</div>
<p>从定量角度看，训练的优化目标就是找到合适的生成器参数<span><span class="heti-spacing"> </span><span class="arithmatex">\(G^* = \arg \max\limits_G \sum_{i=1}^m \log P_G (x^i)\)</span></span>，其中<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\{x^1, x^2, \dots, x^m\}\)</span><span class="heti-spacing"> </span></span>来自分布<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_{data}(x)\)</span></span>。所以基于流的方法能够直接优化目标函数本身。</p>
<p>要想进一步了解该模型的原理，首先得具备以下数学背景知识：</p>
<ul>
<li>
<p><strong>雅可比矩阵</strong>(Jacobian matrix)</p>
<ul>
<li>假设<span><span class="heti-spacing"> </span><span class="arithmatex">\(x = f(z), z = f^{-1}(x)\)</span></span>（即<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(f\)</span><span class="heti-spacing"> </span></span>是可逆的<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，<span class="arithmatex">\(\bm{z} = \begin{bmatrix}z_1 \\ z_2\end{bmatrix}, \bm{x} = \begin{bmatrix}x_1 \\ x_2\end{bmatrix}\)</span></li>
<li>
<p>那么雅可比矩阵 </p>
<div class="arithmatex">\[
J_f = \begin{bmatrix}\frac{\partial x_1}{\partial z_1} &amp; \frac{\partial x_1}{\partial z_2} \\ \frac{\partial x_2}{\partial z_1} &amp; \frac{\partial x_2}{\partial z_2}\end{bmatrix}, J_{f^{-1}} = \begin{bmatrix}\frac{\partial z_1}{\partial x_1} &amp; \frac{\partial z_1}{\partial x_2} \\ \frac{\partial z_2}{\partial x_1} &amp; \frac{\partial z_2}{\partial x_2}\end{bmatrix}
\]</div>
<ul>
<li>以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(J_f\)</span><span class="heti-spacing"> </span></span>为例，同一行的输入是一样的，同一列的输出是一样的</li>
</ul>
</li>
<li>
<p>不难发现<span><span class="heti-spacing"> </span><span class="arithmatex">\(J_f J_{f^{-1}} = I\)</span></span>（单位矩阵）</p>
</li>
</ul>
<details class="example">
<summary>例子</summary>
<p></p><div style="text-align: center">
<img src="images/lec9/49.png" width="30%/"/>
</div>
</details>
</li>
<li>
<p><strong>行列式</strong>(determinant)：仅考虑<span class="heti-skip"><span class="heti-spacing"> </span>2x2<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>的方阵</p>
<ul>
<li>
<p>2x2</p>
<p></p><div style="text-align: center">
<img src="images/lec9/50.png" width="20%/"/>
</div>
<p>从几何角度看，行列式的<strong>绝对值</strong>为一个平行四边形的面积</p>
<p></p><div style="text-align: center">
<img src="images/lec9/52.png" width="30%/"/>
</div>
</li>
<li>
<p>3x3</p>
<p></p><div style="text-align: center">
<img src="images/lec9/51.png" width="30%/"/>
</div>
<p>从几何角度看，行列式的<strong>绝对值</strong>为一个平行六面体的体积</p>
<p></p><div style="text-align: center">
<img src="images/lec9/53.png" width="40%/"/>
</div>
</li>
<li>
<p>因为<span><span class="heti-spacing"> </span><span class="arithmatex">\(\det(A) = \dfrac{1}{\det(A^{-1})}\)</span></span>，所以<span><span class="heti-spacing"> </span><span class="arithmatex">\(\det(J_f) = \dfrac{1}{\det(J_{f^{-1}})}\)</span></span></p>
</li>
</ul>
</li>
<li>
<p><strong>变量替换定理</strong>(change of variable theorem)</p>
<ul>
<li>这里想要探讨的是：对于输入分布<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\pi(z)\)</span><span class="heti-spacing"> </span></span>上的一点<span><span class="heti-spacing"> </span><span class="arithmatex">\(z'\)</span></span>，输出<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x' = f(z')\)</span><span class="heti-spacing"> </span></span>的分布<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(p(x')\)</span><span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\pi(z')\)</span><span class="heti-spacing"> </span></span>之间有什么样的关系</li>
<li>
<p>先从最简单的均匀分布为例。假如<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\pi(z)\)</span><span class="heti-spacing"> </span></span>是<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\([0, 1]\)</span><span class="heti-spacing"> </span></span>之间的均匀分布，而<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(p(x)\)</span><span class="heti-spacing"> </span></span>是<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\([1, 3]\)</span><span class="heti-spacing"> </span></span>之间的均匀分布。令<span><span class="heti-spacing"> </span><span class="arithmatex">\(x = f(z) = 2z + 1\)</span></span>，那么<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(x') = \dfrac{1}{2}\pi(z')\)</span></span> </p>
<p></p><div style="text-align: center">
<img src="images/lec9/54.png" width="60%/"/>
</div>
</li>
<li>
<p>扩展到一般情况，我们可以取两个分布中面积相等且变化不大的部分，将它们近似看作矩形。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/55.png" width="60%/"/>
</div>
<ul>
<li>由于面积相等，可以得到等式<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(x') \Delta x = \pi(x') \Delta z\)</span></span>。两边同时除以<span><span class="heti-spacing"> </span><span class="arithmatex">\(\Delta x\)</span></span>，转化为<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(x') = \pi(x') \dfrac{\Delta z}{\Delta x}\)</span></span></li>
<li>如果<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\Delta z, \Delta x\)</span><span class="heti-spacing"> </span></span>的值很小的话，可以用导数来代替，即<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(x') = \pi(x') \dfrac{d z}{d x}\)</span></span></li>
<li>由于导数可正可负，因此导数要取绝对值，即<span><span class="heti-spacing"> </span><span class="arithmatex">\(p(x') = \pi(x') \Big|\dfrac{d z}{d x}\Big|\)</span></span></li>
</ul>
</li>
<li>
<p>进一步扩展到二维的分布</p>
<p></p><div style="text-align: center">
<img src="images/lec9/56.png" width="60%/"/>
</div>
<ul>
<li>计算公式：<span class="arithmatex">\(p(x') \left|\det\begin{bmatrix}\Delta x_{11} &amp; \Delta x_{12} \\ \Delta x_{21} &amp; \Delta x_{22}\end{bmatrix}\right| = \pi(z') \Delta z_1 \Delta z_2\)</span></li>
<li>其中<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\Delta x_{ij}\)</span><span class="heti-spacing"> </span></span>表示<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z_j\)</span><span class="heti-spacing"> </span></span>变化的时候，<span><span class="arithmatex">\(x_i\)</span><span class="heti-spacing"> </span></span>的改变量</li>
<li>
<p>让我们将这个式子转化到能用雅可比矩阵表示出来的形式</p>
<div class="arithmatex">\[
\begin{align*}
p(x') \left|\det\begin{bmatrix}\Delta x_{11} &amp; \Delta x_{12} \\ \Delta x_{21} &amp; \Delta x_{22}\end{bmatrix}\right| &amp; = \pi(z') \Delta z_1 \Delta z_2 \\
p(x') \left| \dfrac{1}{\Delta z_1 \Delta z_2} \det\begin{bmatrix}\Delta x_{11} &amp; \Delta x_{12} \\ \Delta x_{21} &amp; \Delta x_{22}\end{bmatrix}\right| &amp; = \pi(z') \\
p(x') \left|\det\begin{bmatrix}\Delta x_{11} / \Delta z_1 &amp; \Delta x_{12} / \Delta z_1 \\ \Delta x_{21} / \Delta z_2 &amp; \Delta x_{22} / \Delta z_2\end{bmatrix}\right| &amp; = \pi(z') \\
p(x') \left|\det\begin{bmatrix}\partial x_1 / \partial z_1 &amp; \partial x_2 / \partial z_1 \\ \partial x_1 / \partial z_2 &amp; \partial x_2 / \partial z_2\end{bmatrix}\right| &amp; = \pi(z') \\
p(x') \left|\det\begin{bmatrix}\partial x_1 / \partial z_1 &amp; \partial x_1 / \partial z_2 \\ \partial x_2 / \partial z_1 &amp; \partial x_2 / \partial z_2\end{bmatrix}\right| &amp; = \pi(z') \\
p(x') |\det(J_f)| &amp; = \pi(z') \\
p(x') &amp; = \pi(z') |\det(J_{f^{-1}})|
\end{align*}
\]</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr/>
<p>有了上面的数学基础后，我们可以进一步理解下面形式化的解释。回顾一下，训练目标是找到<span><span class="heti-spacing"> </span><span class="arithmatex">\(G^* = \arg \max\limits_G \sum_{i=1}^m \log P_G (x^i)\)</span></span>。根据变量替换定理，<span class="arithmatex">\(p_G(x^i) = \pi(z^i) |\det(J_{G^{-1}})|\)</span>，其中<span><span class="heti-spacing"> </span><span class="arithmatex">\(z_i = G^{-1}(x^i)\)</span></span>。所以<span><span class="heti-spacing"> </span><span class="arithmatex">\(\log P_G (x^i) = \log \pi (G^{-1}(x^i)) + \log |\det(J_{G^{-1}})|\)</span></span>。要想确定这样的式子，就要满足：</p>
<ul>
<li><span><span class="arithmatex">\(\det(J_G)\)</span><span class="heti-spacing"> </span></span>能被计算出来</li>
<li>知道<span><span class="heti-spacing"> </span><span class="arithmatex">\(G^{-1}\)</span></span>，所以输入和输出的维度应当是一样</li>
</ul>
<p>所以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(G\)</span><span class="heti-spacing"> </span></span>是有限制的，不能是任意的网络，那么这也意味着<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(G\)</span><span class="heti-spacing"> </span></span>的能力也可能是有限的。所以为了提高生成质量，可以将多个生成器连在一起，前一个生成器的输出作为另一个生成器的输入，将最后一个输出作为最终输出。这也正是<span class="heti-skip"><span class="heti-spacing"> </span>"flow-based"<span class="heti-spacing"> </span></span>的由来。</p>
<div style="text-align: center">
<img src="images/lec9/57.png" width="60%/"/>
</div>
<p>假如有<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(K\)</span><span class="heti-spacing"> </span></span>个生成器，输出分布为：<span class="arithmatex">\(p_K(x^i) = \pi(z^i) (|\det(J_{G_1^{-1}})|) \dots (|\det(J_{G_K^{-1}})|)\)</span>。两边取对数，可得<span><span class="heti-spacing"> </span><span class="arithmatex">\(\log p_K(x^i) = \log \pi(z^i) + \sum\limits_{h=1}^K \log (|\det(J_{G_h^{-1}})|)\)</span></span>。</p>
<p>回过头来看，<span><span class="arithmatex">\(\log P_G (x^i) = \log \pi (G^{-1}(x^i)) + \log |\det(J_{G^{-1}})|\)</span><span class="heti-spacing"> </span></span>这个式子中出现的是<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(G^{-1}\)</span><span class="heti-spacing"> </span></span>而非<span><span class="heti-spacing"> </span><span class="arithmatex">\(G\)</span></span>，所以实际上我们要训练的是<span><span class="heti-spacing"> </span><span class="arithmatex">\(G^{-1}\)</span></span>，但生成的任务还是要拿<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(G\)</span><span class="heti-spacing"> </span></span>来做。</p>
<div style="text-align: center">
<img src="images/lec9/58.png" width="60%/"/>
</div>
<ul>
<li><span class="arithmatex">\(\log \pi (G^{-1}(x^i))\)</span><ul>
<li>令<span><span class="heti-spacing"> </span><span class="arithmatex">\(z^i = G^{-1}(x^i)\)</span></span></li>
<li>要让这一项最大化，就要让<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z^i\)</span><span class="heti-spacing"> </span></span>尽可能接近零向量（因为（标准）正态分布中零向量的概率最大）</li>
</ul>
</li>
<li><span class="arithmatex">\(\log |\det(J_{G^{-1}})|\)</span>：<ul>
<li>但如果<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z^i\)</span><span class="heti-spacing"> </span></span>接近零向量，<span><span class="arithmatex">\(J_{G^{-1}}\)</span><span class="heti-spacing"> </span></span>就会接近零矩阵，那么这一项就会越接近负无穷</li>
<li>所以实际训练时不会让所有的<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z\)</span><span class="heti-spacing"> </span></span>都接近零向量</li>
</ul>
</li>
</ul>
<hr/>
<p>实际上，生成器对应的网络叫做<strong>耦合层</strong>(coupling layer)，在比较知名的基于流的模型<a href="https://arxiv.org/abs/1410.8516"><span class="heti-skip"><span class="heti-spacing"> </span>NICE<span class="heti-spacing"> </span></span></a>和<a href="https://arxiv.org/abs/1605.08803"><span class="heti-skip"><span class="heti-spacing"> </span>Real NVP<span class="heti-spacing"> </span></span></a>中均有应用。对于<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{z} = [z_1 \dots z_D]^T\)</span></span>，</p>
<div style="text-align: center">
<img src="images/lec9/59.png" width="60%/"/>
</div>
<ul>
<li>若<span><span class="heti-spacing"> </span><span class="arithmatex">\(i \le d\)</span></span>，<span class="arithmatex">\(x_i = z_i\)</span></li>
<li>否则<span><span class="heti-spacing"> </span><span class="arithmatex">\(x_{i &gt; d} = \beta_i z_i + \gamma_i\)</span></span><ul>
<li>其中<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\beta_i, \gamma_i\)</span><span class="heti-spacing"> </span></span>来自函数<span><span class="heti-spacing"> </span><span class="arithmatex">\(F, H\)</span></span>。它们以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z_1, \dots, z_d\)</span><span class="heti-spacing"> </span></span>为输入，分别输出<span><span class="heti-spacing"> </span><span class="arithmatex">\(\beta_{d+1}, \dots, \beta_D;\ \gamma_{d+1}, \dots, \gamma_D\)</span></span>。<span><span class="arithmatex">\(F, H\)</span><span class="heti-spacing"> </span></span>要多复杂都可以，并且不需要是可逆函数</li>
<li>之所以不必可逆，是因为我们可以从<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\([x_1, \dots, x_D]^T\)</span><span class="heti-spacing"> </span></span>反推<span><span class="heti-spacing"> </span><span class="arithmatex">\([z_1, \dots, z_D]^T\)</span></span><ul>
<li><span class="arithmatex">\(z_{i \le d} = x_i\)</span></li>
<li><span class="arithmatex">\(z_{i &gt; d} = \dfrac{x_i - \gamma_i}{\beta_i}\)</span></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>下面考虑耦合层下的雅可比矩阵：</p>
<div style="text-align: center">
<img src="images/lec9/60.png" width="40%/"/>
</div>
<ul>
<li>左上：因为<span><span class="heti-spacing"> </span><span class="arithmatex">\(x_i = d_i\)</span></span>，所以这里的矩阵是一个单位矩阵</li>
<li>右上：<span><span class="arithmatex">\(i &gt; d\)</span><span class="heti-spacing"> </span></span>时<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(z\)</span><span class="heti-spacing"> </span></span>的计算和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(i \le d\)</span><span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>毫无关系，所以是一个零矩阵</li>
<li>左下：计算行列式时，由于右上是一个零矩阵，因此这里无论是什么都不会被算进去，所以无需考虑</li>
<li>右下：对角矩阵，因为<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(d_i\)</span><span class="heti-spacing"> </span></span>仅和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_i\)</span><span class="heti-spacing"> </span></span>有关</li>
</ul>
<p>综上，<span class="arithmatex">\(\det(J_G) = \dfrac{\partial x_{d+1}}{\partial z_{d+1}} \dfrac{\partial x_{d+2}}{\partial z_{d+2}} \dfrac{\partial x_D}{\partial z_D} = \beta_{d+1} \beta_{d+2} \dots \beta_D\)</span>。</p>
<p>由于基于流的模型会用到不止一个生成器，所以如果不做任何改变的话，那么输入向量的前半部分就会被一直复制，直接作为最终输出向量的前半部分（上图<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，这显然是不合理的。所以还要采用一种叫做<strong>堆叠</strong><span>(stacking)<span class="heti-spacing"> </span></span>的技术，将当前层中不是直接复制过来的元素直接复制到下一个耦合层的输出（下图<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，这样就可以避免某部分元素从未改变的情况。</p>
<div style="text-align: center">
<img src="images/lec9/61.png" width="60%/"/>
</div>
<p>更具体地，如果要做图像生成的话，我们可以这样做：先直接复制索引和为奇数的元素作为耦合层的输出，并计算索引和为偶数的元素。到了下一层就反过来做，以此类推。</p>
<div style="text-align: center">
<img src="images/lec9/62.png" width="60%/"/>
</div>
<hr/>
<p>第二种可作为生成器的网络是 <strong><span>1x1<span class="heti-spacing"> </span></span>卷积</strong>(1x1 convolution)。具体做法是：让图像中的每个像素（包含<span class="heti-skip"><span class="heti-spacing"> </span>3<span class="heti-spacing"> </span></span>个通道，即三维向量）<span><span class="arithmatex">\(\bm{z}\)</span><span class="heti-spacing"> </span></span>乘上一个<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>的矩阵<span><span class="heti-spacing"> </span><span class="arithmatex">\(W\)</span></span>，得到向量<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{x}\)</span></span>。</p>
<div style="text-align: center">
<img src="images/lec9/63.png" width="50%/"/>
</div>
<ul>
<li><span><span class="arithmatex">\(W\)</span><span class="heti-spacing"> </span></span>是通过机器学习学出来的</li>
<li><span><span class="arithmatex">\(W\)</span><span class="heti-spacing"> </span></span>能够打乱像素点的通道值</li>
<li>如果<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(W\)</span><span class="heti-spacing"> </span></span>是可逆的（<heti-adjacent class="heti-adjacent-half">？</heti-adjacent><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，那么计算<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(W^{-1}\)</span><span class="heti-spacing"> </span></span>比较容易</li>
</ul>
<p>令<span><span class="heti-spacing"> </span><span class="arithmatex">\(\bm{x} = f(\bm{z}) = W\bm{z}\)</span></span>。实际上，<span><span class="arithmatex">\(W\)</span><span class="heti-spacing"> </span></span>就是雅可比矩阵<span><span class="heti-spacing"> </span><span class="arithmatex">\(J_f\)</span></span>，即：</p>
<div class="arithmatex">\[
J_f = \begin{bmatrix}\partial x_1 / \partial z_1 &amp; \partial x_1 / \partial z_2 &amp; \partial x_1 / \partial z_3 \\ \partial x_2 / \partial z_1 &amp; \partial x_2 / \partial z_2 &amp; \partial x_2 / \partial z_3 \\ \partial x_3 / \partial z_1 &amp; \partial x_3 / \partial z_2 &amp; \partial x_3 / \partial z_3\end{bmatrix} = \begin{bmatrix}w_{11} &amp; w_{12} &amp; w_{13} \\ w_{21} &amp; w_{22} &amp; w_{23} \\ w_{31} &amp; w_{32} &amp; w_{33}\end{bmatrix} = W
\]</div>
<p>假如图像大小为<span><span class="heti-spacing"> </span>dxd</span>，考虑所有像素的权重矩阵<span><span class="heti-spacing"> </span><span class="arithmatex">\(W\)</span></span>，可得到：</p>
<div style="text-align: center">
<img src="images/lec9/64.png" width="50%/"/>
</div>
<p>这个大矩阵的行列式值为<span><span class="heti-spacing"> </span><span class="arithmatex">\((\det(W))^{d \times d}\)</span></span>。由于<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(W\)</span><span class="heti-spacing"> </span></span>是<span class="heti-skip"><span class="heti-spacing"> </span>3x3<span class="heti-spacing"> </span></span>的矩阵，因此<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\det(W)\)</span><span class="heti-spacing"> </span></span>的值很容易算出来。</p>
<details class="example" open="open">
<summary>应用</summary>
<p>以下两个例子均来自<span class="heti-skip"><span class="heti-spacing"> </span>OpenAI<span class="heti-spacing"> </span></span>的<a href="https://openai.com/blog/glow/"><span class="heti-skip"><span class="heti-spacing"> </span>GLOW<span class="heti-spacing"> </span></span></a>模型，它就用到了<span class="heti-skip"><span class="heti-spacing"> </span>1x1<span class="heti-spacing"> </span></span>卷积的思路。</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="" id="__tabbed_3_1" name="__tabbed_3" type="radio"/><input id="__tabbed_3_2" name="__tabbed_3" type="radio"/><div class="tabbed-labels"><label for="__tabbed_3_1">例<span class="heti-skip"><span class="heti-spacing"> </span>1<span class="heti-spacing"> </span></span></label><label for="__tabbed_3_2">例<span><span class="heti-spacing"> </span>2</span></label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/65.png" width="60%/"/>
</div>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/66.png" width="70%/"/>
</div>
</div>
</div>
</div>
<hr/>
<p>除此之外，<span>GLOW<span class="heti-spacing"> </span></span>还可用于语音领域：</p>
<ul>
<li>
<p><a href="https://arxiv.org/abs/1711.10433">Parallel WaveNet</a></p>
<p></p><div style="text-align: center">
<img src="images/lec9/67.png" width="50%/"/>
</div>
</li>
<li>
<p><a href="https://arxiv.org/abs/1811.00002">WaveGlow</a></p>
<p></p><div style="text-align: center">
<img src="images/lec9/68.png" width="40%/"/>
</div>
</li>
</ul>
</details>
<h3 id="diffusion">Diffusion<a class="headerlink" href="#diffusion" title="Permanent link">⚓︎</a></h3>
<p>扩散模型的运作机制是：</p>
<ul>
<li>先获得一张和生成图像规模一样的随机噪声，然后通过一个去噪模型反复<strong>去噪</strong>(denoise)</li>
<li>去噪次数是预先确定的</li>
<li>去噪的步骤数是倒序排序的，也就是说最开始的步骤数最大的，往后递减，所以这个过程又叫<strong>逆过程</strong>(revervse process)</li>
</ul>
<div style="text-align: center">
<img src="images/lec9/69.png" width="70%/"/>
</div>
<ul>
<li>这个过程和雕刻一座雕像类似——雕像也是从一个大理石块开始（对应扩散模型的噪音<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，由雕塑家不断打磨，最终打造出一个石雕（对应扩散模型的生成图像）</li>
</ul>
<p>在多轮去噪中，用的去噪模型都是同一个，但刚开始和快结束的两张图像的噪声量完全是不一样的，因此去噪模型除了将之前去噪过的图像作为输入外，还要考虑步骤数，因为步骤数和图像中的噪声量成正相关。</p>
<div style="text-align: center">
<img src="images/lec9/70.png" width="70%/"/>
</div>
<details class="info">
<summary>注</summary>
<p>实际上，扩散模型也可以被看成是一种自回归，两者都是“<span>N<span class="heti-spacing"> </span></span>步到位”的体现。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/109.png" width="70%/"/>
</div>
</details>
<p>接下来看去噪模型的内部结构。如下图所示，去噪模型不是一个端到端的模型，而是要先经过一个叫做<strong>噪声预测器</strong><span>(noise predictor)<span class="heti-spacing"> </span></span>的模型。它接收去噪模型的所有输入，输出它认为图像中包含的噪声。之后去噪模型将原图像减去这个预测出来的噪声，得到去噪后的图像。</p>
<div style="text-align: center">
<img src="images/lec9/71.png" width="50%/"/>
</div>
<p>既然是模型，那么噪声预测器也要进行训练。训练时每个输入数据都要有一个匹配的基准事实<span><span class="heti-spacing"> </span>(ground truth)</span>，在这里就是真正的噪声。</p>
<div style="text-align: center">
<img src="images/lec9/72.png" width="50%/"/>
</div>
<p>我们需要自己动手构造训练数据，而这个过程叫做<strong>扩散过程</strong>(diffusion process)。具体来说就是在一张清晰的图像上不断加上随机采样得来的噪声，每一步加上的噪声都要标上步骤数。注意这里的步骤数是递增的，因此该过程又叫做<strong>前向过程</strong>(forward process)。</p>
<div style="text-align: center">
<img src="images/lec9/73.png" width="70%/"/>
</div>
<p>对于噪声预测器而言，在扩散过程中，加上噪声的图像和当前步骤数是输入，而对应的噪声就是基准事实。</p>
<div style="text-align: center">
<img src="images/lec9/74.png" width="70%/"/>
</div>
<hr/>
<p>扩散模型的一大应用是文生图<span><span class="heti-spacing"> </span>(text-to-image)</span>。其中一个知名的训练数据集就是<a href="https://laion.ai/blog/laion-5b/"><span><span class="heti-spacing"> </span>LAION</span></a>，里面包含<span class="heti-skip"><span class="heti-spacing"> </span>5.85B<span class="heti-spacing"> </span></span>左右的训练数据（图像<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。在文生图模型中，去噪模型还要考虑输入文本，以产生符合文本描述的图像。另外训练时也要考虑输入文本。</p>
<div style="text-align: center">
<img src="images/lec9/76.png" width="70%/"/>
</div>
<h4 id="stable-diffusion">Stable Diffusion<a class="headerlink" href="#stable-diffusion" title="Permanent link">⚓︎</a></h4>
<p>扩散模型中的一种有名的实现是<strong>稳定扩散</strong>(stable diffusion)。其他知名的图像生成模型的原理也和它类似，所以接下来就来认识一下它的工作原理。下面是它的框架图，可以看到它包含了三个部件：</p>
<div style="text-align: center">
<img src="images/lec9/77.png" width="60%/"/>
</div>
<ol>
<li>文本编码器：将文本编码为向量</li>
<li>生成模型：将包含文本信息的向量和噪音图像作为输入，输出图像的压缩版本（一种中间产物，不一定能够为人类直接理解）</li>
<li>解码器：将图像的压缩版本还原为图像</li>
</ol>
<details class="example" open="open">
<summary>应用</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="4:3"><input checked="" id="__tabbed_4_1" name="__tabbed_4" type="radio"/><input id="__tabbed_4_2" name="__tabbed_4" type="radio"/><input id="__tabbed_4_3" name="__tabbed_4" type="radio"/><div class="tabbed-labels"><label for="__tabbed_4_1">例<span><span class="heti-spacing"> </span>1</span>：<span>Stable Diffusion<span class="heti-spacing"> </span></span></label><label for="__tabbed_4_2">例<span><span class="heti-spacing"> </span>2</span>：<span>DALL-E<span class="heti-spacing"> </span></span>系列</label><label for="__tabbed_4_3">例<span><span class="heti-spacing"> </span>3</span>：Imagen</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/78.png" width="70%/"/>
</div>
<ul>
<li>编码器实际上不止接收文本输入，还有其他各种形式的数据</li>
</ul>
<blockquote>
<p><a href="https://arxiv.org/abs/2112.10752">论文链接</a></p>
</blockquote>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/79.png" width="70%/"/>
</div>
<ul>
<li>生成模型除了扩散模型外，也可以用自编码器。尽管自编码器生成慢，但我们只需要它生成压缩版本，因此耗时不多，可以使用</li>
</ul>
<blockquote>
<p>论文链接：<a href="https://arxiv.org/abs/2204.06125">链接<span><span class="heti-spacing"> </span>1</span></a>、<a href="https://arxiv.org/abs/2102.12092">链接<span><span class="heti-spacing"> </span>2</span></a></p>
</blockquote>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/80.png" width="50%/"/>
</div>
<ul>
<li>它的“中间产物”是分辨率较小的图像，随后在解码器的帮助下不断增大分辨率</li>
</ul>
<blockquote>
<p>链接：<a href="https://imagen.research.google/">官网</a>、<a href="https://arxiv.org/abs/2205.11487">论文</a></p>
</blockquote>
</div>
</div>
</div>
</details>
<p>接下来详细介绍各部件的具体实现：</p>
<ul>
<li>
<p>文本编码器</p>
<ul>
<li>可以用机器学习课程中介绍过的<a href="../ml/7.html#bert"><span class="heti-skip"><span class="heti-spacing"> </span>BERT<span class="heti-spacing"> </span></span></a>等语言模型来实现</li>
<li>
<p>一般来说，编码器的参数量越大，生成图像的质量越高（图表中越靠右下角表现越好；<a href="https://arxiv.org/abs/2205.11487">图表来源</a>）</p>
<p></p><div style="text-align: center">
<img src="images/lec9/81.png" width="40%/"/>
</div>
<ul>
<li>纵轴是<a href="../ml/6.html#evaluation-of-generation">弗雷歇起始距离（<strong>FID</strong>）</a>，值越小表明生成结果和基准事实越接近<ul>
<li><span>FID-10K<span class="heti-spacing"> </span></span>中的<span class="heti-skip"><span class="heti-spacing"> </span>10K<span class="heti-spacing"> </span></span>指的是训练数据量</li>
</ul>
</li>
<li>
<p>横轴是<a href="https://arxiv.org/abs/2103.00020">对比语言<span class="heti-skip"><span class="heti-spacing"> </span>-<span class="heti-spacing"> </span></span>图像预训练<span><span class="heti-spacing"> </span>(contrastive language-image pre-training,</span> <strong>CLIP</strong>)</a></p>
<ul>
<li>用到<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>亿对图像<span class="heti-skip"><span class="heti-spacing"> </span>-<span class="heti-spacing"> </span></span>文本数据</li>
<li>将文本和图像分别丢给文本编码器和图像编码器，两者输出的向量越接近，<span>CLIP<span class="heti-spacing"> </span></span>分数就越大</li>
</ul>
<p></p><div style="text-align: center">
<img src="images/lec9/82.png" width="60%/"/>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>解码器</p>
<ul>
<li>训练时无需标注数据</li>
<li>
<p>它能接受的中间产物</p>
<ul>
<li>
<p>分辨率较小的图</p>
<p></p><div style="text-align: center">
<img src="images/lec9/83.png" width="40%/"/>
</div>
</li>
<li>
<p>潜表示<span><span class="heti-spacing"> </span>(latent representation)</span></p>
<p></p><div style="text-align: center">
<img src="images/lec9/84.png" width="70%/"/>
</div>
<ul>
<li>
<p>为了让解码器理解潜表示，我们可以将解码器放在自编码器架构下进行训练</p>
<p></p><div style="text-align: center">
<img src="images/lec9/85.png" width="70%/"/>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>生成模型</p>
<ul>
<li>
<p>不同于前面介绍的一般的扩散模型，在扩散阶段开始前，需要先将图像和文本丢给一个编码器，然后向编码后的结果不断添加噪音</p>
<p></p><div style="text-align: center">
<img src="images/lec9/86.png" width="70%/"/>
</div>
<p></p><div style="text-align: center">
<img src="images/lec9/87.png" width="70%/"/>
</div>
</li>
</ul>
</li>
</ul>
<h4 id="denoising-diffusion-probabilistic-model">Denoising Diffusion Probabilistic Model<a class="headerlink" href="#denoising-diffusion-probabilistic-model" title="Permanent link">⚓︎</a></h4>
<p>本节着重介绍隐藏在扩散模型背后的数学原理。以下是扩散模型的算法（训练<span class="heti-skip"><span class="heti-spacing"> </span>+<span class="heti-spacing"> </span></span>生成（采样<heti-adjacent class="heti-adjacent-half">）</heti-adjacent><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<div style="text-align: center">
<img src="images/lec9/88.png" width="80%/"/>
</div>
<p>这些算法看似短短几行，实则暗藏玄机。下面就来仔细剖析其中的思想：</p>
<ul>
<li>
<p>训练</p>
<ul>
<li><span><span class="arithmatex">\(x_0\)</span><span class="heti-spacing"> </span></span>为清晰图像，<span><span class="arithmatex">\(\varepsilon\)</span><span class="heti-spacing"> </span></span>为噪音</li>
<li>第<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>行：从某个分布中采样一张清晰图像</li>
<li>第<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>行：从正态分布中随机采样一个噪音</li>
<li>第<span class="heti-skip"><span class="heti-spacing"> </span>5<span class="heti-spacing"> </span></span>行：<ul>
<li><span><span class="arithmatex">\(\sqrt{\bar{\alpha}_t} x_0 + (1 - \sqrt{\bar{\alpha}_t}) \varepsilon\)</span><span class="heti-spacing"> </span></span>表示加了噪音后的图像</li>
<li><span><span class="arithmatex">\(\varepsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + (1 - \sqrt{\bar{\alpha}_t}) \varepsilon, t)\)</span><span class="heti-spacing"> </span></span>表示噪音预测器的输出结果</li>
<li><span><span class="arithmatex">\(\bar{\alpha}_1, \bar{\alpha}_2, \dots, \bar{\alpha}_T\)</span><span class="heti-spacing"> </span></span>的值逐渐递减</li>
</ul>
</li>
<li>
<p>算法还是太抽象了，下面用图示的方式展现算法：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/89.png" width="70%/"/>
</div>
</li>
<li>
<p>前面我们说扩散过程是一个不断向清晰图像添加噪音的过程，但实际上这个算法告诉我们只需要加一次噪音就够了</p>
<p></p><div style="text-align: center">
<img src="images/lec9/90.png" width="70%/"/>
</div>
</li>
</ul>
</li>
<li>
<p>采样</p>
<ul>
<li><span><span class="arithmatex">\(x_T\)</span><span class="heti-spacing"> </span></span>也是随机采样出来的噪音</li>
<li><span><span class="arithmatex">\(z\)</span><span class="heti-spacing"> </span></span>是另外采样出来的噪音</li>
<li>
<p>算法的形象化表示如下：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/91.png" width="80%/"/>
</div>
</li>
</ul>
</li>
</ul>
<p>以上只是对算法的简单注释。在深入理解算法的正确性与合理性之前，我们先要清楚图像生成模型的共同目标是什么——不管图像生成模型采取何种技术，本质上它们做的事还是输入一个分布<span><span class="heti-spacing"> </span><span class="arithmatex">\(z\)</span></span>，输出一个关于生成图像的分布<span><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span></span>；优化目标就是让<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>和真实图像的分布越接近越好。</p>
<div style="text-align: center">
<img src="images/lec9/92.png" width="70%/"/>
</div>
<p>那么该如何衡量两个分布的接近程度呢？一种常用的方法是<strong>最大可能性估计</strong>(maximum likelihood estimation)，它的思路是：从真实数据分布<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(P_{data}(x)\)</span><span class="heti-spacing"> </span></span>中采样出所有数据<span><span class="heti-spacing"> </span><span class="arithmatex">\(\{x^1, x^2, \dots, x^m\}\)</span></span>，计算这些数据在模型输出分布中出现的概率（即<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta (x^i)\)</span></span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。模型的优化目标就转化为找参数<span><span class="heti-spacing"> </span><span class="arithmatex">\(\theta^* = \arg \max\limits_\theta \prod\limits_{i=1}^m P_\theta(x^i)\)</span></span>（即最大化可能性<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。接下来对这个式子进一步转换：</p>
<div class="arithmatex">\[
\begin{align*}
\theta^* &amp; = \arg \max\limits_\theta \prod\limits_{i=1}^m P_\theta(x^i) \\
&amp; \Rightarrow \arg \max\limits_\theta \log \prod\limits_{i=1}^m P_\theta(x^i) \\
&amp; = \arg \max\limits_\theta \sum\limits_{i=1}^m \log P_\theta(x^i) \\
&amp; \approx \arg \max\limits_\theta \mathbb{E}_{x \sim P_{data}} [\log P_\theta(x)] \\
&amp; = \arg \max\limits_\theta \int\limits_x P_{data}(x) \log P_\theta(x) - \underbrace{\int\limits_x P_{data}(x) \log P_{data}(x)}_{\textcolor{cornflowerblue}{\text{not related to } \theta}} \\
&amp; = \arg \max\limits_\theta \int\limits_x P_{data}(x) \log \dfrac{P_\theta(x)}{P_{data}(x)}dx = \underbrace{\arg \min\limits_\theta KL(P_{data} \| P_\theta)}_{\textcolor{cornflowerblue}{\text{difference between } P_{data} \text{ and } P_\theta}}
\end{align*}
\]</div>
<p>所以最大化可能性<span class="heti-skip"><span class="heti-spacing"> </span>-&gt;<span class="heti-spacing"> </span></span>最小化 <strong><span>KL<span class="heti-spacing"> </span></span>散度</strong>(KL divergence)。</p>
<hr/>
<p>对于<span class="heti-skip"><span class="heti-spacing"> </span>VAE<span class="heti-spacing"> </span></span>模型而言，模型生成的分布为<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta(x) = \int\limits_z P(z) P_\theta(x|z) dz\)</span></span>（<span><span class="arithmatex">\(z\)</span><span class="heti-spacing"> </span></span>是输入，<span><span class="arithmatex">\(x\)</span><span class="heti-spacing"> </span></span>是输出<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。如果<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta(x|z) = \begin{cases}1 &amp; G(z) = x \\ 0 &amp; G(z) \ne x\end{cases}\)</span></span>，那么可能性就几乎为<span><span class="heti-spacing"> </span>0</span>，显然不适合用于计算。因此我们会放宽<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta(x|z)\)</span><span class="heti-spacing"> </span></span>的限制——令<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta(x|z) \propto \exp(-\|G(z) - x\|_2)\)</span></span>，即一个以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(G(z)\)</span><span class="heti-spacing"> </span></span>为均值的正态分布的期望。</p>
<p>另外，<span>VAE<span class="heti-spacing"> </span></span>模型还要计算<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\log P(x)\)</span><span class="heti-spacing"> </span></span>的下界，计算过程如下：</p>
<div class="arithmatex">\[
\begin{align*}
\log P_\theta(x) &amp; = \int\limits_z q(z|x) \log P(x) dz \quad \textcolor{green}{q(z|x) \text{ can be any distribution}}\\
&amp; = \int\limits_z q(z|x) \log \left(\dfrac{P((z, x))}{P(z|x)}\right) dz = \int\limits_z q(z|x) \log \left(\dfrac{P((z, x))}{\textcolor{cornflowerblue}{q(z|x)}} \cdot \dfrac{\textcolor{cornflowerblue}{q(z|x)}}{P(z|x)}\right) dz \\
&amp; = \int\limits_z q(z|x) \log \left(\dfrac{P((z, x))}{q(z|x)}\right) dz + \underbrace{\int\limits_z q(z|x) \log \left(\dfrac{q((z|x))}{P(z|x)}\right) dz}_{\textcolor{red}{KL(q(z|x)\|P(z|x)) \ge 0}} \\
&amp; \ge \int\limits_z q(z|x) \log \left(\dfrac{P((z, x))}{q(z|x)}\right) dz = \mathbb{E}_{\underbrace{q(z|x)}_{\textcolor{red}{\text{encoder}}}} \left[\log\left(\dfrac{P(x, z)}{q(z|x)})\right)\right] \quad \textcolor{cornflowerblue}{\text{lower bound}}
\end{align*}
\]</div>
<hr/>
<p>我们将<span class="heti-skip"><span class="heti-spacing"> </span>VAE<span class="heti-spacing"> </span></span>的思路沿用到<span><span class="heti-spacing"> </span>DDPM</span>：</p>
<ul>
<li>
<p><span class="arithmatex">\(P_\theta(x)\)</span></p>
<ul>
<li>仍然将扩散模型的去噪过程看成多个步骤（从噪音<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_T\)</span><span class="heti-spacing"> </span></span>开始，一直到清晰图像<span><span class="heti-spacing"> </span><span class="arithmatex">\(x_0\)</span></span>）</li>
<li>对于中间图像<span><span class="heti-spacing"> </span><span class="arithmatex">\(x_t\)</span></span>，去噪后的结果是一个正态分布，即<span><span class="heti-spacing"> </span><span class="arithmatex">\(P(x_{t-1}|x_t) \propto \exp(-\|G(x_t) - x_{t-1}\|_2)\)</span></span></li>
<li>所以<span><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta (x_0) = \int\limits_{x_1 : x_T} P(x_T) P_\theta(x_{T-1}|x_T) \dots P_\theta(x_{t-1}|x_t) \dots P_\theta(x_0 | x_1) d x_1:x_T\)</span></span></li>
<li>注意<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(P\)</span><span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(P_\theta\)</span><span class="heti-spacing"> </span></span>是独立的分布，而后者是模型生成出来的，而下标<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\theta\)</span><span class="heti-spacing"> </span></span>表示的就是模型的参数</li>
</ul>
</li>
<li>
<p><span><span class="arithmatex">\(\log P(x)\)</span><span class="heti-spacing"> </span></span>的下界</p>
<ul>
<li>
<p>对比<span class="heti-skip"><span class="heti-spacing"> </span>VAE<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>DDPM</span>，发现两者的计算大差不差，只是<span class="heti-skip"><span class="heti-spacing"> </span>VAE<span class="heti-spacing"> </span></span>的分布来自编码器，而<span class="heti-skip"><span class="heti-spacing"> </span>DDPM<span class="heti-spacing"> </span></span>的分布来自扩散过程</p>
<p></p><div style="text-align: center">
<img src="images/lec9/93.png" width="70%/"/>
</div>
</li>
<li>
<p>其中<span><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_1:x_T|x_0) = q(x_1|x_0)q(x_2|x_1) \dots q(x_T|x_{T-1})\)</span></span></p>
<ul>
<li>
<p><span class="arithmatex">\(q(x_t|x_{t-1})\)</span></p>
<p></p><div style="text-align: center">
<img src="images/lec9/94.png" width="70%/"/>
</div>
</li>
<li>
<p><span class="arithmatex">\(q(x_t|x_0)\)</span></p>
<p></p><div style="text-align: center">
<img src="images/lec9/95.png" width="70%/"/>
</div>
<ul>
<li>
<p>先考虑<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_1|x_0)\)</span><span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_2|x_1)\)</span><span class="heti-spacing"> </span></span>的计算</p>
<p></p><div style="text-align: center">
<img src="images/lec9/96.png" width="70%/"/>
</div>
<p>可以将两个（独立的）噪音合并起来，简化计算<span><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_2|x_0)\)</span></span>。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/97.png" width="70%/"/>
</div>
</li>
<li>
<p>通过这样的合并，在计算<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_t|x_0)\)</span><span class="heti-spacing"> </span></span>时只需考虑一个噪声即可：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/98.png" width="70%/"/>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>接下来就可以转换那个要最大化的式子<span><span class="heti-spacing"> </span><span class="arithmatex">\(\mathbb{E}_{q(x_1:x_T|x_0)}[\log \left(\dfrac{P(x_0:x_T)}{q(x_1:x_T|x_0)}\right)]\)</span></span>。由于中间计算过程过于复杂，这里就不展示了，直接给出最终转换结果：</p>
<div class="arithmatex">\[
\mathbb{E}_{q(x_1|x_0)} [\log P(x_0|x_1)] - KL(q(x_T|x_0)\|P(x_T)) - \sum\limits_{t=2}^T \mathbb{E}_{q(x_t|x_0)} [KL(q(x_{t-1}|x_t, x_0)\|P(x_{t-1}|x_t))]
\]</div>
<p>由于前两项的处理和最后一项是类似的，因此下面只考虑最后一项是如何计算的。</p>
<ul>
<li>
<p>计算<span><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_{t-1}|x_t, x_0)\)</span></span></p>
<ul>
<li>
<p>先算出<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_t|x_0), q(x_{t-1}|x_0), q(x_t|x_{t-1})\)</span><span class="heti-spacing"> </span></span>的值</p>
<p></p><div style="text-align: center">
<img src="images/lec9/99.png" width="70%/"/>
</div>
</li>
<li>
<p><span><span class="arithmatex">\(q(x_{t-1}|x_t, x_0)\)</span><span class="heti-spacing"> </span></span>的含义是：已知<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_0\)</span><span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span><span class="arithmatex">\(x_t\)</span></span>，但不知道中间过程，求<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_{t-1}\)</span><span class="heti-spacing"> </span></span>的分布</p>
<p></p><div style="text-align: center">
<img src="images/lec9/100.png" width="70%/"/>
</div>
</li>
<li>
<p>计算：</p>
<div class="arithmatex">\[
\begin{align*}
q(x_{t-1}|x_t, x_0) &amp; = \dfrac{q(x_{t-1}, x_t, x_0)}{q(x_t, x_0)} \\
&amp; = \dfrac{q(x_t|x_{t-1})q(x_{t-1}|x_0)q(x_0)}{q(x_t|x_0)q(x_0)} \\
&amp; = \dfrac{q(x_t|x_{t-1})q(x_{t-1}|x_0)}{q(x_t|x_0)}
\end{align*}
\]</div>
<p>最后一行的三项都是已知的，所以<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(q(x_{t-1}|x_t, x_0)\)</span><span class="heti-spacing"> </span></span>能够确定下来。</p>
</li>
<li>
<p>要知道具体的值，还得继续往下算，由于太麻烦了，所以就只展示最终结果，不做额外解释：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/101.png" width="80%/"/>
</div>
</li>
<li>
<p>我们知道，这一项是一个正态分布，所以根据前面的计算结果，可得</p>
<ul>
<li>均值：<span class="arithmatex">\(\dfrac{\sqrt{\bar{\alpha}_{t-1}} \beta_t x_0 + \sqrt{\bar{\alpha}_t} (1 - \bar{\alpha}_{t-1}) x_t}{1 - \bar{\alpha}_t}\)</span></li>
<li>方差：<span class="arithmatex">\(\dfrac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \beta_t I\)</span></li>
</ul>
</li>
</ul>
</li>
<li>
<p>考虑整个<span class="heti-skip"><span class="heti-spacing"> </span>KL<span class="heti-spacing"> </span></span>散度</p>
<ul>
<li>第一个分布的均值和方差是固定的（就是前面算出来的那两个<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，第二个分布的方差是固定的，但均值是可调的<span><span class="heti-spacing"> </span>(tunable)</span></li>
<li>
<p>所以要想最小化<span class="heti-skip"><span class="heti-spacing"> </span>KL<span class="heti-spacing"> </span></span>散度，我们能做的就是让第二个分布的均值尽可能接近第一个分布，而第二个分布正是图像<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_t\)</span><span class="heti-spacing"> </span></span>经过去噪后的分布</p>
<p></p><div style="text-align: center">
<img src="images/lec9/102.png" width="70%/"/>
</div>
<p></p><div style="text-align: center">
<img src="images/lec9/103.png" width="70%/"/>
</div>
<p>注意，<span class="arithmatex">\(x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \varepsilon \Rightarrow \dfrac{x_t - \sqrt{1 - \bar{\alpha}_t} \varepsilon}{\sqrt{\bar{\alpha}_t}} = x_0\)</span></p>
</li>
<li>
<p>处理第一个分布的均值：</p>
<div class="arithmatex">\[
\begin{align*}
&amp; \dfrac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \textcolor{red}{x_0} + \sqrt{\bar{\alpha}_t} (1 - \bar{\alpha}_{t-1}) x_t}{1 - \bar{\alpha}_t} \\
= &amp; \dfrac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \textcolor{red}{\dfrac{x_t - \sqrt{1 - \bar{\alpha}_t} \varepsilon}{\sqrt{\bar{\alpha}_t}}} + \sqrt{\bar{\alpha}_t} (1 - \bar{\alpha}_{t-1}) x_t}{1 - \bar{\alpha}_t} \\
= &amp; \dfrac{1}{\sqrt{\bar{\alpha}_t}} \left(x_t - \dfrac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \varepsilon\right)
\end{align*}
\]</div>
<p>不难发现，这个式子正是采样算法第<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>行等式的前半部分。而式子中<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(x_t, \alpha_t\)</span><span class="heti-spacing"> </span></span>都是固定值，实际需要模型预测的部分就是<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\varepsilon\)</span><span class="heti-spacing"> </span></span>了。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div style="text-align: center">
<img src="images/lec9/104.png" width="60%/"/>
</div>
<p>为什么采样算法第<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>行等式还有一项<span><span class="heti-spacing"> </span><span class="arithmatex">\(\sigma_t z\)</span></span>（一个正态分布）呢，而不是直接取前面计算出来的值（即正态分布的均值）呢？李宏毅老师给出了以下猜想：如果不引入额外的采样，模型生成的结果可能缺乏创新性，容易出现重复的内容。</p>
<details class="example" open="open">
<summary>例子</summary>
<div class="tabbed-set tabbed-alternate" data-tabs="5:3"><input checked="" id="__tabbed_5_1" name="__tabbed_5" type="radio"/><input id="__tabbed_5_2" name="__tabbed_5" type="radio"/><input id="__tabbed_5_3" name="__tabbed_5" type="radio"/><div class="tabbed-labels"><label for="__tabbed_5_1">例<span><span class="heti-spacing"> </span>1</span>：文本生成</label><label for="__tabbed_5_2">例<span><span class="heti-spacing"> </span>2</span>：语音合成</label><label for="__tabbed_5_3">例<span><span class="heti-spacing"> </span>3</span>：图像生成</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/105.png" width="70%/"/>
</div>
<p></p><div style="text-align: center">
<img src="images/lec9/106.png" width="40%/"/>
</div>
</div>
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/107.png" width="70%/"/>
</div>
</div>
<div class="tabbed-block">
<p>如果<span><span class="heti-spacing"> </span><span class="arithmatex">\(\sigma_t = 0\)</span></span>，那么就无法正常生成图像了。</p>
<p></p><div style="text-align: center">
<img src="images/lec9/108.png" width="70%/"/>
</div>
</div>
</div>
</div>
</details>
<h4 id="applications">Applications<a class="headerlink" href="#applications" title="Permanent link">⚓︎</a></h4>
<div class="tabbed-set tabbed-alternate" data-tabs="6:3"><input checked="" id="__tabbed_6_1" name="__tabbed_6" type="radio"/><input id="__tabbed_6_2" name="__tabbed_6" type="radio"/><input id="__tabbed_6_3" name="__tabbed_6" type="radio"/><div class="tabbed-labels"><label for="__tabbed_6_1">语音</label><label for="__tabbed_6_2">文本</label><label for="__tabbed_6_3">图像</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p></p><div style="text-align: center">
<img src="images/lec9/110.png" width="70%/"/>
</div>
</div>
<div class="tabbed-block">
<p>直接在文本上加噪音是很困难的。</p>
<p>一种解决方案是在潜空间<span class="heti-skip"><span class="heti-spacing"> </span>(latent space)<span class="heti-spacing"> </span></span>上加噪音。下面列出一些相关研究：</p>
<ul>
<li>
<p>Diffusion-LM</p>
<p></p><div style="text-align: center">
<img src="images/lec9/111.png" width="70%/"/>
</div>
</li>
<li>
<p>DiffuSeq</p>
<p></p><div style="text-align: center">
<img src="images/lec9/112.png" width="70%/"/>
</div>
</li>
</ul>
<p>另一种方法是不要加从正态分布上采样得到的噪音，改变噪音来源：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/113.png" width="70%/"/>
</div>
</div>
<div class="tabbed-block">
<p>有一种叫做<strong>掩码预测</strong><span>(mask-predict)<span class="heti-spacing"> </span></span>的方法，最开始用于<a href="https://aclanthology.org/D19-1633/">文本模型</a>，简答来说就是做填空题：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/114.png" width="70%/"/>
</div>
<p>这种技术还能用在图像生成上：</p>
<p></p><div style="text-align: center">
<img src="images/lec9/115.png" width="70%/"/>
</div>
<p></p><div style="text-align: center">
<img src="images/lec9/116.png" width="70%/"/>
</div>
<p></p><div style="text-align: center">
<img src="images/lec9/117.png" width="70%/"/>
</div>
</div>
</div>
</div>
<h3 id="gan">GAN<a class="headerlink" href="#gan" title="Permanent link">⚓︎</a></h3>
<p>这里不会展开介绍<span class="heti-skip"><span class="heti-spacing"> </span>GAN<span class="heti-spacing"> </span></span>的原理，感兴趣的读者可阅读笔者之前写过的<a href="../ml/6.html"><span class="heti-skip"><span class="heti-spacing"> </span>GAN<span class="heti-spacing"> </span></span>笔记</a>。</p>
<p>实际上，<span>GAN<span class="heti-spacing"> </span></span>可以是一个外挂，和前面几种方法结合起来使用，进一步提高图像<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>视频生成的质量。</p>
<div style="text-align: center">
<img src="images/lec9/44.png" width="70%/"/>
</div>
<h3 id="others">Others<a class="headerlink" href="#others" title="Permanent link">⚓︎</a></h3>
<p>有一种更加强大的模型，可以让我们和它生成的视频进行互动，比如直接操控视频中人物的动作。这个模型就是 <a href="https://arxiv.org/abs/2402.15391"><strong>Genie</strong></a>（全程生成式可交互环境<span><span class="heti-spacing"> </span>(generative interactive environments)</span><heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。该模型将一张图像（帧）和用户输入的动作作为输入，输出下一帧。</p>
<div style="text-align: center">
<img src="images/lec9/45.png" width="60%/"/>
</div>
<p>训练时，我们可以收集大量的视频数据，但是很难收集到用户输入的动作。所以可以采用类似自编码器架构的方法，另外准备一个从当前帧和下一帧的画面中提取动作的模型，它会输出行动的编号（叫做<strong>潜在动作</strong>(latent action)<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。然后将潜在行动和当前帧画面丢给图像生成的模型，让它输出下一帧画面。</p>
<div style="text-align: center">
<img src="images/lec9/46.png" width="70%/"/>
</div>
<details class="info">
<summary>延伸阅读</summary>
<ul>
<li><a href="https://arxiv.org/abs/2405.17247">An Introduction to Vision-Language Modeling</a></li>
<li><a href="https://arxiv.org/abs/2405.03150">Video Diffusion Models: A Survey</a></li>
</ul>
</details></div>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="最后更新">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年8月23日 18:28:24">2025年8月23日 18:28:24</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="创建日期">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="2025年8月23日 18:28:24">2025年8月23日 18:28:24</span>
</span>
</aside>
<p style="font-size: 30px; font-weight: 600">评论区</p>
<div>
    如果大家有什么问题或想法，欢迎在下方留言~
  </div>
<!-- Insert generated snippet here -->
<script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOMAb9Zs4CfmpP" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="noughtq/notebook" data-repo-id="R_kgDOMAb9Zg" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate"
        ? "transparent_dark"
        : "light"

      // Instruct Giscus to set theme
      giscus.setAttribute("data-theme", theme) 
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate"
            ? "dark"
            : "light"

          // Instruct Giscus to change theme
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
<!-- 标题计数器 -->
<link href="/css/counter.css" rel="stylesheet"/>
<!-- 主页个性化 -->
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="上一页: Generation Strategies" class="md-footer__link md-footer__link--prev" href="8.html">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z" fill="currentColor"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                上一页
              </span>
<div class="md-ellipsis">
                Generation Strategies
              </div>
</div>
</a>
<a aria-label="下一页: Voice Mode of GPT-4o" class="md-footer__link md-footer__link--next" href="10.html">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                Voice Mode of GPT-4o
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z" fill="currentColor"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright" style="margin-left: 33.5%">
<div class="md-copyright__highlight" style="text-align: center">
        Copyright © 2024-2025 <a href="https://github.com/NoughtQ">NoughtQ</a>
</div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" rel="noopener" target="_blank">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
        Material
      </a>
      modified by
      <a href="https://github.com/NoughtQ" rel="noopener" target="_blank">
        NoughtQ
      </a>
<!-- <br> -->
<div style="text-align: center;">
<a href="https://icp.gov.moe/?keyword=20252357" target="_blank">萌ICP备20252357号</a>
</div>
</div>
<div class="md-social">
<a class="md-social__link" href="https://noughtq.top" rel="noopener" target="_blank" title="noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M277.8 8.6c-12.3-11.4-31.3-11.4-43.5 0l-224 208c-9.6 9-12.8 22.9-8 35.1S18.8 272 32 272h16v176c0 35.3 28.7 64 64 64h288c35.3 0 64-28.7 64-64V272h16c13.2 0 25-8.1 29.8-20.3s1.6-26.2-8-35.1zM240 320h32c26.5 0 48 21.5 48 48v96H192v-96c0-26.5 21.5-48 48-48" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://blog.noughtq.top" rel="noopener" target="_blank" title="blog.noughtq.top">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/noughtq" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="mailto:noughtq666@gmail.com" rel="noopener" target="_blank" title="">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.copy", "content.code.annotate", "content.footnote.tooltips", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.indexes", "navigation.tracking", "navigation.prune", "search.share"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
<script src="../../js/anchor.js"></script>
<script src="../../js/katex.js"></script>
<script src="../../js/toc.js"></script>
<script src="../../js/typed.js"></script>
<script src="../../js/custom.js"></script>
<script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
<script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
</body>
</html>