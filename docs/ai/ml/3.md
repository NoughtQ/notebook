---
counter: true
---

# Deep Learning

## Introduction

在前面介绍的机器学习的训练中，找到合适的参数后，便可以通过模型得到一组较为准确的一组预测值 $\bm{a}$（向量）。难道这样就结束了吗？我们还可以将 $\bm{a}$ 再一次代入这个模型中，得到 $\bm{a}'$，...，以此类推。

<div style="text-align: center">
    <img src="images/lec3/1.png" width=80%/>
    <img src="images/lec3/2.png" width=80%/>
</div>

在机器学习中，我们通常为上图的计算过程赋予这些名称：

- **神经元**(neuron)：包括输入（通过权重和偏移对一组数据求和）、激活函数和输出
    - 网络参数(network parameter)$\theta$：神经元的所有权重和偏移
- **神经网络**(neural network)：由众多这样的神经元构成的集体，类似一张网（模拟人类的大脑）
    - 这里的神经网络称为**全连接神经网络**(fully-connected neural network)，这种网络的特点是每个神经元接受所有的输入，且都有各自的权重和偏移，因此相当灵活；但缺点是效率不高
- **层**(layer)：相当于一次训练的过程
    - **输入层**(input layer)：初始输入的数据集
    - **隐藏层**(hidden layer)：中间的一排排神经元
    - **输出层**(output layer)：最后一层神经元，得到训练结果

多次训练意味着有多层的神经元，看起来就很“深”，因此称之为**深度学习**(deep learning)。

??? example "（有些过时的）例子"

    <div style="text-align: center">
        <img src="images/lec3/3.png" width=80%/>
    </div>

根据实际经验，随着层数的加深，训练结果的质量会不断提升，但也不是始终能够提升——到达一定层数后，虽然对于训练数据的预测更准确，但是对未来的预测结果的质量反而会下降，这种情况称为**过拟合**(overfitting)。因此，我们不会让层数一直深下去的，合适的层数需要通过直觉(intuition)和不断的试错(trial and error)得到。


## Why Deep?

现在来思考一个问题：我们为什么要搭建深层的神经网络，而不是更浅更“胖”的神经网络呢？

<div style="text-align: center">
    <img src="images/lec3/30.png" width=60%/>
</div>

假设上面的两个神经网络具备相同数量的参数，那么究竟哪一个的表现更好呢？前人对此做过研究了，结果如下（表格前两列表示深层网络，后两列表示浅层网络，同一行的网络参数数量相等）：

<div style="text-align: center">
    <img src="images/lec3/31.png" width=70%/>
</div>

- 随着层数（深度）的增加，神经网络的表现会越来越好
- 在参数数量相等的情况下，深层网络的表现显著优于浅层网络
- 同一层网络规模的增加（即变得更“胖”）并不一定会改善神经网络的表现

因此，深层网络可以用更少的参数达到和浅层网络相等甚至更好的表现，而更少的参数也意味着更不容易发生过拟合等问题，因此我们才会推崇“深度学习”。

但是，为什么更深意味着更好呢？在前面的学习中，我们知道理论上是可以只用一层神经元来表示任意的函数（模型）（回忆一下：任意函数 = 常量 + sigmoid/ReLu 函数的组合），当然这一层上会有很多很多的参数。然而，通过多层的结构，我们可以更加**高效**地表示函数，具体来说就是深层网络可以用更少的参数达到相同的效果：

<div style="text-align: center">
    <img src="images/lec3/32.png" width=60%/>
</div>

??? example "一些类比"

    === "逻辑电路"

        <div style="text-align: center">
            <img src="images/lec3/33.png" width=70%/>
        </div>

        用逻辑门构建一个 $d$ 位奇偶校验器（这里是偶校验）

        - 如果只用两层电路的话，那么需要 $O(2^d)$ 个逻辑门（每一位都有 0 和 1 两种可能）
        - 如果使用多层电路的话，电路图就如上所示，这时只需要 $O(d)$ 个逻辑门就 OK 了

    === "编程"

        <div style="text-align: center">
            <img src="images/lec3/34.png" width=70%/>
        </div>

        在编写一个大型项目的时候，我们通常不会将所有的功能都放在主函数中实现（类比一层很胖的神经元），而是将不同功能放在不同模块（或子函数）中实现，而这些模块可能会调用下面的其他子模块，好比深层次的神经网络。


    === "剪纸"

        <div style="text-align: center">
            <img src="images/lec3/35.png" width=70%/>
        </div>

        在正式剪纸之前，我们往往会先将纸对折几次（类比深层的神经网络）后再开始剪，这样相比直接在纸上剪（类比浅层的神经网络），不仅可以剪得更快，而且更不容易失误。

下面用一个简单的例子来说明深层的神经网络是如何高效表示出复杂的函数：

???+ example "例子"

    === "第一层"

        假设训练时只用到一个数据 $x$，通过不同神经元（偏移、权重、激活函数）的组合后，得到输出 $a_1$，它是一个 2 段的分段函数。

        <div style="text-align: center">
            <img src="images/lec3/36.png" width=70%/>
        </div>


    === "第二层"

        然后将 $a_1$ 作为第二层的输入，通过与第一层相同的神经元的计算后，得到 $a_2$，它是一个 4 段的分段函数（至于为什么是 4 段，这点不难推导，所以这里就不解释了）。

        <div style="text-align: center">
            <img src="images/lec3/37.png" width=70%/>
        </div>


    === "第三层"

        然后将 $a_2$ 作为第三层的输入，通过与前两层相同的神经元的计算后，得到 $a_3$，它是一个 8 段的分段函数。

        <div style="text-align: center">
            <img src="images/lec3/38.png" width=70%/>
        </div>


假如我们要表示一个 $2^k$ 段的分段函数，如果使用上面的深层神经网络（每层只有两个神经元），那么只需要 $k$ 层，即 $2k$ 个神经元就能完成任务。然而，如果用一层神经网络的话，就需要 $2^k$ 个神经元。所以深层神经网络所需要的神经元数量明显更小，这样不仅成本低，而且更小的参数也意味着更少的模型可能性（即 $|H|$ 更小），那么在训练集上得到的模型的表现与在真实情况下的表现更加接近。

!!! note "注"

    - 当需要的函数是复杂而规整的话，深层的神经网络会优于相等数量参数下的浅层网络
    - 当 $y = x^2$ 时，深层的神经网络相比浅层的表现是指数级的好！

呼应上一讲的结尾：<u>**深度学习**是一个可以让鱼和熊掌可以兼得的方法</u>。


## CNN

接下来介绍一种非常有名的，主要为**图像**(image)设计的神经网络架构——**卷积神经网络**(convolutional neural network, CNN)。我们将会从两个角度认识 CNN，对 CNN 有一个全面而深入的理解。


### Neuron Version Story

现在要训练一个用于**图像分类**(image classification)的模型，它的输入和输出为：

<div style="text-align: center">
    <img src="images/lec3/4.png" width=70%/>
</div>

- 所有输入图像都应是固定的尺寸，这里假设均为 100 x 100
- 由于是分类问题，所以输出是一个独热向量（可能包含成千上万的元素），并且使用交叉熵来计算损失

我们将一张图像看作是一个三维的**张量**(tensor)（简单理解成多维数组），它有宽度、高度、通道数量（或者称为深度）这三维。这里假定通道数量 = 3，即 RGB 三个通道。在将图像输入给模型训练前，需要将这个三维张量“**拉直**”，即让这个三维张量变成一维向量，该向量的每个元素都是来自不同宽、高和通道的像素，其值表示的是图像上某个位置、某个通道下的亮度(intensity)。

<div style="text-align: center">
    <img src="images/lec3/5.png" width=70%/>
</div>

现在，将拉直后的一维向量丢给全连接神经网络：

<div style="text-align: center">
    <img src="images/lec3/6.png" width=70%/>
</div>

假设网络的第一层有 1000 个神经元，由于有 100 x 100 x 3 = 30000 个输入项，所以第一个隐藏层就有 $3 \times 10^7$ 个权重，因此产生了很多参数。前面提到过，虽然参数多意味着模型很灵活，但是这会带来过拟合的问题。所以全连接神经网络不太适合做图像处理相关的任务。现在我们来观察一下图像处理任务究竟有什么特性，以帮助我们设计出更合理的神经网络。


#### Observation and Simplification 1

与其让神经元读取图像上的所有数据，不如让每个神经元读取部分图像区域上的数据，用于识别图像上的一些关键**模式**(patterns)。比如对于下面这张关于鸟的图片，机器可以从它的嘴巴、眼睛、爪子等特征（模式）来作出“这是一只鸟”的判断。实际上，人类也正是基于相似的方法来分辨图像。

<div style="text-align: center">
    <img src="images/lec3/7.png" width=80%/>
</div>

基于上述发现，我们可以着手简化神经网络的设计——每个神经元仅读取某一小块区域上的图像数据，因此用到了更少的参数；而我们通常称这一小块区域为**感受野**(receptive field)。

<div style="text-align: center">
    <img src="images/lec3/8.png" width=70%/>
</div>

!!! note "注"

    - 不同神经元对应的感受野可以有重叠的地方
    - 甚至不同神经元的感受野可以是相同的
        - 但由于不同神经元的权重和偏移不同，因此即使对于相同的一块区域，输出也是不一样的

    <div style="text-align: center">
        <img src="images/lec3/9.png" width=70%/>
    </div>

???+ question "思考"

    === "问题1"

        不同的神经元可以有不同大小的感受野吗？

        可以的（而且也很常见）。比如不同的模式可能有不同的大小，因此神经元需要用不同大小的感受野来检测对应的模式。

    === "问题2"

        感受野可以仅包含部分通道吗？

        可以。在其他的网络架构中会有这样的调整，但在一般的 CNN 中不会考虑。


    === "问题3"

        感受野可以不是方的（可以是矩形或其他形状）吗？一定是一块邻近的连续区域吗？

        可以。根据自己对任务的理解，可以确定不同形状的感受野。

- 实际上，每个感受野都对应一组不同的神经元
- 而且，我们会让所有的感受野覆盖整张图像，最经典的安排方法是：
    - 先在图像左上角取图像的一部分作为感受野（但包含所有通道），这块感受野的大小称为**核尺寸**(kernel size)，一般设置为 3x3
    - 然后移动这块感受野，从而得到新的感受野。每次移动都有规定的**步幅**(stride)，一般设为 1 或 2。这可能会带来一些问题：
        - 相邻的感受野之间会有**重叠**，这是正常现象。而且如果没有做到重叠的话，那就有可能会漏掉那些位于重叠区域的模式，从而影响图像分类的效果
        - 感受野移动到边界的时候，可能会有一部分不在图像内。一般采取的做法是在图像外围**填充**(padding)一圈 `0`，也就是说不存在的部分用 `0` 表示即可

<div style="text-align: center">
    <img src="images/lec3/10.png" width=70%/>
</div>


#### Observation and Simplification 2

另一个不难发现的事实是：对于不同的图像而言，相同的模式可能出现在图像的不同位置上。比如下面有两张关于鸟的图片，上图鸟嘴出现在图像左上方，而下图鸟嘴出现在图像中央位置。

<div style="text-align: center">
    <img src="images/lec3/11.png" width=80%/>
</div>

因此，我们可以让某些神经元**共享参数**(parameter sharing)，那么这些神经元识别的是同一种模式，但针对的是不同的感受野，这样可以在确保识别不同位置上的模式的同时，还能减少一些参数。

<div style="text-align: center">
    <img src="images/lec3/12.png" width=70%/>
</div>

前面提到过，每个感受野都对应一组不同的神经元，但其中一些神经元之间共享参数，我们称这样的神经元为**滤波器**(filter)。

<div style="text-align: center">
    <img src="images/lec3/13.png" width=80%/>
</div>

!!! abstract "总结"

    现在总结一下我们目前学到过的有关深度学习的知识：

    <div style="text-align: center">
        <img src="images/lec3/14.png" width=70%/>
    </div>

    从这张维恩图中可以看出，我们简单地认为：使用感受野和参数共享这两项简化技术的全连接层就是**卷积层**(convolutional layer)。

    - 虽然经过这两项简化技术后，卷积层的模型偏移会变得更大，但是相比全连接层而言，它还是更适合用于图像处理的任务
    - 而全连接层的模型偏移较小，意味着灵活性高，可以胜任各种各样的任务，但这也意味着它没有特别擅长的事


### Filter Version Story

现在我们知道，图像在经过一些卷积层的处理后，就可以得到关于图像的分类结果；而且在卷积过程中会用到一些滤波器，这些滤波器一般都是规模为 3x3 通道数量的张量。为了方便后续的讨论，

- 假定通道数为1，即处理的是黑白图像。
- 且图像的尺寸为 6x6，还有以下两个滤波器，里面的值就是模型的未知参数：

    <div style="text-align: center">
        <img src="images/lec3/15.png" width=70%/>
    </div>

- 规定步幅 = 1，即滤波器一次只能走一格

滤波结果为：

=== "第1个滤波器"

    <div style="text-align: center">
        <img src="images/lec3/16.png" width=70%/>
    </div>

    观察第1个滤波器的特征，发现对角线上的值都是1，这也就意味着这个滤波器寻找的是图像上对角线均为1的模式。

    <div style="text-align: center">
        <img src="images/lec3/17.png" width=70%/>
    </div>


=== "第2个滤波器"

    <div style="text-align: center">
        <img src="images/lec3/18.png" width=70%/>
    </div>

    观察第2个滤波器的特征，发现中间列上的值都是1，这也就意味着这个滤波器寻找的是图像上中间列均为1的模式。

    我们将所有使用滤波器得到的结果汇总在一起，构成了一张**特征图**(feature map)。有多少个滤波器，这张特征图就有多少个通道。

---
一个神经网络中可以用多个卷积层，前一个卷积层的结果会作为下一个卷积层的输入。以上面的例子来说，假如有 64 个滤波器，那么就会得到一张有 64 个通道的特征图。我们可以将它看作是一张“图像”，传递到下一个卷积层中。而下一个卷积层中的滤波器可以是一个 3x3x64 大小的张量。

<div style="text-align: center">
    <img src="images/lec3/19.png" width=70%/>
</div>

??? question "思考：为什么一般使用 3x3 大小的滤波器就够了"

    假如每个卷积层的滤波器的宽和高都是3。在第一个卷积层得到的特征点之上使用滤波器（此时来到了第二个卷积层），此时得到的每个特征点实际上包含了 5x5 的区域。因此随着层数的加深，即使滤波器的大小一直是 3x3，但是特征点对原图的覆盖范围会越来越大，所以我们不用担心滤波器太小而无法覆盖图像上区域较大的模式的问题。

    <div style="text-align: center">
        <img src="images/lec3/20.png" width=60%/>
    </div>

!!! abstract "总结"

    |从神经元角度看|从滤波器角度看|
    |:-|:-|
    |每个神经元仅考虑一块感受野|有一组用于检测小区域模式的滤波器|
    |不同感受野下的神经元可能会共享参数|每个滤波器在输入图像上进行卷积操作|


### Pooling

对图像的第三个发现是：对原图像的像素进行二次采样(subsampling)后，不会改变图像中的物体。比如对下面关于鸟的图片进行二次采样，仅选择部分像素点，得到一张缩小了的图像，但是图像中的鸟没有发生太大的变化，依然可以识别出来。

<div style="text-align: center">
    <img src="images/lec3/21.png" width=60%/>
</div>

基于这一发现，我们在卷积神经网络中引入**池化**(pooling)的概念。由于它没有任何权重（即无法“学习”），因此它算不上是一个“层”，反而类似一个像 sigmoid 之类的激活函数。有很多种池化方法，这里仅介绍**最大池化**(max pooling)——它接受来自滤波器的输出（一组数字，类似图像数据），将其按固定大小划分为多个组，然后取每个组中的最大值，扔掉其他值。结果就是保留更少的，但又能符合原图像特征的数据。

=== "池化前"

    <div style="text-align: center">
        <img src="images/lec3/22.png" width=60%/>
    </div>

=== "池化后"

    <div style="text-align: center">
        <img src="images/lec3/23.png" width=60%/>
    </div>

回到整个神经网络，比对池化前后的结果：

<div style="text-align: center">
    <img src="images/lec3/24.png" width=70%/>
</div>

!!! abstract "完整的 CNN 框架！"

    <div style="text-align: center">
        <img src="images/lec3/25.png" width=60%/>
    </div>

    使用池化的最大原因是降低特征图的空间维度，减少计算量。但随着技术的发展，计算机的算力会越来越强，因此有时不必使用池化操作；而且过多的池化操作有可能会破坏原图像的特征，所以有些 CNN 甚至直接抛弃了池化（后面介绍的 Alpha Go 就是其中一个例子）。


### Applications

事实上，CNN 不仅可以用于图像处理，也能够完成其他领域内的任务，比如下围棋(playing Go)——著名的 Alpha Go 用的就是 CNN。

- 之所以这样是可行的，是因为可以将棋盘看作一张 19x19 的图像，每个位置上只有 3 种值：黑子（用1表示）、白子（用-1表示）、空（用0表示）
- Alpha Go 内将棋盘划分为 48 个通道，每个通道表示不同的棋局
- CNN 根据当前棋盘上的棋局，输出下一次移动的位置（19x19 个类）

此外，围棋也符合一些上述对图像的观察：

- 图像上有一些区域更小的模式
    - Alpha Go 在第一层上采用 5x5 大小的感受野

    <div style="text-align: center">
        <img src="images/lec3/26.png" width=20%/>
    </div>

- 相同的模式可能会出现在图像的不同区域上

    <div style="text-align: center">
        <img src="images/lec3/27.png" width=70%/>
    </div>

- 但显然不能在棋盘上进行所谓的“二次采样”，因为随便抽走某一列或某一行，棋局就可能会发生很大的变化。因此 Alpha Go 的 CNN 并没有使用池化。

???+ info "更多的应用"

    === "语音"

        <div style="text-align: center">
            <img src="images/lec3/28.png" width=70%/>
        </div>

    === "自然语言处理"

        <div style="text-align: center">
            <img src="images/lec3/29.png" width=80%/>
        </div>

!!! failure "CNN 的缺陷"

    如果对同一张图像进行缩放、旋转等操作，CNN 就无法识别出这些变换后的图像（有点笨）。因此需要在训练过程中使用**数据增强**(data augmentation)的方法，将这些变换后的图像也作为训练资料喂给神经网络。

    不过也有另一种方法：空间变换层(spatial transformer layer)能够解决这一问题。


## Self-Attention

之前我们介绍的模型，都只是将一个向量作为输入（比如 COVID-19 感染人数预测、图像处理等问题），输出的是一个标量（回归问题）或类（分类问题）。而现在我们将要讨论这样的一个模型：将**一组**向量（向量序列）作为输入，输出的是多个标量或类；而且输入向量的个数是可变的。

<div style="text-align: center">
    <img src="images/lec3/39.png" width=80%/>
</div>


### Inputs and Outputs

首先需要考虑的一个问题是：如何将实际问题的**输入**转化为一组向量的形式呢？来看下面几个例子：

???+ example "例子"

    === "句子"

        一个句子就是一个向量序列，而句子中的每个单词对应一个个的向量。将单词转化为向量的方式有：

        - **独热编码**(one-hot encoding)：假如所有单词的个数为n，那么我们就用一个大小为n的向量来表示每个单词，每个位置上的元素表示唯一的单词
            - 这种方式简单粗暴，但是不仅占用内存空间大，而且无法体现出两个单词之间的联系，即没有考虑到语义信息

                <div style="text-align: center">
                    <img src="images/lec3/40.png" width=50%/>
                </div>

        - **词嵌入**(word embedding)：语义关系越接近的两个单词，它们对应的向量值会更加接近，如下图所示：

            <div style="text-align: center">
                <img src="images/lec3/41.png" width=50%/>
            </div>


    === "语音"

        在机器学习课程 HW2 中，我们将语音看作一段段的帧（25ms 的语音）；并且用一个滑动窗口来划分帧，窗口每次移动的步幅为 10ms，所以 1s 的语音里就有 100 个帧。因此，每个帧就是一个向量，而一段语音就是变长的向量序列。

        <div style="text-align: center">
            <img src="images/lec3/42.png" width=70%/>
        </div>


    === "图"

        我们可以将图上的每个节点看作一个向量，所以整张图就是一组向量。在实际应用中：

        - 社交网络：

            <div style="text-align: center">
                <img src="images/lec3/43.png" width=70%/>
            </div>

        - 分子结构

            <div style="text-align: center">
                <img src="images/lec3/44.png" width=70%/>
            </div>

而输出的内容则可以分为以下几种情况：

- 每个输入向量对应一个输出标签(label)（即预测值）

    <div style="text-align: center">
        <img src="images/lec3/45.png" width=70%/>
    </div>

    ??? example "例子"

        <div style="text-align: center">
            <img src="images/lec3/46.png" width=70%/>
        </div>

- 对于整组向量，输出一个标签

    <div style="text-align: center">
        <img src="images/lec3/47.png" width=60%/>
    </div>

    ??? example "例子"

        <div style="text-align: center">
            <img src="images/lec3/48.png" width=70%/>
        </div>

- 由模型决定输出标签的数量（seq2seq，序列到序列）

    <div style="text-align: center">
        <img src="images/lec3/49.png" width=70%/>
    </div>

不过之后我们只专注第一种输出情况，即对于 N 个向量的输入，输出相应的 N 个标量或类。


### Self-Attention

接下来考虑如何构建适用于向量序列输入的模型。

??? bug "Naive Idea"

    既然 N 个向量输入对应 N 个输出，那么不妨让每个向量单独进入一个全连接层得到一个输出，如下图所示：

    <div style="text-align: center">
        <img src="images/lec3/50.png" width=70%/>
    </div>

    显然，这样有一个很大的缺陷：我们没有考虑到向量序列各个向量之间的联系，各个向量都是“各自为政”的。所以，如果有两个向量的值是相等的，那就会被视为意义相同的两个东西，从而产生两个相同的输出。

每个向量输入都有一个对应的**全连接层**，这个全连接层不仅应该接收对应的向量输入，同时也要顾及整个**上下文**(context)中的向量。

- 这个上下文的范围可以是一个局部的窗口，这样就仅考虑与对应输入向量相邻的部分向量

    <div style="text-align: center">
        <img src="images/lec3/51.png" width=70%/>
    </div>

- 也可以将整个向量序列都纳入考虑范围内，这样考虑得更全面些，比如用一个固定大小的窗口覆盖整个向量序列
    - 但是向量序列的长度可长可短，所以不能简单地使用窗口来实现这一点
    - 再说，就算有一个足够大小的窗口可以容纳所有向量，但是这样也意味着全连接层需要非常多的参数（$n$ 个向量就会产生 $n^2$ 个参数），而过多的参数意味着很容易出现过拟合的问题

因此，这里引入一种更好的做法——使用一种名为“**自注意**”(self-attention)的机制：

- 将输入向量送入全连接层之前，先让这些向量经过一种“自注意”的运算。对于每个输入向量，经过“自注意”运算后都会得到一个对应的输出，我们可以把这个输出看作是包含整个向量序列上下文信息的新向量，但同时也保留了原来输入向量的特征。
- 然后将这个新向量传给全连接层进行训练

这一过程如下图所示：

<div style="text-align: center">
    <img src="images/lec3/52.png" width=60%/>
</div>

当然，在多层神经网络中，可以在每两个隐藏层之间塞一个自注意计算：

<div style="text-align: center">
    <img src="images/lec3/53.png" width=60%/>
</div>

在自注意计算这个“盒子”的内部，输入和输出的关系如下所示：

<div style="text-align: center">
    <img src="images/lec3/54.png" width=60%/>
</div>

其中输入既可以是最外面的向量序列，也可以是经过几层训练后得到的输出向量序列。现在我们就考虑某一个输出向量，比如 $\bm{b^1}$，来认识一下自注意的计算过程。

首先，我们要计算 $\bm{b^1}$ 对应的输入向量 $\bm{a^1}$ 与其他输入向量的**相关程度**（用 $\alpha$ 表示）。有以下两种常用的方式：

<div style="text-align: center">
    <img src="images/lec3/55.png" width=60%/>
</div>

!!! info "注"

    下面我们会将主要考虑的输入向量称为**查询**(query)，而把另外的向量看作**键**(key)，所以它们分别对应的矩阵为 $W^q$ 和 $W^k$，与矩阵相乘的结果分别为 $\bm{q}$ 和 $\bm{k}$。

- **点积**(dot-product)：相关程度 $\alpha = \bm{q} \cdot \bm{k}$（向量的点积，得到一个标量）
- 加法(additive)：将 $\bm{q} + \bm{k}$ 的结果丢给 $\tanh$ 函数计算，然后再经过一次转换（用矩阵 $W$ 表示）得到 $\alpha$

下面我们仅考虑**点积**这一方法。

---
回到前面有4个输入的例子，先将 $\bm{a^1}$ 作为查询，其他几个输入向量（也可以包括 $\bm{a^1}$）作为键，计算相关程度 $\alpha_{1, j}\ (j = 1, \dots, 4)$：

<div style="text-align: center">
    <img src="images/lec3/58.png" width=80%/>
</div>

实际上，相关程度的值应该在 $[0, 1]$ 这一范围内，所以让这些相关程度值再经过一次 softmax 函数的运算，将它们的值映射到 $[0, 1]$ 上（用其他激活函数也没有问题）。

<div style="text-align: center">
    <img src="images/lec3/59.png" width=80%/>
</div>

另外，对于每个输入向量，我们还要为它们计算第三个向量 $\bm{v} = W^v \bm{a}$，然后将这个向量与刚刚经过 softmax 得到的相关程度值相乘，再将这些乘积相加（加权和），最终得到 $\bm{b}$。对于本例中的 $\bm{b^1}$ 而言，计算公式为：

$$
\bm{b^1} = \sum\limits_{i} \alpha'_{1, i} \bm{v^i}
$$

<div style="text-align: center">
    <img src="images/lec3/60.png" width=80%/>
</div>

剩下的 $\bm{b^2}, \bm{b^3}, \dots$ 等输出向量可以一起计算计算（**并行**计算），由于计算过程类似，故不再赘述。

---
现在我们从**矩阵**的角度研究一般情况下的计算过程：

- 对于每个输入向量 $\bm{a^i}$，需要得到三个向量 $\bm{q^i}, \bm{k^i}, \bm{v^i}$，而这些向量分别通过三个矩阵 $W^q, W^k, W^v$ 和 $\bm{a^i}$ 相乘得到。与其让矩阵分别和单个的输入向量相乘，不如将这些向量拼在一起，形成一个矩阵，这样就将多次的矩阵 $\times$ 向量的运算转化为一次的矩阵 $\times$ 矩阵的运算，如下所示：

    <div style="text-align: center">
        <img src="images/lec3/61.png" width=60%/>
    </div>

- 我们知道，计算相关程度 $\alpha$ 的过程是一个向量乘法，但是我们也可以将其转化为一个矩阵乘法，一次性算出所有的相关程度值
    - 先将所有的 $\bm{k}$ 拼在一起，一次性计算某个查询下的所有相关程度：

        <div style="text-align: center">
            <img src="images/lec3/62.png" width=80%/>
        </div>

    - 然后将所有的 $\bm{q}$ 拼在一起，这样就可以将所有的相关程度一次性算出来了！

        <div style="text-align: center">
            <img src="images/lec3/63.png" width=90%/>
        </div>

- 同理，将所有的向量 $\bm{v}$ 拼在一起，与相关程度构成的矩阵 $A'$ 相乘，得到所有的输出向量：

    <div style="text-align: center">
        <img src="images/lec3/64.png" width=70%/>
    </div>

综上，整个自注意的计算过程可以抽象为以下一系列的矩阵运算：

<div style="text-align: center">
    <img src="images/lec3/65.png" width=70%/>
</div>

其中三个矩阵 $W^q, W^k, W^v$ 是我们需要通过训练学习的参数。而由相关程度构成的（且经过 softmax 归一化处理后的）矩阵称作**注意矩阵**(attention matrix)。


### Multi-head Self-Attention

对于那些需要学习的参数 $\bm{q}, \bm{k}, \bm{v}$，我们可以将同一个参数拆成多份（即“**多个头**”(multi-head)，通过原参数 x 不同的矩阵得到），每个“头”考虑不同的相关性类型，从而能够捕获更复杂的关系，提高模型对复杂模式的理解。下图就是头数 = 2 的例子：

<div style="text-align: center">
    <img src="images/lec3/66.png" width=70%/>
</div>

下面以第 $i$ 个输入 $\bm{a^i}$ 为例介绍输出 $\bm{b^i}$ 的计算过程。先算出第一个头对应的输出 $\bm{b^{i, 1}}$：

<div style="text-align: center">
    <img src="images/lec3/67.png" width=70%/>
</div>

然后算出第二个头对应的输出 $\bm{b^{i, 2}}$：

<div style="text-align: center">
    <img src="images/lec3/68.png" width=70%/>
</div>

最后将这2个向量拼起来，乘上某个矩阵 $W^O$ 后，就能得到完整的输出 $\bm{b^i}$ 了：

<div style="text-align: center">
    <img src="images/lec3/69.png" width=40%/>
</div>


### Positional Encoding

自注意机制的一个缺陷是：没有考虑位置信息，比如输入序列中第 i 个和第 j 个向量无论它们之间距离多远，都不会影响到它们在自注意机制中的计算结果。但有时候我们希望将这些位置信息考虑在内，比如在做词性标记的时候，我们知道动词一般不会出现在句首，这就是个值得考虑的位置信息。所以这里引入了一种叫做**位置编码**(positional encoding)的技术——它会为每个输入向量设置一个唯一的**位置向量** $\bm{e^i}$，在进入自注意计算前，将其和输入向量 $\bm{a^i}$ 相加，这样自注意计算时就将位置信息考虑进去了。

下图展示了一种可行的位置向量序列（这也正是经典论文 *Attention Is All Your Need* 中最早用到的位置向量），其中1列表示1个位置向量：

<div style="text-align: center">
    <img src="images/lec3/70.png" width=40%/>
</div>

上面的位置向量是**人为设定的**(hand-crafted)——其实还可以通过数据训练出位置向量，下面就是一些典型的例子：

<div style="text-align: center">
    <img src="images/lec3/71.png" width=80%/>
</div>

注意，这里的图需要横着看，也就是说一行表示一个位置向量。


### Applications

自注意机制被广泛应用在 NLP 中，而且我们熟知的 Transformer 和 BERT 中也用到了自注意。下面来认识一下常见的应用！


#### Speech

在语音识别中也可以用自注意机制，但是存在一个问题：正如前面提到的，我们会把一段 10ms 的语音当做一个向量，那么随便将一两句话，这个输入序列的长度 $L$ 就大到吓人；而且注意矩阵 $A'$ 的规模是 $L \times L$ 的，甚至大到无法被内存容纳。

所以我们采取一种改进手段，叫做**截断自注意**(truncated self-attention)。简单来说就是：对于某个输入向量，我们仅考虑那些和当前输入向量比较接近的向量作为键，不去考虑更远的向量。在语音识别中，这种做法是合理的，因为要识别一句话中的一个字，我们往往无需得知整个段落的内容，也许仅靠这一句话甚至半句话就能判断出来了。

下面就是一个简化的示意图：

<div style="text-align: center">
    <img src="images/lec3/72.png" width=40%/>
</div>


#### Images

图像除了能用 CNN 来训练外，也可以用自注意来训练。我们可以将一张图像看作是一个向量集，而每个像素点就是一个向量，每个通道就是向量的元素。

<div style="text-align: center">
    <img src="images/lec3/73.png" width=70%/>
</div>

下面就是一些具体的应用：

<div style="text-align: center">
    <img src="images/lec3/74.png" width=80%/>
</div>


#### Graphs

自注意 + 图 = **图神经网络**(graph neural network)

<div style="text-align: center">
    <img src="images/lec3/83.png" width=80%/>
</div>

这里利用了图的信息，尤其是边的信息。我们仅考虑有边相连的两个节点对应的注意矩阵上的元素（蓝色方框），其他元素均为0（白色方框），这样我们就不会训练哪些没有意义的参数了。


### Comparison

#### Self-Attention v.s. CNN

<div style="text-align: center">
    <img src="images/lec3/75.png" width=40%/>
</div>

上图中，黄色方框对应的是 CNN 的感受野，而红色方框对应的是自注意的查询和键。我们不难发现：

- **CNN** 是一种只考虑感受野范围内的自注意机制，即 CNN 是一种简化的自注意机制。
- **自注意机制**是一种感受野范围更大（按 PPT 说法是可学习的(leanable)）的 CNN，即自注意机制是一种复杂版本的 CNN。

用维恩图可以形象表示两者的关系：

<div style="text-align: center">
    <img src="images/lec3/76.png" width=30%/>
</div>

由于自注意机制会考虑更多的输入，因而更加灵活，所以在数据不多的情况下更容易出现过拟合现象，效果就不如 CNN 了；而一旦数据量大到一定程度后，自注意机制的优势就显现出来了。

<div style="text-align: center">
    <img src="images/lec3/78.png" width=70%/>
</div>

下面这篇论文详细介绍了两者的关系，感兴趣的同学可自行上网搜索：

<div style="text-align: center">
    <img src="images/lec3/77.png" width=80%/>
</div>


#### Self-Attention v.s. RNN

目前**循环神经网络**(recurrent neutral network, RNN)基本上能被自注意机制给替代了，所以这里就简单介绍一下 RNN 的机制：

<div style="text-align: center">
    <img src="images/lec3/79.png" width=80%/>
</div>

- 底下4个小矩形就是输入，最开始会有一个初始内存
- 将这块内存和第一个输入向量一同放到 RNN 中，得到一个输出（中间用黑框包裹的矩形），该输出可进入 FC（全连接层）的训练中。
- 这个输出将和第二个输入向量一同放到 RNN 中，得到下一个输出，该输出也会进入 FC（全连接层）的训练中。之后就以此类推下去，故不再赘述。

对应的自注意机制示意图为：

<div style="text-align: center">
    <img src="images/lec3/80.png" width=60%/>
</div>

!!! bug "RNN 的劣势"

    - 难以考虑太远的输入向量：虽然我们可以将 RNN 改为双向的（这样的话输出向量都能包含任意输入向量，而不是像图示那样只能考虑左侧的输入向量），但相比自注意机制能一次看透所有输入的能力，读取较远位置的输入向量还是有些差劲的。

        <div style="text-align: center">
            <img src="images/lec3/81.png" width=70%/>
        </div>

    - 无法并行：其实解释和前面的差不多，就是 RNN 需要一个个看输入，不能并行加速；而自注意能通过并行一次看完所有输入，所以效率之间有着很大差别。

        <div style="text-align: center">
            <img src="images/lec3/82.png" width=70%/>
        </div>

正因为这些劣势，那些采用 RNN 的应用开始改用自注意机制了。